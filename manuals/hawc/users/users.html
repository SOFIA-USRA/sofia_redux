<!DOCTYPE html>

<html lang="en" data-content_root="../../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>HAWC+ DRP User’s Manual &#8212; sofia_redux v1.3.4.dev38+g92ea2f4</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../../_static/bootstrap-sofia.css?v=3fe2c07e" />
    <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css?v=eafc0fe6" />
    <link rel="stylesheet" type="text/css" href="../../../_static/plot_directive.css" />
    
    <script src="../../../_static/jquery.js?v=5d32c60e"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
    <script src="../../../_static/documentation_options.js?v=6aa39468"></script>
    <script src="../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/javascript" src="../../../_static/sidebar.js"></script>
    <script type="text/javascript" src="../../../_static/copybutton.js"></script>
    <link rel="icon" href="../../../_static/redux.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="EXES Redux Developer’s Manual" href="../../exes/developers/developers.html" />
    <link rel="prev" title="FORCAST Redux User’s Manual" href="../../forcast/users/users.html" />
    <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,600' rel='stylesheet' type='text/css'/>

  </head><body>
<div class="topbar">
  <a class="brand" title="Documentation Home" href="../../../index.html"><span id="logotext1">SOFIA</span><span id="logotext2">Redux</span><span id="logotext3">:docs</span></a>
  <ul>
    <li><a class="homelink" title="SOFIA Homepage" href="https://irsa.ipac.caltech.edu/Missions/sofia.html"></a></li>
    <li><a title="General Index" href="../../../genindex.html">Index</a></li>
    <li><a title="Module Index" href="../../../py-modindex.html">Modules</a></li>
    <li>
      
      
<form action="../../../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
      
    </li>
  </ul>
</div>

<div class="related">
    <h3>Navigation</h3>
    <ul>
      <li class="right">
	<a href="../../exes/developers/developers.html" title="EXES Redux Developer’s Manual">
	  next &raquo;
	</a>
      </li>
      <li class="right">
	<a href="../../forcast/users/users.html" title="FORCAST Redux User’s Manual">
	  &laquo; previous
	</a>
	 |
      </li>
      <li>
	<a href="../../../index.html">sofia_redux v1.3.4.dev38+g92ea2f4</a>
	 &#187;
      </li>
      <li><a href="../../../sofia_redux/index.html" accesskey="U">SOFIA Redux</a> &#187;</li>
      
      <li>HAWC+ DRP User’s Manual</li> 
    </ul>
</div>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="hawc-drp-users-manual">
<h1>HAWC+ DRP User’s Manual<a class="headerlink" href="#hawc-drp-users-manual" title="Link to this heading">¶</a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">¶</a></h2>
<p>The SI Pipeline User’s Manual (OP10) is intended for use by both SOFIA
Science Center staff during routine data processing and analysis, and
also as a reference for Guest Observers (GOs) and archive users to
understand how the data in which they are interested was processed. This
manual is intended to provide all the needed information to execute the
SI data reduction pipeline, and assess the data quality of the resulting
products. It will also provide a description of the algorithms used by
the pipeline and both the final and intermediate data products.</p>
<p>A description of the current pipeline capabilities, testing results,
known issues, and installation procedures are documented in the SI
Pipeline Software Version Description Document (SVDD, SW06, DOCREF). The
overall Verification and Validation (V&amp;V) approach can be found in the
Data Processing System V&amp;V Plan (SV01-2232). Both documents can be
obtained from the SOFIA document library in Windchill.</p>
<p>This manual applies to HAWC DRP version 3.2.0.</p>
</section>
<section id="si-observing-modes-supported">
<h2>SI Observing Modes Supported<a class="headerlink" href="#si-observing-modes-supported" title="Link to this heading">¶</a></h2>
<section id="hawc-instrument-information">
<h3>HAWC+ Instrument Information<a class="headerlink" href="#hawc-instrument-information" title="Link to this heading">¶</a></h3>
<p>HAWC+ is the upgraded and redesigned incarnation of the High-Resolution
Airborne Wide-band Camera instrument (HAWC), built for SOFIA. Since the
original design never collected data for SOFIA, the instrument may be
alternately referred to as HAWC or HAWC+. HAWC+ is designed for
far-infrared imaging observations in either total intensity (imaging) or
polarimetry mode.</p>
<p>HAWC currently consists of dual TES BUG Detector arrays in a 64x40
rectangular format. A six-position filter wheel is populated with five
broadband filters ranging from 40 to 250 <span class="math notranslate nohighlight">\(\mu\)</span>m and a dedicated
position for diagnostics. Another wheel holds pupil masks and rotating
half-wave plates (HWPs) for polarization observations. A polarizing beam
splitter directs the two orthogonal linear polarizations to the two
detectors (the reflected (R) array and the transmitted (T) array). Each
array was designed to have two 32x40 subarrays, for four total detectors
(R0, R1, T0, and T1), but T1 is not currently available for HAWC. Since
polarimetry requires paired R and T pixels, it is currently only
available for the R0 and T0 arrays. Total intensity observations may use
the full set of 3 subarrays.</p>
</section>
<section id="hawc-observing-modes">
<h3>HAWC+ Observing Modes<a class="headerlink" href="#hawc-observing-modes" title="Link to this heading">¶</a></h3>
<p>The HAWC instrument has two instrument configurations, for imaging and
polarization observations. In both types of observations, removing
background flux due to the telescope and sky is a challenge that
requires one of several observational strategies. The HAWC instrument
may use the secondary mirror to chop rapidly between two positions
(source and sky), may use discrete telescope motions to nod between
different sky positions, or may use slow continuous scans of the
telescope across the desired field. In chopping and nodding strategies,
sky positions are subtracted from source positions to remove background
levels. In scanning strategies, the continuous stream of data is used to
solve for the underlying source and background structure.</p>
<p>The instrument has two standard observing modes for imaging: the
Chop-Nod instrument mode combines traditional chopping with nodding; the
Scan mode uses slow telescope scans without chopping. The Scan mode is
the most commonly used for total intensity observations.
Likewise, polarization observations may be taken in either Nod-Pol or
Scan-Pol mode.  Nod-Pol mode includes chopping and nodding cycles
in multiple HWP positions; Scan-Pol mode includes repeated scans at
multiple HWP positions.</p>
<p>All modes that include chopping or nodding may be chopped and nodded
on-chip or off-chip. Currently, only two-point chop patterns with
matching nod amplitudes (nod-match-chop) are used in either Chop-Nod or
Nod-Pol observations, and nodding is performed in an A-B-B-A pattern
only. All HAWC modes can optionally have a small dither pattern or a
larger mapping pattern, to cover regions of the sky larger than HAWC’s
fields of view. Scanning patterns may be either box rasters or Lissajous
patterns.</p>
</section>
</section>
<section id="algorithm-description">
<h2>Algorithm Description<a class="headerlink" href="#algorithm-description" title="Link to this heading">¶</a></h2>
<section id="chop-nod-and-nod-pol-reduction-algorithms">
<h3>Chop-Nod and Nod-Pol Reduction Algorithms<a class="headerlink" href="#chop-nod-and-nod-pol-reduction-algorithms" title="Link to this heading">¶</a></h3>
<p>The following sections describe the major algorithms used to reduce
Chop-Nod and Nod-Pol observations. In nearly every case, Chop-Nod (total
intensity) reductions use the same methods as Nod-Pol observations, but
either apply the algorithm to the data for the single HWP angle
available, or else, if the step is specifically for polarimetry, have no
effect when called on total intensity data. Since nearly all total
intensity HAWC observations are taken with scanning mode, the following
sections will focus primarily on Nod-Pol data.</p>
<p>See the figures below for flow charts that illustrate the data reduction
process for Nod-Pol data (<a class="reference internal" href="#nodpol-flowchart-1"><span class="std std-numref">Fig. 100</span></a> and
<a class="reference internal" href="#nodpol-flowchart-2"><span class="std std-numref">Fig. 101</span></a>) and Chop-Nod data
(<a class="reference internal" href="#chopnod-flowchart-1"><span class="std std-numref">Fig. 102</span></a> and <a class="reference internal" href="#chopnod-flowchart-2"><span class="std std-numref">Fig. 103</span></a>).</p>
<figure class="align-default" id="nodpol-flowchart-1">
<img alt="Nod-Pol data reduction flowchart" src="../../../_images/polnod_single.png" />
<figcaption>
<p><span class="caption-number">Fig. 100 </span><span class="caption-text">Nod-Pol data reduction flowchart, up through Stokes parameter
calculation for a single input file.</span><a class="headerlink" href="#nodpol-flowchart-1" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<figure class="align-default" id="nodpol-flowchart-2">
<img alt="Nod-Pol data reduction flowchart, part 2" src="../../../_images/polnod_multiple.png" />
<figcaption>
<p><span class="caption-number">Fig. 101 </span><span class="caption-text">Nod-Pol data reduction flowchart, picking up from Stokes parameter
calculation, through combining multiple input files and calculating
polarization vectors.</span><a class="headerlink" href="#nodpol-flowchart-2" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<figure class="align-default" id="chopnod-flowchart-1">
<a class="reference internal image-reference" href="../../../_images/chopnod_single.png"><img alt="Chop-Nod data reduction flowchart" src="../../../_images/chopnod_single.png" style="width: 75%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 102 </span><span class="caption-text">Chop-Nod data reduction flowchart, up through Stokes parameter
calculation for a single input file.</span><a class="headerlink" href="#chopnod-flowchart-1" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<figure class="align-default" id="chopnod-flowchart-2">
<img alt="Chop-Nod data reduction flowchart, part 2" src="../../../_images/chopnod_multiple.png" />
<figcaption>
<p><span class="caption-number">Fig. 103 </span><span class="caption-text">Chop-Nod data reduction flowchart, picking up from Stokes parameter
calculation, through combining multiple input files.</span><a class="headerlink" href="#chopnod-flowchart-2" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<section id="prepare">
<span id="id1"></span><h4>Prepare<a class="headerlink" href="#prepare" title="Link to this heading">¶</a></h4>
<p>The first step in the pipeline is to prepare the raw data for
processing, by rearranging and regularizing the raw input data tables,
and performing some initial calculations required by subsequent steps.</p>
<p>The raw (Level 0) HAWC files contain all information in FITS binary
table extensions located in two Header Data Unit (HDU) extensions. The
raw file includes the following HDUs:</p>
<ul class="simple">
<li><p>Primary HDU: Contains the necessary FITS keywords in the header but
no data. It contains all required keywords for SOFIA data files, plus
all keywords required to reduce or characterize the various observing
modes. Extra keywords (either from the SOFIA keyword dictionary or
otherwise) have been added for human parsing.</p></li>
<li><p>CONFIGURATION HDU (EXTNAME = CONFIGURATION): Contains MCE (detector
electronics) configuration data. This HDU is stored only in the raw
and demodulated files; it is not stored in Level 2 or higher data
products. Nominally, it is the first HDU but users should use EXTNAME
to identify the correct HDUs. Note, the “HIERARCH” keyword option and
long strings are used in this HDU. All keyword names are prefaced
with “MCEn” where n=0,1,2,3. Only the header is used from this HDU.</p></li>
<li><p>TIMESTREAM Data HDU (EXTNAME = TIMESTREAM): Contains a binary table
with data from all detectors, with one row for each time sample. The
raw detector data is stored in the column “SQ1Feedback”, in FITS
(data-store) indices, i.e. 41 rows and 128 columns. Columns 0-31 are
for subarray R0, 32-63 for R1, 64-95 for T0 and 96-127 for T1).
Additional columns contain other important data and metadata,
including time stamps, instrument encoder readings, chopper signals,
and astrometry data.</p></li>
</ul>
<p>In order to begin processing the data, the pipeline first splits these
input TIMESTREAM data arrays into separate R and T tables. It will also
compute nod and chop offset values from telescope data, and may also
delete, rename, or replace some input columns in order to format them as
expected by later algorithms. The output data from this step has the
same HDU structure as the input data, but the detector data is now
stored in the “R Array” and “T Array” fields, which have 41 rows and 64
columns each.</p>
</section>
<section id="demodulate">
<h4>Demodulate<a class="headerlink" href="#demodulate" title="Link to this heading">¶</a></h4>
<p>For both Chop-Nod and Nod-Pol instrument modes, data is taken in a
two-point chop cycle. In order to combine the data from the high and low
chop positions, the pipeline demodulates the raw time stream with either
a square or sine wave-form. Throughout this step, data for each of the R
and T arrays are handled separately. The process is equivalent to
identifying matched sets of chopped images and subtracting them.</p>
<p>During demodulation, a number of filtering steps are performed to
identify good data. By default, the raw data is first filtered with a
box high-pass filter with a time constant of one over the chop
frequency. Then, any data taken during telescope movement (line-of-sight
rewinds, for example, or tracking errors) is flagged for removal. In
square wave demodulation, samples are then tagged as being in the
high-chop state, low-chop state, or in between (not used). For each
complete chop cycle within a single nod position at a single HWP angle,
the pipeline computes the average of the signal in the high-chop state
and subtracts it from the average of the signal in the low-chop state.
Incomplete chop cycles at the end of a nod or HWP position are
discarded. The sine-wave demodulation proceeds similarly, except that
the data are weighted by a sine wave instead of being considered either
purely high or purely low state.</p>
<p>During demodulation, the data is also corrected for the phase delay in
the readout of each pixel, relative to the chopper signal. For square
wave demodulation, the phase delay time is multiplied by the sample
frequency to calculate the delay in data samples for each individual
pixel. The data is then shifted by that many samples before
demodulating. For sine wave demodulation, the phase delay time is
multiplied with 2<span class="math notranslate nohighlight">\(\pi\)</span> times the chop frequency to get the phase
shift of the demodulating wave-form in radians.</p>
<p>Alongside the chop-subtracted flux, the pipeline calculates the error on
the raw data during demodulation. It does so by taking the mean of all
data samples at the same chop phase, nod position, HWP angle, and
detector pixel, then calculates the variance of each raw data point with
respect to the appropriate mean. The square root of this value gives the
standard deviation of the raw flux. The pipeline will propagate these
calculated error estimates throughout the rest of the data reduction
steps.</p>
<p>The result of the demodulation process is a chop-subtracted,
time-averaged flux value and associated variance for each nod position,
HWP angle, and detector pixel. The output is stored in a new FITS table,
in the extension called DEMODULATED DATA, which replaces the TIMESTREAM
data extension. The CONFIGURATION extension is left unmodified.</p>
</section>
<section id="flat-correct">
<h4>Flat Correct<a class="headerlink" href="#flat-correct" title="Link to this heading">¶</a></h4>
<p>After demodulation, the pipeline corrects the data for pixel-to-pixel
gain variations by applying a flat field correction. Flat files are
generated on the fly from internal calibrator files (CALMODE=INT_CAL),
taken before and after each set of science data. Flat files contain
normalized gains for the R and T array, so that they are corrected to
the same level. Flat files also contain associated variances and a bad
pixel mask, with zero values indicating good pixels and any other value
indicating a bad pixel. Pixels marked as bad are set to NaN in the gain
data. To apply the gain correction and mark bad pixels, the pipeline
multiplies the R and T array data by the appropriate flat data. Since
the T1 subarray is not available, all pixels in the right half of the T
array are marked bad at this stage. The flat variance values are also
propagated into the data variance planes.</p>
<p>The output from this step contains FITS images in addition to the data
tables. The R array data is stored as an image in the primary HDU; the R
array variance, T array data, T array variance, R bad pixel mask, and T
bad pixel mask are stored as images in extensions 1 (EXTNAME=”R ARRAY
VAR”), 2 (EXTNAME=”T ARRAY”), 3 (EXTNAME=”T ARRAY VAR”), 4 (EXTNAME=”R
BAD PIXEL MASK”), and 5 (EXTNAME=”T BAD PIXEL MASK”), respectively. The
DEMODULATED DATA table is attached unmodified as extension 6. The R and
T data and variance images are 3D cubes, with dimension
64x41xN<span class="math notranslate nohighlight">\(_{frame}\)</span>, where N<span class="math notranslate nohighlight">\(_{frame}\)</span> is the number of
nod positions in the observation, times the number of HWP positions.</p>
</section>
<section id="align-arrays">
<h4>Align Arrays<a class="headerlink" href="#align-arrays" title="Link to this heading">¶</a></h4>
<p>In order to correctly pair R and T pixels for calculating polarization,
and to spatially align all subarrays, the pipeline must reorder the
pixels in the raw images. The last row is removed, R1 and T1 subarray
images (columns 32-64) are rotated 180 degrees, and then all images are
inverted along the y-axis. Small shifts between the R0 and T0 and R1 and
T1 subarrays may also be corrected for at this stage. The spatial gap
between the 0 and 1 subarrays is also recorded in the ALNGAPX and
ALNGAPY FITS header keywords, but is not added to the image; it is
accounted for in a later resampling of the image. The output images are
64x40xN<span class="math notranslate nohighlight">\(_{frame}\)</span>.</p>
</section>
<section id="split-images">
<h4>Split Images<a class="headerlink" href="#split-images" title="Link to this heading">¶</a></h4>
<p>To prepare for combining nod positions and calculating Stokes
parameters, the pipeline next splits the data into separate images for
each nod position at each HWP angle, calculates the sum and difference
of the R and T arrays, and merges the R and T array bad pixel masks. The
algorithm uses data from the DEMODULATED DATA table to distinguish the
high and low nod positions and the HWP angle. At this stage, any pixel
for which there is a good pixel in R but not in T, or vice versa, is
noted as a “widow pixel.” In the sum image (R+T), each widow pixel’s
flux is multiplied by 2 to scale it to the correct total intensity. In
the merged bad pixel mask, widow pixels are marked with the value 1 (R
only) or 2 (T only), so that later steps may handle them appropriately.</p>
<p>The output from this step contains a large number of FITS extensions:
DATA and VAR image extensions for each of R+T and R-T for each HWP angle
and nod position, a VAR extension for uncombined R and T arrays at each
HWP angle and nod position, as well as a TABLE extension containing the
demodulated data for each HWP angle and nod position, and a single
merged BAD PIXEL MASK image. For a typical Nod-Pol observation with two
nod positions and four HWP angles, there are 8 R+T images, 8 R-T images,
32 variance images, 8 binary tables, and 1 bad pixel mask image, for 57
extensions total, including the primary HDU. The output images, other
than the bad pixel mask, are 3D cubes with dimension
64x40xN<span class="math notranslate nohighlight">\(_{chop}\)</span>, where N<span class="math notranslate nohighlight">\(_{chop}\)</span> is the number of chop
cycles at the given HWP angle.</p>
</section>
<section id="combine-images">
<h4>Combine Images<a class="headerlink" href="#combine-images" title="Link to this heading">¶</a></h4>
<p>The pipeline combines all chop cycles at a given nod position and HWP
angle by computing a robust mean of all the frames in the R+T and R-T
images. The robust mean is computed at each pixel using Chauvenet’s
criterion, iteratively rejecting pixels more than 3<span class="math notranslate nohighlight">\(\sigma\)</span> from
the mean value, by default. The associated variance values are
propagated through the mean, and the square root of the resulting value
is stored as an error image in the output.</p>
<p>The output from this step contains the same FITS extensions as in the
previous step, with all images now reduced to 2D images with dimensions
64x40, and the variance images for R+T and R-T replaced with ERROR
images. For the example above, with two nod positions and four HWP
angles, there are still 57 total extensions, including the primary HDU.</p>
</section>
<section id="subtract-beams">
<h4>Subtract Beams<a class="headerlink" href="#subtract-beams" title="Link to this heading">¶</a></h4>
<p>In this pipeline step, the sky nod positions (B beams) are subtracted
from the source nod positions (A beams) at each HWP angle and for each
set of R+T and R-T, and the resulting flux is divided by two for
normalization. The errors previously calculated in the combine step are
propagated accordingly. The output contains extensions for DATA and
ERROR images for each set, as well as variance images for R and T
arrays, a table of demodulated data for each HWP angle, and the bad
pixel mask.</p>
</section>
<section id="compute-stokes">
<span id="stokes"></span><h4>Compute Stokes<a class="headerlink" href="#compute-stokes" title="Link to this heading">¶</a></h4>
<p>From the R+T and R-T data for each HWP angle, the pipeline now computes
images corresponding to the Stokes I, Q, and U parameters for each
pixel.</p>
<p>Stokes I is computed by averaging the R+T signal over all HWP angles:</p>
<div class="math notranslate nohighlight">
\[I = \frac{1}{N} \sum_{\phi=1}^N (R+T)_{\phi},\]</div>
<p>where <span class="math notranslate nohighlight">\(N\)</span> is the number of HWP angles and <span class="math notranslate nohighlight">\((R+T)_{\phi}\)</span> is
the summed R+T flux at the HWP angle <span class="math notranslate nohighlight">\(\phi\)</span>. The associated
uncertainty in I is propagated from the previously calculated errors for
R+T:</p>
<div class="math notranslate nohighlight">
\[\sigma_I = \frac{1}{N} \sqrt{\sum_{\phi=1}^N \sigma_{R+T,\phi}^2}.\]</div>
<p>In the most common case of four HWP angles at 0, 45, 22.5, and 67.5
degrees, Stokes Q and U are computed as:</p>
<div class="math notranslate nohighlight">
\[Q = \frac{1}{2} [(R-T)_{0} - (R-T)_{45}]\]</div>
<div class="math notranslate nohighlight">
\[U = \frac{1}{2} [(R-T)_{22.5} - (R-T)_{67.5}]\]</div>
<p>where <span class="math notranslate nohighlight">\((R-T)_{\phi}\)</span> is the differential R-T flux at the HWP
angle <span class="math notranslate nohighlight">\(\phi\)</span>. Uncertainties in Q and U are propagated from the
input error values on R-T:</p>
<div class="math notranslate nohighlight">
\[\sigma_Q = \frac{1}{2} \sqrt{\sigma_{R-T,0}^2 + \sigma_{R-T,45}^2}\]</div>
<div class="math notranslate nohighlight">
\[\sigma_U = \frac{1}{2} \sqrt{\sigma_{R-T,22.5}^2 + \sigma_{R-T,67.5}^2}.\]</div>
<p>Since Stokes I, Q, and U are derived from the same data samples, they
will have non-zero covariance. For later use in error propagation, the
pipeline now calculates the covariance between Q and I
(<span class="math notranslate nohighlight">\(\sigma_{QI}\)</span>) and U and I (<span class="math notranslate nohighlight">\(\sigma_{UI}\)</span>) from the
variance in R and T as follows:</p>
<div class="math notranslate nohighlight">
\[\sigma_{QI} = \frac{1}{8} [\sigma_{R,0}^2 - \sigma_{R,45}^2 - \sigma_{T,0}^2 + \sigma_{T,45}^2]\]</div>
<div class="math notranslate nohighlight">
\[\sigma_{UI} = \frac{1}{8} [\sigma_{R,22.5}^2 - \sigma_{R,67.5}^2 - \sigma_{T,22.5}^2 + \sigma_{T,67.5}^2]\]</div>
<p>The covariance between Q and U (<span class="math notranslate nohighlight">\(\sigma_{QU}\)</span>) is zero at this
stage, since they are derived from data for different HWP angles.</p>
<p>The output from this step contains an extension for the flux and error
of each Stokes parameter, as well as the covariance images, bad pixel
mask, and a table of the demodulated data, with columns from each of the
HWP angles merged. The STOKES I flux image is in the primary HDU. For
Nod-Pol data, there will be 10 additional extensions (ERROR I, STOKES Q,
ERROR Q, STOKES U, ERROR U, COVAR Q I, COVAR U I, COVAR Q U, BAD PIXEL
MASK, TABLE DATA). For Chop-Nod imaging, only Stokes I is calculated, so
there are only 3 additional extensions (ERROR I, BAD PIXEL MASK, TABLE
DATA).</p>
</section>
<section id="update-wcs">
<h4>Update WCS<a class="headerlink" href="#update-wcs" title="Link to this heading">¶</a></h4>
<p>To associate the pixels in the Stokes parameter image with sky
coordinates, the pipeline uses FITS header keywords describing the
telescope position to calculate the reference right ascension and
declination (CRVAL1/2), the pixel scale (CDELT1/2), and the rotation
angle (CROTA2). It may also correct for small shifts in the pixel
corresponding to the instrument boresight, depending on the filter used,
by modifying the reference pixel (CRPIX1/2). These standard FITS world
coordinate system (WCS) keywords are written to the header of the
primary HDU.</p>
</section>
<section id="subtract-instrumental-polarization">
<span id="ip"></span><h4>Subtract Instrumental Polarization<a class="headerlink" href="#subtract-instrumental-polarization" title="Link to this heading">¶</a></h4>
<p>The instrument and the telescope itself may introduce some foreground
polarization to the data which must be removed to determine the
polarization from the astronomical source. The instrument team uses
measurements of the sky to characterize the introduced polarization in
reduced Stokes parameters (<span class="math notranslate nohighlight">\(q=Q/I\)</span> and <span class="math notranslate nohighlight">\(u=U/I\)</span>) for each
filter band at each pixel. The correction is then applied as</p>
<div class="math notranslate nohighlight">
\[Q' = Q - q' I\]</div>
<div class="math notranslate nohighlight">
\[U' = U - u' I\]</div>
<p>and propagated to the associated error and covariance images as</p>
<div class="math notranslate nohighlight">
\[\sigma_Q' = \sqrt{\sigma_Q^2 + (q' \sigma_I)^2 +  2q'\sigma_{QI}}\]</div>
<div class="math notranslate nohighlight">
\[\sigma_U' = \sqrt{\sigma_U^2 + (u' \sigma_I)^2 +  2u'\sigma_{UI}}\]</div>
<div class="math notranslate nohighlight">
\[\sigma_{Q'I} = \sigma_{QI} - q' \sigma_I^2\]</div>
<div class="math notranslate nohighlight">
\[\sigma_{U'I} = \sigma_{UI} - u' \sigma_I^2\]</div>
<div class="math notranslate nohighlight">
\[\sigma_{Q'U'} = -u' \sigma_{QI} - q' \sigma_{UI} + qu\sigma_I^2.\]</div>
<p>The correction is expected to be good to within <span class="math notranslate nohighlight">\(Q/I &lt; 0.6\%\)</span> and
<span class="math notranslate nohighlight">\(U/I &lt; 0.6\%\)</span>.</p>
</section>
<section id="rotate-polarization-coordinates">
<span id="rotate"></span><h4>Rotate Polarization Coordinates<a class="headerlink" href="#rotate-polarization-coordinates" title="Link to this heading">¶</a></h4>
<p>The Stokes Q and U parameters, as calculated so far, reflect
polarization angles measured in detector coordinates. After the
foreground polarization is removed, the parameters may then be rotated
into sky coordinates. The pipeline calculates a relative rotation angle,
<span class="math notranslate nohighlight">\(\alpha\)</span>, that accounts for the vertical position angle of the
instrument, the initial angle of the half-wave plate position, and an
offset position that is different for each HAWC filter. It applies the
correction to the Q and U images with a standard rotation matrix, such
that:</p>
<div class="math notranslate nohighlight">
\[Q' = cos(\alpha) Q + sin(\alpha) U\]</div>
<div class="math notranslate nohighlight">
\[U' = sin(\alpha) Q - cos(\alpha) U.\]</div>
<p>The errors and covariances become:</p>
<div class="math notranslate nohighlight">
\[\sigma_Q' = \sqrt{(cos(\alpha)\sigma_Q)^2 + (sin(\alpha) \sigma_U)^2 +  2 cos(\alpha) sin(\alpha) \sigma_{QU}}\]</div>
<div class="math notranslate nohighlight">
\[\sigma_U' = \sqrt{(sin(\alpha)\sigma_Q)^2 + (cos(\alpha) \sigma_U)^2 -  2 cos(\alpha) sin(\alpha) \sigma_{QU}}\]</div>
<div class="math notranslate nohighlight">
\[\sigma_{Q'I} = cos(\alpha) \sigma_{QI} + sin(\alpha) \sigma_{UI}\]</div>
<div class="math notranslate nohighlight">
\[\sigma_{U'I} = sin(\alpha) \sigma_{QI} - cos(\alpha) \sigma_{UI}\]</div>
<div class="math notranslate nohighlight">
\[\sigma_{Q'U'} = cos(\alpha)sin(\alpha)(\sigma_Q^2 - \sigma_U^2) + (sin^2(\alpha) - cos^2(\alpha)) \sigma_{QU}.\]</div>
</section>
<section id="correct-for-atmospheric-opacity">
<span id="calibrate"></span><h4>Correct for Atmospheric Opacity<a class="headerlink" href="#correct-for-atmospheric-opacity" title="Link to this heading">¶</a></h4>
<p>In order to combine images taken under differing atmospheric conditions,
the pipeline corrects the flux in each individual file for the estimated
atmospheric transmission during the observation, based on the altitude
and zenith angle at the time when the observation was obtained.</p>
<p>Atmospheric transmission values in each HAWC+ filter have been computed
for a range of telescope elevations and observatory altitudes
(corresponding to a range of overhead precipitable water vapor values)
using the ATRAN atmospheric modeling code, provided to the SOFIA program
by Steve Lord. The ratio of the transmission at each altitude and zenith
angle, relative to that at the reference altitude (41,000 feet) and
reference zenith angle (45 degrees), has been calculated for each filter
and fit with a low-order polynomial. The ratio appropriate for the
altitude and zenith angle of each observation is calculated from the fit
coefficients. The pipeline applies this relative opacity correction
factor directly to the flux in the Stokes I, Q, and U images, and
propagates it into the corresponding error and covariance images.</p>
</section>
<section id="calibrate-flux">
<h4>Calibrate Flux<a class="headerlink" href="#calibrate-flux" title="Link to this heading">¶</a></h4>
<p>The pipeline now converts the flux units from instrumental counts to
physical units of Jansky per pixel (Jy/pixel). For each filter band, the
instrument team determines a calibration factor in counts/Jy/pixel
appropriate to data that has been opacity-corrected to the reference
zenith angle and altitude.</p>
<p>The calibration factors are computed in a manner similar to that for
another SOFIA instrument (FORCAST), taking into account that HAWC+ is a
bolometer, not a photon-counting device. Measured photometry is compared
to the theoretical fluxes of objects (standards) whose spectra are
assumed to be known. The predicted fluxes in each HAWC+ passband are
computed by multiplying the model spectrum by the overall response curve
of the telescope and instrument system and integrating over the filter
passband. For HAWC+, the standards used to date include Uranus, Neptune,
Ceres, and Pallas. The models for Uranus and Neptune
were obtained from the Herschel project (see Mueller et al.
2016). Standard thermal models are used for Ceres and Pallas. All models
are scaled to match the distances of the objects at the time of the
observations. Calibration factors computed from these standards are then
corrected by a color correction factor based on the mean and pivot
wavelengths of each passband, such that the output flux in the
calibrated data product is that of a nominal, flat spectrum source at
the mean wavelength for the filter. See the FORCAST GO Handbook,
available from the <a class="reference external" href="https://irsa.ipac.caltech.edu/data/SOFIA/docs/instruments/handbooks/FORCAST_Handbook_for_Archive_Users_Ver1.0.pdf">SOFIA
webpage</a>,
for more details on the calibration process.</p>
<p>Raw calibration factors are computed as above by the pipeline,
for any observation marked as a flux standard (OBSTYPE=STANDARD_FLUX),
and are stored in the FITS headers of the output data product.  The
instrument team generally combines these factors across a flight series,
to determine a robust average value for each instrument configuration
and mode. The overall calibration thus determined is expected to be good
to within about 10%.</p>
<p>For science observations, the series-average calibration factor is
directly applied to the flux in each of the Stokes I, Q, and U images,
and to their associated error and covariance images:</p>
<div class="math notranslate nohighlight">
\[I' = I / f\]</div>
<div class="math notranslate nohighlight">
\[Q' = Q / f\]</div>
<div class="math notranslate nohighlight">
\[U' = U / f\]</div>
<div class="math notranslate nohighlight">
\[\sigma_Q' = \sigma_Q / f\]</div>
<div class="math notranslate nohighlight">
\[\sigma_U' = \sigma_Q / f\]</div>
<div class="math notranslate nohighlight">
\[\sigma_{QI}' = \sigma_{QI} / f^2\]</div>
<div class="math notranslate nohighlight">
\[\sigma_{UI}' = \sigma_{UI} / f^2\]</div>
<div class="math notranslate nohighlight">
\[\sigma_{QU}' = \sigma_{QU} / f^2.\]</div>
<p>where <em>f</em> is the reference calibration factor.  The systematic
error on <em>f</em> is not propagated into the error planes, but it is
stored in the ERRCALF FITS header keyword.  The calibration
factor applied is stored in the CALFCTR keyword.</p>
<p>Note that for Chop-Nod imaging data, this factor is applied after
the merge step, below.</p>
</section>
<section id="subtract-background">
<h4>Subtract Background<a class="headerlink" href="#subtract-background" title="Link to this heading">¶</a></h4>
<p>After chop and nod subtraction, some residual background noise may
remain in the flux images. After flat correction, some residual gain
variation may remain as well. To remove these, the pipeline reads in all
images in a reduction group, and then iteratively performs the following
steps:</p>
<ul class="simple">
<li><p>Smooth and combine the input Stokes I, Q, and U images</p></li>
<li><p>Compare each Stokes I image (smoothed) to the combined map to
determine any background offset or scaling</p></li>
<li><p>Subtract the offset from the input (unsmoothed) Stokes I images;
scale the input Stokes I, Q, and U images</p></li>
<li><p>Compare each smoothed Stokes Q and U images to the combined map to
determine any additional background offset</p></li>
<li><p>Subtract the Q and U offsets from the input Q and U images</p></li>
</ul>
<p>The final determined offsets (<span class="math notranslate nohighlight">\(a_I, a_Q, a_U\)</span>) and scales
(<span class="math notranslate nohighlight">\(b\)</span>) for each file are applied to the flux for each
Stokes image as follows:</p>
<div class="math notranslate nohighlight">
\[I' = (I - a_I) / b\]</div>
<div class="math notranslate nohighlight">
\[Q' = (Q - a_Q) / b\]</div>
<div class="math notranslate nohighlight">
\[U' = (U - a_U) / b\]</div>
<p>and are propagated into the associated error and covariance images
appropriately.</p>
</section>
<section id="rebin-images">
<h4>Rebin Images<a class="headerlink" href="#rebin-images" title="Link to this heading">¶</a></h4>
<p>In polarimetry, it is sometimes useful to bin several pixels together
to increase signal-to-noise, at the cost of decreased resolution. The
chop-nod pipeline provides an optional step to perform this binning
on individual images, prior to merging them together into a single map.</p>
<p>The Stokes I, Q, and U images are divided into blocks of a specified bin
width, then each block is summed over.  The summed flux is scaled to
account for missing pixels within the block, by the factor:</p>
<div class="math notranslate nohighlight">
\[f' = f (n_{pix} / n_{valid})\]</div>
<p>where <span class="math notranslate nohighlight">\(n_{pix}\)</span> is the number of pixels in a block, and
<span class="math notranslate nohighlight">\(n_{valid}\)</span> is the number of valid pixels within the block. The
error and covariance images are propagated to match. The WCS keywords
in the FITS header are also updated to match the new data array.</p>
<p>By default, no binning is performed by the pipeline.  The additional
processing is generally performed only on request for particular
science cases.</p>
</section>
<section id="merge-images">
<span id="id2"></span><h4>Merge Images<a class="headerlink" href="#merge-images" title="Link to this heading">¶</a></h4>
<p>All steps up until this point produce an output file for each input file
taken at each telescope dither position, without changing the
pixelization of the input data. To combine files taken at separate
locations into a single map, the pipeline resamples the flux from each
onto a common grid, defined such that North is up and East is to the
left. First, the WCS from each input file is used to determine the sky
location of all the input pixels. Then, for each pixel in the output
grid, the algorithm considers all input pixels within a given radius
that are not marked as bad pixels. It weights the input pixels by a
Gaussian function of their distance from the output grid point and,
optionally, their associated errors. The value at the output grid pixel
is the weighted average of the input pixels within the considered
window. The output grid may subsample the input pixels: by default,
there are 4 output pixels for each input pixel. For flux conservation,
the output flux is multiplied by the ratio of the output pixel area to
the input pixel area.</p>
<p>The error maps output by this algorithm are calculated from the input
variances for the pixels involved in each weighted average. That is, the
output fluxes from N input pixels are:</p>
<div class="math notranslate nohighlight">
\[I' =  \frac{\sum_{i}^N w_{i,I} I_i}{w_{tot,I}}\]</div>
<div class="math notranslate nohighlight">
\[Q' =  \frac{\sum_{i}^N w_{i,Q} Q_i}{w_{tot,Q}}\]</div>
<div class="math notranslate nohighlight">
\[U' =  \frac{\sum_{i}^N w_{i,U} U_i}{w_{tot,U}}\]</div>
<p>and the output errors and covariances are</p>
<div class="math notranslate nohighlight">
\[\sigma_I' = \frac{\sqrt{\sum_{i}^N (w_{i,I} \sigma_{i,I})^2}}{w_{tot,I}}\]</div>
<div class="math notranslate nohighlight">
\[\sigma_Q' = \frac{\sqrt{\sum_{i}^N (w_{i,Q} \sigma_{i,Q})^2}}{w_{tot,Q}}\]</div>
<div class="math notranslate nohighlight">
\[\sigma_U' = \frac{\sqrt{\sum_{i}^N (w_{i,U} \sigma_{i,U})^2}}{w_{tot,U}}\]</div>
<div class="math notranslate nohighlight">
\[\sigma_{QI}' = \frac{\sum_{i}^N w_{i,Q} w_{i,I}\sigma_{i,QI}}{w_{tot,Q}w_{tot,I}}\]</div>
<div class="math notranslate nohighlight">
\[\sigma_{UI}' = \frac{\sum_{i}^N w_{i,U} w_{i,I}\sigma_{i,UI}}{w_{tot,U}w_{tot,I}}\]</div>
<div class="math notranslate nohighlight">
\[\sigma_{QU}' = \frac{\sum_{i}^N w_{i,Q} w_{i,U}\sigma_{i,QU}}{w_{tot,Q}w_{tot,U}}\]</div>
<p>where <span class="math notranslate nohighlight">\(w_i\)</span> is the pixel weight and <span class="math notranslate nohighlight">\(w_{tot}\)</span> is the sum of
the weights of all input pixels.</p>
<p>As of HAWC DRP v2.4.0, the distance-weighted input pixels within the fit
radius may optionally be fit by a low-order polynomial surface, rather than
a weighted average. In this case, each output pixel value is the value of
the local polynomial fit, evaluated at that grid location.  Errors and
covariances are propagated similarly.</p>
<p>The output from this step is a single FITS file, containing a flux and
error image for each of Stokes I, Q, and U, as well as the Stokes
covariance images. An image mask is also produced, which represents how
many input pixels went into each output pixel. Because of the weighting
scheme, the values in this mask are not integers. A data table
containing demodulated data merged from all input tables is also
attached to the file with extension name MERGED DATA.</p>
</section>
<section id="compute-vectors">
<span id="vectors"></span><h4>Compute Vectors<a class="headerlink" href="#compute-vectors" title="Link to this heading">¶</a></h4>
<p>Using the Stokes I, Q, and U images, the pipeline now computes the
polarization percentage (<span class="math notranslate nohighlight">\(p\)</span>) and angle (<span class="math notranslate nohighlight">\(\theta\)</span>) and their
associated errors (<span class="math notranslate nohighlight">\(\sigma\)</span>) in the standard way. For the
polarization angle <span class="math notranslate nohighlight">\(\theta\)</span> in degrees:</p>
<div class="math notranslate nohighlight">
\[\theta = \frac{90}{\pi} arctan\Big(\frac{U}{Q}\Big)\]</div>
<div class="math notranslate nohighlight">
\[\sigma_\theta = \frac{90}{\pi (Q^2 + U^2)} \sqrt{(U\sigma_Q)^2 + (Q\sigma_U)^2 - 2 Q U \sigma_{QU}}.\]</div>
<p>The percent polarization (<span class="math notranslate nohighlight">\(p\)</span>) and its error are calculated as</p>
<div class="math notranslate nohighlight">
\[p = 100 \sqrt{\Big(\frac{Q}{I}\Big)^2 + \Big(\frac{U}{I}\Big)^2}\]</div>
<div class="math notranslate nohighlight">
\[\sigma_p = \frac{100}{I} \sqrt{\frac{1}{(Q^2 + U^2)} \Big[(Q \sigma_Q)^2 + (U \sigma_U)^2 + 2 Q U \sigma_{QU}\Big] + \Big[\Big(\frac{Q}{I}\Big)^2 + \Big(\frac{U}{I}\Big)^2\Big] \sigma_I^2 - 2 \frac{Q}{I}\sigma_{QI} - 2 \frac{U}{I} \sigma_{UI}}.\]</div>
<p>The debiased polarization percentage (<span class="math notranslate nohighlight">\(p'\)</span>)is also calculated, as:</p>
<div class="math notranslate nohighlight">
\[p' = \sqrt{p^2 - \sigma_p^2}.\]</div>
<p>Each of the <span class="math notranslate nohighlight">\(\theta\)</span>, <span class="math notranslate nohighlight">\(p\)</span>, and <span class="math notranslate nohighlight">\(p'\)</span> maps and their
error images are stored as separate extensions in the output from this
step, which is the final output from the pipeline for Nod-Pol data. This
file will have 19 extensions, including the primary HDU, with extension
names, types, and numbers as follows:</p>
<ul class="simple">
<li><p>STOKES I: primary HDU, image, extension 0</p></li>
<li><p>ERROR I: image, extension 1</p></li>
<li><p>STOKES Q: image, extension 2</p></li>
<li><p>ERROR Q: image, extension 3</p></li>
<li><p>STOKES U: image, extension 4</p></li>
<li><p>ERROR U: image, extension 5</p></li>
<li><p>IMAGE MASK: image, extension 6</p></li>
<li><p>PERCENT POL: image, extension 7</p></li>
<li><p>DEBIASED PERCENT POL: image, extension 8</p></li>
<li><p>ERROR PERCENT POL: image, extension 9</p></li>
<li><p>POL ANGLE: image, extension 10</p></li>
<li><p>ROTATED POL ANGLE: image, extension 11</p></li>
<li><p>ERROR POL ANGLE: image, extension 12</p></li>
<li><p>POL FLUX: image, extension 13</p></li>
<li><p>ERROR POL FLUX: image, extension 14</p></li>
<li><p>DEBIASED POL FLUX: image, extension 15</p></li>
<li><p>MERGED DATA: table, extension 16</p></li>
<li><p>POL DATA: table, extension 17</p></li>
<li><p>FINAL POL DATA: table, extension 18</p></li>
</ul>
<p>The final two extensions contain table representations of the
polarization values for each pixel, as an alternate representation of
the <span class="math notranslate nohighlight">\(\theta\)</span>, <span class="math notranslate nohighlight">\(p\)</span>, and <span class="math notranslate nohighlight">\(p'\)</span> maps. The FINAL POL DATA
table (extension 18) is a subset of the POL DATA table (extension 17),
with data quality cuts applied.</p>
</section>
</section>
<section id="scan-reduction-algorithms">
<span id="scanmap"></span><h3>Scan Reduction Algorithms<a class="headerlink" href="#scan-reduction-algorithms" title="Link to this heading">¶</a></h3>
<p>This section covers the main algorithms used to reduce Scan mode data.
See the flowchart in <a class="reference internal" href="#scan-flowchart"><span class="std std-numref">Fig. 104</span></a> for an overview of the
iterative process.  In this description, “channels” refer to detector
pixels, and “frames” refer to time samples read out from the detector
pixels during the scan observation.</p>
<figure class="align-default" id="scan-flowchart">
<a class="reference internal image-reference" href="../../../_images/scan_flowchart.png"><img alt="Flowchart with three main sections: (1) Set up: define observation (2) Iterate: refine gains and source map, (3) Output: final source map." src="../../../_images/scan_flowchart.png" style="height: 800px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 104 </span><span class="caption-text">Scan data reduction flowchart</span><a class="headerlink" href="#scan-flowchart" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<section id="signal-structure">
<h4>Signal Structure<a class="headerlink" href="#signal-structure" title="Link to this heading">¶</a></h4>
<p>Scan map reconstruction is based on the assumption that the measured
data (<span class="math notranslate nohighlight">\(X_{ct}\)</span>) for detector <span class="math notranslate nohighlight">\(c\)</span>, recorded at time <span class="math notranslate nohighlight">\(t\)</span>,
is the superposition of various signal components and essential (not
necessarily white) noise <span class="math notranslate nohighlight">\(n_{ct}\)</span>:</p>
<div class="math notranslate nohighlight">
\[X_{ct} = D_{ct} + g_{(1),c} C_{(1),t} + ... + g_{(n),c} C_{(n),t} + G_c M_{ct}^{xy} S_{xy} + n_{ct}\]</div>
<p>We can model the measured detector timestreams via a number of
appropriate parameters, such as 1/f drifts (<span class="math notranslate nohighlight">\(D_{ct}\)</span>), <span class="math notranslate nohighlight">\(n\)</span>
correlated noise components (<span class="math notranslate nohighlight">\(C_{(1),t} ... C_{(n),t}\)</span>) and
channel responses to these (gains, <span class="math notranslate nohighlight">\(g_{(1),c} ... g_{(n),c}\)</span>), and
the observed source structure (<span class="math notranslate nohighlight">\(S_{xy}\)</span>). We can derive
statistically sound estimates (such as maximum-likelihood or robust
estimates) for these parameters based on the measurements themselves. As
long as our model is representative of the physical processes that
generate the signals, and sufficiently complete, our derived parameters
should be able to reproduce the measured data with the precision of the
underlying limiting noise.</p>
<p>Below is a summary of the assumed principal model parameters, in general:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(X_{ct}\)</span>: The raw timestream of channel c, measured at time t.</p></li>
<li><p><span class="math notranslate nohighlight">\(D_{ct}\)</span>: The 1/f drift value of channel c at time t.</p></li>
<li><p><span class="math notranslate nohighlight">\(g_{(1),c} ... g_{(n),c}\)</span>: Channel <span class="math notranslate nohighlight">\(c\)</span> gain (response) to
correlated signals (for modes 1 through <span class="math notranslate nohighlight">\(n\)</span>).</p></li>
<li><p><span class="math notranslate nohighlight">\(C_{(1),t} ... C_{(n),t}\)</span>: Correlated signals (for modes 1
through <span class="math notranslate nohighlight">\(n\)</span>) at time <span class="math notranslate nohighlight">\(t\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(G_c\)</span>: The point source gain of channel <span class="math notranslate nohighlight">\(c\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(M_{ct}^{xy}\)</span>: Scanning pattern, mapping a sky position
<span class="math notranslate nohighlight">\(\{x,y\}\)</span> into a sample of channel <span class="math notranslate nohighlight">\(c\)</span> at time <span class="math notranslate nohighlight">\(t\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(S_{xy}\)</span>: Actual 2D source flux at position <span class="math notranslate nohighlight">\(\{x,y\}\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(n_{ct}\)</span>: Essential limiting noise in channel c at time t.</p></li>
</ul>
</section>
<section id="sequential-incremental-modeling-and-iterations">
<h4>Sequential Incremental Modeling and Iterations<a class="headerlink" href="#sequential-incremental-modeling-and-iterations" title="Link to this heading">¶</a></h4>
<p>The pipeline’s approach is to solve for each term separately, and
sequentially, rather than trying to do a brute-force matrix inversion in
a single step. Sequential modeling works on the assumption that each term
can be considered independently from one another. To a large degree this is
justified, as many of the signals produce more or less orthogonal imprints
in the data (e.g. you cannot easily mistake correlated sky response seen
by all channels with a per-channel DC offset). As such, from the point
of view of each term, the other terms represent but an increased level
of noise. As the terms all take turns in being estimated (usually from
bright to faint) this model confusion “noise” goes away, especially with
multiple iterations.</p>
<p>Even if the terms are not perfectly orthogonal to one another, and have
degenerate flux components, the sequential approach handles this degeneracy
naturally. Degenerate fluxes between a pair of terms will tend to end up
in the term that is estimated first. Thus, the ordering of the
estimation sequence provides a control on handling degeneracies in a
simple and intuitive manner.</p>
<p>A practical trick for efficient implementation is to replace the raw
timestream with the unmodeled residuals
<span class="math notranslate nohighlight">\(X_{ct} \rightarrow R_{ct}\)</span> and let modeling steps produce
incremental updates to the model parameters. Every time a model
parameter is updated, its incremental imprint is removed from the
residual timestream (a process we shall refer to as synchronization).</p>
<p>With each iteration, the incremental changes to the parameters become
more insignificant, and the residual will approach the limiting noise of
the measurement.</p>
</section>
<section id="initialization-and-scan-validation">
<h4>Initialization and Scan Validation<a class="headerlink" href="#initialization-and-scan-validation" title="Link to this heading">¶</a></h4>
<p>Prior to beginning iterative solution for the model components, the
pipeline reads in the raw FITS table, assigns positional offsets to
every detector channel, and sky coordinates to every time frame in the
scan.</p>
<p>The input timestream is then checked for inconsistencies.
For example, HAWC data is prone to discontinuous jumps in flux levels.
The pipeline will search the timestream for flux jumps, and flag or fix
jump-related artifacts as necessary.  The pipeline also checks for gaps in
the astrometry data in the timestream, gyro drifts over the course of
the observation,</p>
<p>By default, the pipeline also clips extreme scanning velocities using, by
default, a set minimum and maximum value for each instrument.
The default settings still include a broad range of speeds, so
images can sometimes be distorted by low or high speeds causing too
little or too much exposure on single pixels. To fix this, the pipeline
can optionally remove frames from the beginning or end of the observation,
or sigma-clip the telescope speeds to a tighter range.</p>
<p>The size of the output source map is determined from the mapped area on
the sky, and a configurable output pixel grid size.  This map is updated
on each iteration, with the derived source model.</p>
<p>Gains for all detector pixels are initialized with a reference gain map,
derived from earlier observations.  These initial gains serve as a starting
place for the iterative model and allow for flagging and removal of channels
known to be bad prior to iterating.</p>
</section>
<section id="dc-offset-and-1-f-drift-removal">
<h4>DC Offset and 1/f Drift Removal<a class="headerlink" href="#dc-offset-and-1-f-drift-removal" title="Link to this heading">¶</a></h4>
<p>For 1/f drifts, consider only the term:</p>
<div class="math notranslate nohighlight">
\[R_{ct} \approx \delta D_{c\tau}\]</div>
<p>where <span class="math notranslate nohighlight">\(\delta D_{c\tau}\)</span> is the 1/f channel drift value for
<span class="math notranslate nohighlight">\(t\)</span> between <span class="math notranslate nohighlight">\(\tau\)</span> and <span class="math notranslate nohighlight">\(\tau + T\)</span>, for a 1/f time
window of <span class="math notranslate nohighlight">\(T\)</span> samples. That is, we simply assume that the
residuals are dominated by an unmodeled 1/f drift increment
<span class="math notranslate nohighlight">\(\delta D_{c\tau}\)</span>. Note that detector DC offsets can be treated
as a special case with <span class="math notranslate nohighlight">\(\tau = 0\)</span>, and <span class="math notranslate nohighlight">\(T\)</span> equal to the
number of detector samples in the analysis.</p>
<p>We can construct a <span class="math notranslate nohighlight">\(\chi^2\)</span> measure, as:</p>
<div class="math notranslate nohighlight">
\[\chi^2 = \sum_{c,t = \tau}^{t=\tau + T} w_{ct} (R_{ct} - \delta D_{ct})^2\]</div>
<p>where <span class="math notranslate nohighlight">\(w_{ct} = \sigma_{ct}^{-2}\)</span> is the proper noise-weight
associated with each datum. The pipeline furthermore assumes that the noise
weight of every sample <span class="math notranslate nohighlight">\(w_{ct}\)</span> can be separated into the product
of a channel weight <span class="math notranslate nohighlight">\(w_c\)</span> and a time weight <span class="math notranslate nohighlight">\(w_t\)</span>, i.e.
<span class="math notranslate nohighlight">\(w_{ct} = w_c \cdot w_t\)</span>. This assumption is identical to that of
separable noise (<span class="math notranslate nohighlight">\(\sigma_{ct} = \sigma_c \cdot \sigma_t\)</span>). Then,
by setting the <span class="math notranslate nohighlight">\(\chi^2\)</span> minimizing condition
<span class="math notranslate nohighlight">\(\partial \chi^2 / \partial(\delta D_{ct}) = 0\)</span>, we arrive at the
maximum-likelihood incremental update:</p>
<div class="math notranslate nohighlight">
\[\delta D_{c\tau} = \frac{\sum\limits_{t=\tau}^{\tau + T} w_t R_{ct}}{\sum\limits_{t=\tau}^{\tau + T} w_t}\]</div>
<p>Note that each sample (<span class="math notranslate nohighlight">\(R_{ct}\)</span>) contributes a fraction:</p>
<div class="math notranslate nohighlight">
\[p_{ct} = w_t / \sum_{t=\tau}^{\tau + T} w_t\]</div>
<p>to the estimate of the single parameter <span class="math notranslate nohighlight">\(\delta D_{c\tau}\)</span>. In
other words, this is how much that parameter is <em>dependent</em> on each data
point. Above all, <span class="math notranslate nohighlight">\(p_{ct}\)</span> is a fair measure of the fractional
degrees of freedom lost from each datum, due to modeling of the 1/f
drifts. We will use this information later, when estimating proper noise
weights.</p>
<p>Note, also, that we may replace the maximum-likelihood estimate for the
drift parameter with any other statistically sound estimate (such as a
weighted median), and it will not really change the dependence, as we
are still measuring the same quantity, from the same data, as with the
maximum-likelihood estimate. Therefore, the dependence calculation
remains a valid and fair estimate of the degrees of freedom lost,
regardless of what statistical estimator is used.</p>
<p>The removal of 1/f drifts must be mirrored in the correlated signals
also if gain solutions are to be accurate.</p>
</section>
<section id="correlated-noise-removal-and-gain-estimation">
<h4>Correlated Noise Removal and Gain Estimation<a class="headerlink" href="#correlated-noise-removal-and-gain-estimation" title="Link to this heading">¶</a></h4>
<p>For the correlated noise (mode <span class="math notranslate nohighlight">\(i\)</span>), we shall consider only the
term with the incremental signal parameter update:</p>
<div class="math notranslate nohighlight">
\[R_{ct} = g_{(i),c} \delta C_{(i),t} + ...\]</div>
<p>Initially, we can assume <span class="math notranslate nohighlight">\(C_{(i),t}\)</span> as well as
<span class="math notranslate nohighlight">\(g_{(i),c} = 1\)</span>, if better values of the gain are not
independently known at the start. Accordingly, the <span class="math notranslate nohighlight">\(\chi^2\)</span>
becomes:</p>
<div class="math notranslate nohighlight">
\[\chi^2 = \sum_c w_{ct}(R_{ct} - g_{(i),c} \delta C_{(i),t})^2.\]</div>
<p>Setting the <span class="math notranslate nohighlight">\(\chi^2\)</span> minimizing condition with respect to
<span class="math notranslate nohighlight">\(\delta C_{(i),t}\)</span> yields:</p>
<div class="math notranslate nohighlight">
\[\delta C_{(i),t} =  \frac{\sum\limits_c w_c g_{(i),c} R_{ct}}{\sum\limits_c w_c g_{(i),c}^2}.\]</div>
<p>The dependence of this parameter on <span class="math notranslate nohighlight">\(R_{ct}\)</span> is:</p>
<div class="math notranslate nohighlight">
\[p_{ct} = w_c g_{(i),c}^2 / \sum_{c} w_c  g_{(i),c}^2\]</div>
<p>After we update <span class="math notranslate nohighlight">\(C_{(i)}\)</span> (the correlated noise model for mode
<span class="math notranslate nohighlight">\(i\)</span>) for all frames <span class="math notranslate nohighlight">\(t\)</span>, we can update the gain response as
well in an analogous way, if desired. This time, consider the residuals
due to the unmodeled gain increment:</p>
<div class="math notranslate nohighlight">
\[R_{ct} = \delta g_{(i),c} C_{(i),t} + ...\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[\chi^2 = \sum_t w_{ct}(R_{ct} - \delta g_{(i),c} C_{(i),t})^2\]</div>
<p>Minimizing it with respect to <span class="math notranslate nohighlight">\(\delta g_{(i),c}\)</span> yields:</p>
<div class="math notranslate nohighlight">
\[\delta g_{(i),c} =  \frac{\sum\limits_t w_t C_{(i),t} R_{ct}}{\sum\limits_t w_t C_{(i),t}^2}\]</div>
<p>which has a parameter dependence:</p>
<div class="math notranslate nohighlight">
\[p_{ct} = w_t C_{(i),t}^2 / \sum_{t} w_t  C_{(i),t}^2\]</div>
<p>Because the signal <span class="math notranslate nohighlight">\(C_t\)</span> and gain <span class="math notranslate nohighlight">\(g_c\)</span> are a product in our
model, scaling <span class="math notranslate nohighlight">\(C_t\)</span> by some factor <span class="math notranslate nohighlight">\(X\)</span>, while dividing
<span class="math notranslate nohighlight">\(g_c\)</span> by the same factor will leave the product intact. Therefore,
our solutions for <span class="math notranslate nohighlight">\(C_t\)</span> and <span class="math notranslate nohighlight">\(g_c\)</span> are not unique. To remove
this inherent degeneracy, it is practical to enforce a normalizing
condition on the gains, such that the mean gain <span class="math notranslate nohighlight">\(\mu(g_c) = 1\)</span>, by
construct. The pipeline uses a robust mean measure for gain normalization to
produce reasonable comparisons under various pathologies, such as when
most gains are zero, or when a few gains are very large compared to the
others.</p>
</section>
<section id="noise-weighting">
<h4>Noise Weighting<a class="headerlink" href="#noise-weighting" title="Link to this heading">¶</a></h4>
<p>Once we model out the dominant signal components, such that the
residuals are starting to approach a reasonable level of noise, we can
turn our attention to determining proper noise weights. In its simplest
form, we can determine the weights based on the mean observed variance
of the residuals, normalized by the remaining degrees of freedom in the
data:</p>
<div class="math notranslate nohighlight">
\[w_c = \eta_c \frac{N_{(t),c} - P_c}{\sum\limits_t w_t R_{ct}^2}\]</div>
<p>where <span class="math notranslate nohighlight">\(N_{(t),c}\)</span> is the number of unflagged data points (time
samples) for channel <span class="math notranslate nohighlight">\(c\)</span>, and <span class="math notranslate nohighlight">\(P_c\)</span> is the total number of
parameters derived from channel <span class="math notranslate nohighlight">\(c\)</span>. The scalar value
<span class="math notranslate nohighlight">\(\eta_c\)</span> is the overall spectral filter pass correction for
channel <span class="math notranslate nohighlight">\(c\)</span>, which is 1 if the data was
not spectrally filtered, and 0 if the data was maximally filtered (i.e.
all information is removed). Thus typical <span class="math notranslate nohighlight">\(\eta_c\)</span> values will
range between 0 and 1 for rejection filters, or can be greater than 1
for enhancing filters. We determine time-dependent weights as:</p>
<div class="math notranslate nohighlight">
\[w_t = \frac{N_{(c),t} - P_t}{\sum\limits_c w_c R_{ct}^2}\]</div>
<p>Similar to the above, here <span class="math notranslate nohighlight">\(N_{(c),t}\)</span> is the number of unflagged
channel samples in frame <span class="math notranslate nohighlight">\(t\)</span>, while <span class="math notranslate nohighlight">\(P_t\)</span> is the total
number of parameters derived from frame <span class="math notranslate nohighlight">\(t\)</span>. Once again, it is
practical to enforce a normalizing condition of setting the mean time
weight to unity, i.e. <span class="math notranslate nohighlight">\(\mu(w_t) = 1\)</span>. This way, the channel
weights <span class="math notranslate nohighlight">\(w_c\)</span> have natural physical weight units, corresponding to
<span class="math notranslate nohighlight">\(w_c = 1/\sigma_c^2\)</span>.</p>
<p>The total number of parameters derived from each channel, and frame, are
simply the sum, over all model parameters <span class="math notranslate nohighlight">\(m\)</span>, of all the
parameter dependencies <span class="math notranslate nohighlight">\(p_{ct}\)</span> we calculated for them. That is,</p>
<div class="math notranslate nohighlight">
\[P_c = \sum_m \sum_t p_{(m),ct}\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[P_t = \sum_m \sum_c p_{(m),ct}\]</div>
<p>Getting these lost-degrees-of-freedom measures right is critical for
the stability of the solutions in an iterated framework. Even slight
biases in <span class="math notranslate nohighlight">\(p_{ct}\)</span> can grow exponentially with iterations, leading
to divergent solutions, which may manifest as over-flagging or as
extreme mapping artifacts.</p>
</section>
<section id="despiking">
<h4>Despiking<a class="headerlink" href="#despiking" title="Link to this heading">¶</a></h4>
<p>After deriving fair noise weights, we can try to identify outliers in
the data (glitches and spikes) and flag them for removal from further
analysis. By default, the pipeline uses differential deviations between
neighboring data points to identify outlier values.</p>
</section>
<section id="spectral-conditioning">
<h4>Spectral Conditioning<a class="headerlink" href="#spectral-conditioning" title="Link to this heading">¶</a></h4>
<p>Ideally, detectors would have featureless white noise spectra (at least
after the 1/f noise is treated by the drift removal). In practice, that
is rarely the case. Spectral features are bad because (a) they produce
mapping features/artifacts (such as “striping”), and because (b) they
introduce a covariant noise term between map points that is not easily
represented by the output. It is therefore desirable to “whiten” the
residual noise whenever possible, to mitigate both these effects.</p>
<p>Noise whitening starts with measuring the effective noise spectrum in a
temporal window, significantly shorter than the integration on which it
is measured. In the pipeline, the temporal window is designed to match the 1/f
stability timescale <span class="math notranslate nohighlight">\(T\)</span> chosen for the drift removal, since the
drift removal will wipe out all features on longer timescales. With the
use of such a spectral window, we may derive a lower-resolution averaged
power-spectrum for each channel. The pipeline then identifies the white noise
level, either as the mean (RMS) scalar amplitude over a specified range
of frequencies, or automatically, over an appropriate frequency range
occupied by the point-source signal as a result of the scanning motion.</p>
<p>Then, the pipeline will look for significant outliers in each spectral bin,
above a specified level (and optimally below a critical level too), and
create a real-valued spectral filter profile <span class="math notranslate nohighlight">\(\phi_{cf}\)</span> for each
channel <span class="math notranslate nohighlight">\(c\)</span> and frequency bin <span class="math notranslate nohighlight">\(f\)</span> to correct these
deviations.</p>
<p>There are other filters that can be applied also, such as notch filters,
or a motion filter to reject responses synchronous to the dominant
telescope motion. In the end, every one of these filters is represented
by an appropriate scalar filter profile <span class="math notranslate nohighlight">\(\phi_{cf}\)</span>, so the
discussion remains unchanged.  Only the whitening filter is used by default
for HAWC data.</p>
<p>Once a filter profile is determined, we apply the filter by first
calculating a rejected signal:</p>
<div class="math notranslate nohighlight">
\[\varrho_{ct} = F^{-1}[(1-\phi_{cf}) \hat{R}_{cf}]\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{R}_{cf}\)</span> is the Fourier transform of <span class="math notranslate nohighlight">\(R_{ct}\)</span>,
using the weighting function provided by <span class="math notranslate nohighlight">\(w_t\)</span>, and <span class="math notranslate nohighlight">\(F^{-1}\)</span>
denotes the inverse Fourier Transform from the spectral domain back into
the timestream. The rejected signals are removed from the residuals as:</p>
<div class="math notranslate nohighlight">
\[R_{ct} \rightarrow R_{ct} - \varrho_{ct}\]</div>
<p>The overall filter pass <span class="math notranslate nohighlight">\(\eta_c\)</span> for channel <span class="math notranslate nohighlight">\(c\)</span>, can be
calculated as:</p>
<div class="math notranslate nohighlight">
\[\eta_c = \frac{\sum\limits_f \phi_{cf}^2}{N_f}\]</div>
<p>where <span class="math notranslate nohighlight">\(N_f\)</span> is the number of spectral bins in the profile
<span class="math notranslate nohighlight">\(\phi_{cf}\)</span>. The above is simply a measure of the white-noise
power fraction retained by the filter, which according to Parseval’s
theorem, is the same as the power fraction retained in the timestream,
or the scaling of the observed noise variances as a result of filtering.</p>
</section>
<section id="map-making">
<h4>Map Making<a class="headerlink" href="#map-making" title="Link to this heading">¶</a></h4>
<p>The mapping algorithm for the output source model implements a nearest-pixel method,
whereby each data point is mapped entirely into the map pixel that falls
nearest to the given detector channel <span class="math notranslate nohighlight">\(c\)</span>, at a given time
<span class="math notranslate nohighlight">\(t\)</span>. Here,</p>
<div class="math notranslate nohighlight">
\[\delta S_{xy} = \frac{\sum\limits_{ct} M_{xy}^{ct} w_c w_t \varkappa_c G_c R_{ct}}{\sum\limits_{ct} M_{xy}^{ct} w_c w_t \varkappa_c^2 G_c^2}\]</div>
<p>where <span class="math notranslate nohighlight">\(M_{xy}^{ct}\)</span> associates each sample <span class="math notranslate nohighlight">\(\{c,t\}\)</span>
uniquely with a map pixel <span class="math notranslate nohighlight">\(\{x,y\}\)</span>, and is effectively the
transpose of the mapping function defined earlier. <span class="math notranslate nohighlight">\(\varkappa_c\)</span>
is the point-source filtering (pass) fraction of the pipeline. It can be
thought of as a single scalar version of the transfer function. Its
purpose is to measure how isolated point-source peaks respond to the
various reduction steps, and correct for it. When done correctly, point
source peaks will always stay perfectly cross-calibrated between
different reductions, regardless of what reduction steps were used in
each case. More generally, a reasonable quality of cross-calibration (to
within 10%) extends to compact and slightly extended sources (typically
up to about half of the field-of-view (FoV) in size). While corrections
for more extended structures (<span class="math notranslate nohighlight">\(\geq\)</span> FoV) are possible to a
certain degree, they come at the price of steeply increasing noise at
the larger scales.</p>
<p>The map-making algorithm should skip over any data that is unsuitable
for quality map-making (such as too-fast scanning that may smear a
source). For formal treatment, we assume that <span class="math notranslate nohighlight">\(M_{ct}^{xy} = 0\)</span>
for any troublesome data.</p>
<p>Calculating the precise dependence of each map point <span class="math notranslate nohighlight">\(S_{xy}\)</span> on
the timestream data <span class="math notranslate nohighlight">\(R_{ct}\)</span> is computationally costly to the
extreme. Instead, the pipeline gets by with the approximation:</p>
<div class="math notranslate nohighlight">
\[p_{ct} \approx N_{xy} \cdot \frac{w_t}{\sum\limits_t w_t} \cdot \frac{w_c \varkappa_c^2 G_c}{\sum\limits_c w_c \varkappa_c^2 G_c^2}\]</div>
<p>This approximation is good as long as most map points are covered with
a representative collection of pixels, and as long as the pixel
sensitivities are more or less uniformly distributed over the field of
view.</p>
<p>We can also calculate the flux uncertainty in the map
<span class="math notranslate nohighlight">\(\sigma_{xy}\)</span> at each point <span class="math notranslate nohighlight">\(\{x,y\}\)</span> as:</p>
<div class="math notranslate nohighlight">
\[\sigma_{xy}^2 = 1 / \sum_{ct} M_{xy}^{ct} w_c w_t \varkappa_c^2 G_c^2\]</div>
<p>Source models are first derived from each input scan separately. These
may be despiked and filtered, if necessary, before added to the global
increment with an appropriate noise weight (based on the observed map
noise) if source weighting is desired.</p>
<p>Once the global increment is complete, we can add it to the prior source
model <span class="math notranslate nohighlight">\(S_{xy}^{r(0)}\)</span> and subject it to further conditioning,
especially in the intermediate iterations. Conditioning operations may
include smoothing, spatial filtering, redundancy flagging, noise or
exposure clipping, signal-to-noise blanking, or explicit source masking.
Once the model is processed into a finalized <span class="math notranslate nohighlight">\(S_{xy}'\)</span>, we
synchronize the incremental change
<span class="math notranslate nohighlight">\(\delta S_{xy}' = S_{xy}' - S_{xy}^{r(0)}\)</span> to the residuals:</p>
<div class="math notranslate nohighlight">
\[R_{ct} \rightarrow R_{ct} - M_{ct}^{xy} (\delta G_c S_{xy}^{r(0)} + G_c \delta S_{xy}')\]</div>
<p>Note, again, that <span class="math notranslate nohighlight">\(\delta S_{xy}' \neq \delta S_{xy}\)</span>. That is,
the incremental change in the conditioned source model is not the same
as the raw increment derived above. Also, since the source gains
<span class="math notranslate nohighlight">\(G_c\)</span> may have changed since the last source model update, we must
also re-synchronize the prior source model <span class="math notranslate nohighlight">\(S_{xy}^{(0)}\)</span> with the
incremental source gain changes <span class="math notranslate nohighlight">\(\delta G_c\)</span> (first term inside
the brackets).</p>
<p>The pipeline operates under the assumption that the point-source
gains <span class="math notranslate nohighlight">\(G_c\)</span> of the detectors are closely related to the observed
sky-noise gains <span class="math notranslate nohighlight">\(g_c\)</span> derived from the correlated noise for all
channels. Specifically, it treats the point-source gains as the
product:</p>
<div class="math notranslate nohighlight">
\[G_c = \varepsilon_c g_c g_s e^{-\tau}\]</div>
<p>where <span class="math notranslate nohighlight">\(\varepsilon_c\)</span> is the point-source coupling efficiency. It
measures the ratio of point-source gains to sky-noise gains (or extended
source gains). Generally, the pipeline will assume <span class="math notranslate nohighlight">\(\varepsilon_c = 1\)</span>,
unless these values are measured and loaded during the initial scan validation
sequence.</p>
<p>Optionally, the pipeline can also derive <span class="math notranslate nohighlight">\(\varepsilon_c\)</span> from
the observed response to a source structure, provided the scan pattern
is sufficient to move significant source flux over all detectors. The
source gains also include a correction for atmospheric attenuation, for
an optical depth <span class="math notranslate nohighlight">\(\tau\)</span>, in-band and in the line of sight.</p>
</section>
<section id="point-source-flux-corrections">
<h4>Point-Source Flux Corrections<a class="headerlink" href="#point-source-flux-corrections" title="Link to this heading">¶</a></h4>
<p>We mentioned point-source corrections in the section above; here, we
explain how these are calculated. First, consider drift removal. Its
effect on point source fluxes is a reduction by a factor:</p>
<div class="math notranslate nohighlight">
\[\varkappa_{D,c} \approx 1 - \frac{\tau_{pnt}}{T}\]</div>
<p>In terms of the 1/f drift removal time constant <span class="math notranslate nohighlight">\(T\)</span> and the
typical point-source crossing time <span class="math notranslate nohighlight">\(\tau_{pnt}\)</span>. Clearly, the
effect of 1/f drift removal is smaller the faster one scans across the
source, and becomes negligible when <span class="math notranslate nohighlight">\(\tau_{pnt} \ll T\)</span>.</p>
<p>The effect of correlated-noise removal, over some group of channels of
mode <span class="math notranslate nohighlight">\(i\)</span>, is a little more complex. It is calculated as:</p>
<div class="math notranslate nohighlight">
\[\varkappa_{(i),c} = 1 - \frac{1}{N_{(i),t}} (P_{(i),c} + \sum_k \Omega_{ck} P_{(i),k})\]</div>
<p>where <span class="math notranslate nohighlight">\(\Omega_{ck}\)</span> is the overlap between channels <span class="math notranslate nohighlight">\(c\)</span> and
<span class="math notranslate nohighlight">\(k\)</span>. That is, <span class="math notranslate nohighlight">\(\Omega_{ck}\)</span> is the fraction of the point
source peak measured by channel <span class="math notranslate nohighlight">\(c\)</span> when the source is centered on
channel <span class="math notranslate nohighlight">\(k\)</span>. <span class="math notranslate nohighlight">\(N_{(i),t}\)</span> is the number of correlated
noise-samples that have been derived for the given mode (usually the
same as the number of time samples in the analysis). The correlated
model’s dependence on channel <span class="math notranslate nohighlight">\(c\)</span> is:</p>
<div class="math notranslate nohighlight">
\[P_{(i),c} = \sum_t p_{(i),ct}\]</div>
<p>Finally, the point-source filter correction due to spectral filtering is
calculated based on the average point-source spectrum produced by the
scanning. Gaussian source profiles with spatial spread
<span class="math notranslate nohighlight">\(\sigma_x \approx FWHM / 2.35\)</span> produce a typical temporal spread
<span class="math notranslate nohighlight">\(\sigma_t \approx \sigma_x / \bar{v}\)</span>, in terms of the mean
scanning speed <span class="math notranslate nohighlight">\(\bar{v}\)</span>. In frequency space, this translates to a
Gaussian frequency spread of <span class="math notranslate nohighlight">\(\sigma_f = (2 \pi \sigma_t)^{-1}\)</span>,
and thus a point-source frequency profile of:</p>
<div class="math notranslate nohighlight">
\[\Psi_f \approx e^{-f^2 / (2\sigma_f^2)}\]</div>
<p>More generally, <span class="math notranslate nohighlight">\(\Psi_f\)</span> may be complex-valued (asymmetric beam).
Accordingly, the point-source filter correction due to filtering with
<span class="math notranslate nohighlight">\(\phi_f\)</span> is generally:</p>
<div class="math notranslate nohighlight">
\[\varkappa_{\phi,c} \approx \frac{\sum\limits_f Re(\phi_f \Psi_f \phi_f)}{\sum\limits_f Re(\Psi_f)}\]</div>
<p>The compound point source filtering effect from <span class="math notranslate nohighlight">\(m\)</span> model
components is the product of the individual model corrections, i.e.:</p>
<div class="math notranslate nohighlight">
\[\varkappa_c = \prod_m \varkappa_{(m),c}\]</div>
</section>
<section id="scan-map-output">
<h4>Scan Map Output<a class="headerlink" href="#scan-map-output" title="Link to this heading">¶</a></h4>
<p>Since the Scan mode algorithms are iterative, there are no well-defined
intermediate products that may be written to disk. For Scan mode data,
the pipeline takes as input a set of raw Level 0 HAWC FITS files,
described in the <a class="reference internal" href="#prepare"><span class="std std-ref">Prepare</span></a> section, and writes as output a single FITS
file per file group, saved with PRODTYPE = <em>scanmap</em> (file name code SMP).
These files contain an image of the source map in units of detector counts,
and several other extensions.</p>
<p>The flux calibrated map file is saved as the <em>calibrate</em> product type
(CAL).  The primary HDU in the CAL file contains the flux image in
units of Jy/pixel. The first extension (EXTNAME = EXPOSURE)
contains an image of the nominal exposure time in seconds at each point
in the map. The second extension (EXTNAME = NOISE) holds the error image
corresponding to the flux map, and the third extension (EXTNAME = S/N)
is the signal-to-noise ratio of the flux to the error image. The fourth
and further extensions contain binary tables of data, one for each input
scan.</p>
</section>
</section>
<section id="scan-pol-reduction-algorithms">
<h3>Scan-Pol Reduction Algorithms<a class="headerlink" href="#scan-pol-reduction-algorithms" title="Link to this heading">¶</a></h3>
<p>Scanning polarimetry reductions are a hybrid of the the Nod-Pol and Scan
reduction algorithms, described above.</p>
<p>Scan-Pol observations are performed in a sequence of four scans, where
each scan has a different HWP position angle in the following sequence:
5 degrees, 50 degrees, 27.5 degrees, and 72.5 degrees. This sequence is
called a ‘set’ hereafter. The pipeline sorts observations into sets
and runs the scan map reconstruction algorithm on each set, following the
procedure in <a class="reference internal" href="#scanmap"><span class="std std-ref">Scan Reduction Algorithms</span></a>. For Scan-Pol observations, the pipeline produces two images
per scan per HWP angle associated with the R and T arrays. Thus, for a
single set, 8 images are generated, one for each of R0 and T0 at each angle.
The pipeline creates all maps in the same output coordinate system and
pixel scale, so that they are all registered to each other.</p>
<p>Since the scan map step sets the background level independently for each
scan image from the median of the full map, there may be inconsistencies
in the zero-level between the images, if there is significant diffuse
emission across the map.  In this case, the pipeline may optionally correct
the zero-level in each image by identifying a sky region with no emission,
and subtracting the median level in this region from each image.  The same
region is used for each HWP angle and subarray, so that all images are set
independently to a common zero level.</p>
<p>After zero-level correction, the R and T arrays are directly added
and subtracted at each HWP angle, and combined as described above to
generate Stokes I, Q, and U images (the <a class="reference internal" href="#stokes"><span class="std std-ref">Compute Stokes</span></a> step).  The output
data format is the same as for the <em>stokes</em> product for the Nod-Pol pipeline.</p>
<p>After Stokes calculation, the following steps are also performed,
in the way described above for the Nod-Pol pipeline:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#ip"><span class="std std-ref">Subtract Instrumental Polarization</span></a></p></li>
<li><p><a class="reference internal" href="#rotate"><span class="std std-ref">Rotate Polarization Coordinates</span></a></p></li>
<li><p><a class="reference internal" href="#calibrate"><span class="std std-ref">Correct for Atmospheric Opacity</span></a></p></li>
<li><p><a class="reference internal" href="#merge-images"><span class="std std-ref">Merge Images</span></a></p></li>
<li><p><a class="reference internal" href="#vectors"><span class="std std-ref">Compute Vectors</span></a></p></li>
</ul>
<p>Note that the scan map pipeline step performs opacity and background level
corrections on individual scans and resamples data into sky coordinates with
full WCS corrections, as part of its standard processing, so these
steps from the Nod-Pol pipeline are not applied.</p>
<p>The final output product is a polarization map, the same as is
produced by the Nod-Pol pipeline.</p>
</section>
<section id="other-resources">
<h3>Other Resources<a class="headerlink" href="#other-resources" title="Link to this heading">¶</a></h3>
<p>For more information on the code or algorithms used in the HAWC DRP pipeline,
see the following documents:</p>
<ul class="simple">
<li><p>Far-infrared polarimetry analysis: <a class="reference external" href="http://iopscience.iop.org/article/10.1086/316613">Hildebrand et. al. 2000 PASP,
112, 1215</a></p></li>
<li><p>DRP infrastructure and image viewer: <a class="reference external" href="http://adsabs.harvard.edu/abs/2013ASPC..475..193B">Berthoud, M. 2013 ADASS XXII,
475, 193</a></p></li>
</ul>
<p>The scan map reconstruction algorithms are based on a Java pipeline
called CRUSH.  For more information, see:</p>
<ul class="simple">
<li><p>CRUSH paper: <a class="reference external" href="http://adsabs.harvard.edu/abs/2008SPIE.7020E..45K">Kovács, A. 2008, Proc. SPIE, 7020,
45</a></p></li>
<li><p>CRUSH thesis: <a class="reference external" href="http://adsabs.harvard.edu/abs/2006PhDT........28K">Kovács, A. 2006, PhD Thesis,
Caltech</a></p></li>
<li><p>Online documentation: <a class="reference external" href="http://www.sigmyne.com/crush/">http://www.sigmyne.com/crush/</a></p></li>
</ul>
</section>
</section>
<section id="data-products">
<h2>Data Products<a class="headerlink" href="#data-products" title="Link to this heading">¶</a></h2>
<section id="file-names">
<h3>File names<a class="headerlink" href="#file-names" title="Link to this heading">¶</a></h3>
<p>Output files from the HAWC pipeline are named according to the
convention:</p>
<blockquote>
<div><p>FILENAME =
F[<em>flight</em>]_HA_[<em>mode</em>]_[<em>aorid</em>]_[<em>spectel</em>]_[<em>type</em>]_[<em>fn1</em>[<em>-fn2</em>]].fits</p>
</div></blockquote>
<p>where <em>flight</em> is the SOFIA flight number, <em>HA</em> indicates the instrument
(HAWC+), and <em>mode</em> is either <em>IMA</em> for imaging observations, <em>POL</em> for
polarization observations, or <em>CAL</em> for diagnostic data. The <em>aorid</em>
indicates the SOFIA program and observation number; <em>spectel</em> indicates
the filter/band and the HWP setting. The <em>type</em> is a three-letter
identifier for the pipeline product type, and <em>fn1</em> and <em>fn2</em> are the
first and last raw file numbers that were combined to produce the output
product. For example, a polarization map data product with AOR-ID
81_0131_04, derived from files 5 to 6 of flight 295, taken in Band A
with HWP in the A position would have the filename
<em>F0295_HA_POL_81013104_HAWAHWPA_PMP_005-006.fits</em>. See the tables
below for a list of all possible values for the three-letter product
type.</p>
</section>
<section id="data-format">
<h3>Data format<a class="headerlink" href="#data-format" title="Link to this heading">¶</a></h3>
<p>Most HAWC data is stored in FITS files, conforming to the FITS standard
(Pence et al. 2010). Each FITS file contains a primary Header Data Unit
(HDU) which may contain the most appropriate image data for that
particular data reduction level. Most files have additional data stored
in HDU image or table extensions. All keywords describing the file are
in the header of the primary HDU. Each HDU also has a minimal header and
is identified by the EXTNAME header keyword. The algorithm descriptions,
above, give more information about the content of each extension.</p>
</section>
<section id="pipeline-products">
<h3>Pipeline products<a class="headerlink" href="#pipeline-products" title="Link to this heading">¶</a></h3>
<p>The following tables list all intermediate and final products that may
be generated by the HAWC pipeline, in the order in which they are
produced for each mode. The product type is stored in the primary
header, under the keyword PRODTYPE. By default, for Nod-Pol mode, the
<em>demodulate</em>, <em>opacity</em>, <em>calibrate</em>, <em>merge</em>, and <em>polmap</em> products
are saved. For Chop-Nod mode, the <em>demodulate</em>, <em>opacity</em>, <em>merge</em>,
and <em>calibrate</em> products are saved. For Scan mode, the <em>scanmap</em>
and <em>calibrate</em> products are saved.  For Scan-Pol mode, the <em>scanmappol</em>,
<em>calibrate</em>, <em>merge</em>, and <em>polmap</em> products are saved.</p>
<p>For polarization data, the pipeline also generates two auxiliary products: a
polarization map image in PNG format, with polarization vectors plotted
over the Stokes I image, and a polarization vector file in DS9 region
format, for displaying with FITS images. These products are alternate
representations of the data in the FINAL POL DATA table in the
polarization map (PMP) FITS file. Similarly, for imaging data, a PNG
quick-look preview image is generated as a final step in the pipeline.
These auxiliary products may be distrubuted to observers separately from
the FITS file products.</p>
<p>Data products that contain multiple AORs or that contain observations from
multiple flights are referred to as multi-mission products. When
multi-mission data are processed and stored in the database, they replace the
corresponding single-mission/single-AOR data files. This process usually
results in fewer data files for a project.  For HAWC+, the following data
products can be multi-mission:</p>
<blockquote>
<div><ul class="simple">
<li><p>imaging: <em>calibrate</em> (CAL)</p></li>
<li><p>polarimetry: <em>merge</em> (MRG), <em>polmap</em> (PMP).</p></li>
</ul>
</div></blockquote>
<table class="docutils align-default" id="id4">
<caption><span class="caption-number">Table 25 </span><span class="caption-text">Nod-Pol mode intermediate and final pipeline data products</span><a class="headerlink" href="#id4" title="Link to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Step</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>PRODTYPE</p></th>
<th class="head"><p>PROCSTAT</p></th>
<th class="head"><p>Identifier</p></th>
<th class="head"><p>Saved</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Make Flat</p></td>
<td><p>Flat generated from Int. Cal file</p></td>
<td><p>obsflat</p></td>
<td><p>LEVEL_2</p></td>
<td><p>OFT</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p>Demodulate</p></td>
<td><p>Chops subtracted</p></td>
<td><p>demodulate</p></td>
<td><p>LEVEL_1</p></td>
<td><p>DMD</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>Flat Correct</p></td>
<td><p>Flat field correction applied</p></td>
<td><p>flat</p></td>
<td><p>LEVEL_2</p></td>
<td><p>FLA</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Align Arrays</p></td>
<td><p>R array shifted to T array</p></td>
<td><p>shift</p></td>
<td><p>LEVEL_2</p></td>
<td><p>SFT</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Split Images</p></td>
<td><p>Data split by nod, HWP</p></td>
<td><p>split</p></td>
<td><p>LEVEL_2</p></td>
<td><p>SPL</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Combine Images</p></td>
<td><p>Chop cycles combined</p></td>
<td><p>combine</p></td>
<td><p>LEVEL_2</p></td>
<td><p>CMB</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Subtract Beams</p></td>
<td><p>Nod beams subtracted</p></td>
<td><p>nodpolsub</p></td>
<td><p>LEVEL_2</p></td>
<td><p>NPS</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Compute Stokes</p></td>
<td><p>Stokes parameters calculated</p></td>
<td><p>stokes</p></td>
<td><p>LEVEL_2</p></td>
<td><p>STK</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Update WCS</p></td>
<td><p>WCS added to header</p></td>
<td><p>wcs</p></td>
<td><p>LEVEL_2</p></td>
<td><p>WCS</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Subtract IP</p></td>
<td><p>Instrumental polarization removed</p></td>
<td><p>ip</p></td>
<td><p>LEVEL_2</p></td>
<td><p>IPS</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Rotate Coordinates</p></td>
<td><p>Polarization angle corrected to sky</p></td>
<td><p>rotate</p></td>
<td><p>LEVEL_2</p></td>
<td><p>ROT</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Correct Opacity</p></td>
<td><p>Corrected for atmospheric opacity</p></td>
<td><p>opacity</p></td>
<td><p>LEVEL_2</p></td>
<td><p>OPC</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>Calibrate Flux</p></td>
<td><p>Flux calibrated to physical units</p></td>
<td><p>calibrate</p></td>
<td><p>LEVEL_3</p></td>
<td><p>CAL</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p>Subtract Background</p></td>
<td><p>Residual background removed</p></td>
<td><p>bgsubtract</p></td>
<td><p>LEVEL_3</p></td>
<td><p>BGS</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Bin Pixels</p></td>
<td><p>Pixels rebinned to increase S/N</p></td>
<td><p>binpixels</p></td>
<td><p>LEVEL_3</p></td>
<td><p>BIN</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Merge Images</p></td>
<td><p>Dithers merged to a single map</p></td>
<td><p>merge</p></td>
<td><p>LEVEL_3</p></td>
<td><p>MRG</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>Compute Vectors</p></td>
<td><p>Polarization vectors calculated</p></td>
<td><p>polmap</p></td>
<td><p>LEVEL_4</p></td>
<td><p>PMP</p></td>
<td><p>Y</p></td>
</tr>
</tbody>
</table>
<span id="nod-products"></span><table class="docutils align-default" id="id5">
<caption><span class="caption-number">Table 26 </span><span class="caption-text">Chop-Nod mode intermediate and final pipeline data products</span><a class="headerlink" href="#id5" title="Link to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Step</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>PRODTYPE</p></th>
<th class="head"><p>PROCSTAT</p></th>
<th class="head"><p>Identifier</p></th>
<th class="head"><p>Saved</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Make Flat</p></td>
<td><p>Flat generated from Int.Cal file</p></td>
<td><p>obsflat</p></td>
<td><p>LEVEL_2</p></td>
<td><p>OFT</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p>Demodulate</p></td>
<td><p>Chops subtracted</p></td>
<td><p>demodulate</p></td>
<td><p>LEVEL_1</p></td>
<td><p>DMD</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>Flat Correct</p></td>
<td><p>Flat field correction applied</p></td>
<td><p>flat</p></td>
<td><p>LEVEL_2</p></td>
<td><p>FLA</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Align Arrays</p></td>
<td><p>R array shifted to T array</p></td>
<td><p>shift</p></td>
<td><p>LEVEL_2</p></td>
<td><p>SFT</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Split Images</p></td>
<td><p>Data split by nod, HWP</p></td>
<td><p>split</p></td>
<td><p>LEVEL_2</p></td>
<td><p>SPL</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Combine Images</p></td>
<td><p>Chop cycles combined</p></td>
<td><p>combine</p></td>
<td><p>LEVEL_2</p></td>
<td><p>CMB</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Subtract Beams</p></td>
<td><p>Nod beams subtracted</p></td>
<td><p>nodpolsub</p></td>
<td><p>LEVEL_2</p></td>
<td><p>NPS</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Compute Stokes</p></td>
<td><p>Stokes parameters calculated</p></td>
<td><p>stokes</p></td>
<td><p>LEVEL_2</p></td>
<td><p>STK</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Update WCS</p></td>
<td><p>WCS added to header</p></td>
<td><p>wcs</p></td>
<td><p>LEVEL_2</p></td>
<td><p>WCS</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Correct Opacity</p></td>
<td><p>Corrected for atmospheric opacity</p></td>
<td><p>opacity</p></td>
<td><p>LEVEL_2</p></td>
<td><p>OPC</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>Subtract Background</p></td>
<td><p>Residual background removed</p></td>
<td><p>bgsubtract</p></td>
<td><p>LEVEL_2</p></td>
<td><p>BGS</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Bin Pixels</p></td>
<td><p>Pixels rebinned to increase S/N</p></td>
<td><p>binpixels</p></td>
<td><p>LEVEL_2</p></td>
<td><p>BIN</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Merge Images</p></td>
<td><p>Dithers merged to single map</p></td>
<td><p>merge</p></td>
<td><p>LEVEL_2</p></td>
<td><p>MRG</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p>Calibrate Flux</p></td>
<td><p>Flux calibrated to physical units</p></td>
<td><p>calibrate</p></td>
<td><p>LEVEL_3</p></td>
<td><p>CAL</p></td>
<td><p>Y</p></td>
</tr>
</tbody>
</table>
<span id="scan-products"></span><table class="docutils align-default" id="id6">
<caption><span class="caption-number">Table 27 </span><span class="caption-text">Scan mode intermediate and final pipeline data products</span><a class="headerlink" href="#id6" title="Link to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Step</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>PRODTYPE</p></th>
<th class="head"><p>PROCSTAT</p></th>
<th class="head"><p>Identifier</p></th>
<th class="head"><p>Saved</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Construct Scan Map</p></td>
<td><p>Source model iteratively derived</p></td>
<td><p>scanmap</p></td>
<td><p>LEVEL_2</p></td>
<td><p>SMP</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p>Calibrate Flux</p></td>
<td><p>Flux calibrated to physical units</p></td>
<td><p>calibrate</p></td>
<td><p>LEVEL_3</p></td>
<td><p>CAL</p></td>
<td><p>Y</p></td>
</tr>
</tbody>
</table>
<span id="scanpol-products"></span><table class="docutils align-default" id="id7">
<caption><span class="caption-number">Table 28 </span><span class="caption-text">Scan-Pol mode intermediate and final pipeline data products</span><a class="headerlink" href="#id7" title="Link to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Step</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>PRODTYPE</p></th>
<th class="head"><p>PROCSTAT</p></th>
<th class="head"><p>Identifier</p></th>
<th class="head"><p>Saved</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Construct Scan Map</p></td>
<td><p>Source model iteratively derived</p></td>
<td><p>scanmappol</p></td>
<td><p>LEVEL_2</p></td>
<td><p>SMP</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p>Compute Stokes</p></td>
<td><p>Stokes parameters calculated</p></td>
<td><p>stokes</p></td>
<td><p>LEVEL_2</p></td>
<td><p>STK</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Subtract IP</p></td>
<td><p>Instrumental polarization removed</p></td>
<td><p>ip</p></td>
<td><p>LEVEL_2</p></td>
<td><p>IPS</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-odd"><td><p>Rotate Coordinates</p></td>
<td><p>Polarization angle corrected to sky</p></td>
<td><p>rotate</p></td>
<td><p>LEVEL_2</p></td>
<td><p>ROT</p></td>
<td><p>N</p></td>
</tr>
<tr class="row-even"><td><p>Calibrate Flux</p></td>
<td><p>Flux calibrated to physical units</p></td>
<td><p>calibrate</p></td>
<td><p>LEVEL_3</p></td>
<td><p>CAL</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-odd"><td><p>Merge Images</p></td>
<td><p>HWP sets merged to single map</p></td>
<td><p>merge</p></td>
<td><p>LEVEL_3</p></td>
<td><p>MRG</p></td>
<td><p>Y</p></td>
</tr>
<tr class="row-even"><td><p>Compute Vectors</p></td>
<td><p>Polarization vectors calculated</p></td>
<td><p>polmap</p></td>
<td><p>LEVEL_4</p></td>
<td><p>PMP</p></td>
<td><p>Y</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="grouping-level-0-data-for-processing">
<h2>Grouping Level 0 Data for Processing<a class="headerlink" href="#grouping-level-0-data-for-processing" title="Link to this heading">¶</a></h2>
<p>In order for the pipeline to successfully reduce a group of HAWC+ data
together, all input data must share a common instrument configuration
and observation mode, as well as target and filter band and HWP setting.
These requirements translate into a set of FITS header keywords that
must match in order for a set of data to be grouped together. These
keyword requirements are summarized in the table below, for imaging and
polarimetry data.</p>
<span id="grouping"></span><table class="docutils align-default" id="id8">
<caption><span class="caption-number">Table 29 </span><span class="caption-text">Grouping Criteria for Imaging and Polarimetry Modes</span><a class="headerlink" href="#id8" title="Link to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Mode</p></th>
<th class="head"><p>Keyword</p></th>
<th class="head"><p>Data Type</p></th>
<th class="head"><p>Match Criterion</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>All</p></td>
<td><p>OBSTYPE</p></td>
<td><p>string</p></td>
<td><p>exact</p></td>
</tr>
<tr class="row-odd"><td><p>All</p></td>
<td><p>FILEGPID</p></td>
<td><p>string</p></td>
<td><p>exact</p></td>
</tr>
<tr class="row-even"><td><p>All</p></td>
<td><p>INSTCFG</p></td>
<td><p>string</p></td>
<td><p>exact</p></td>
</tr>
<tr class="row-odd"><td><p>All</p></td>
<td><p>INSTMODE</p></td>
<td><p>string</p></td>
<td><p>exact</p></td>
</tr>
<tr class="row-even"><td><p>All</p></td>
<td><p>SPECTEL1</p></td>
<td><p>string</p></td>
<td><p>exact</p></td>
</tr>
<tr class="row-odd"><td><p>All</p></td>
<td><p>SPECTEL2</p></td>
<td><p>string</p></td>
<td><p>exact</p></td>
</tr>
<tr class="row-even"><td><p>All</p></td>
<td><p>PLANID</p></td>
<td><p>string</p></td>
<td><p>exact</p></td>
</tr>
<tr class="row-odd"><td><p>All</p></td>
<td><p>NHWP</p></td>
<td><p>float</p></td>
<td><p>exact</p></td>
</tr>
<tr class="row-even"><td><p>Imaging only</p></td>
<td><p>SCNPATT</p></td>
<td><p>string</p></td>
<td><p>exact</p></td>
</tr>
<tr class="row-odd"><td><p>Imaging only</p></td>
<td><p>CALMODE</p></td>
<td><p>string</p></td>
<td><p>exact</p></td>
</tr>
</tbody>
</table>
</section>
<section id="configuration-and-execution">
<h2>Configuration and Execution<a class="headerlink" href="#configuration-and-execution" title="Link to this heading">¶</a></h2>
<section id="installation">
<h3>Installation<a class="headerlink" href="#installation" title="Link to this heading">¶</a></h3>
<p>The HAWC pipeline is written entirely in Python.  The pipeline is
platform independent and has been tested on Linux, Mac OS X, and Windows
operating systems.  Running the pipeline requires a minimum of 16GB RAM,
or equivalent-sized swap file.</p>
<p>The pipeline is comprised of six modules within the <code class="xref py py-obj docutils literal notranslate"><span class="pre">sofia_redux</span></code> package:
<code class="xref py py-obj docutils literal notranslate"><span class="pre">sofia_redux.instruments.hawc</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">sofia_redux.pipeline</span></code>,
<code class="xref py py-obj docutils literal notranslate"><span class="pre">sofia_redux.calibration</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">sofia_redux.scan</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">sofia_redux.toolkit</span></code>, and
<code class="xref py py-obj docutils literal notranslate"><span class="pre">sofia_redux.visualization</span></code>.
The <code class="xref py py-obj docutils literal notranslate"><span class="pre">hawc</span></code> module provides the data processing
algorithms specific to HAWC, with supporting libraries from the
<code class="xref py py-obj docutils literal notranslate"><span class="pre">calibration</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">scan</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">toolkit</span></code>, and <code class="xref py py-obj docutils literal notranslate"><span class="pre">visualization</span></code>
modules.  The <code class="xref py py-obj docutils literal notranslate"><span class="pre">pipeline</span></code> module provides interactive and batch interfaces
to the pipeline algorithms.</p>
<section id="external-requirements">
<h4>External Requirements<a class="headerlink" href="#external-requirements" title="Link to this heading">¶</a></h4>
<p>To run the pipeline for any mode from the Redux interface, Python 3.8 or
higher is required, as well as the following packages: astropy, astroquery,
bottleneck, configobj, cycler, dill, joblib, matplotlib, numba, numpy, pandas,
photutils, scikit-learn, and scipy.</p>
<p>Some display functions for the graphical user interface (GUI) additionally
require the PyQt5, pyds9, and regions packages. All required
external packages are available to install via the pip or conda package
managers.  See the Anaconda environment file
(<em>environment.yml</em>), or the pip requirements file (<em>requirements.txt</em>)
distributed with <code class="xref py py-obj docutils literal notranslate"><span class="pre">sofia_redux</span></code> for up-to-date version requirements.</p>
<p>Running the pipeline’s interactive display tools also requires an installation
of SAO DS9 for FITS image display. See <a class="reference external" href="http://ds9.si.edu/">http://ds9.si.edu/</a> for download
and installation instructions.  The <em>ds9</em> executable
must be available in the PATH environment variable for the pyds9
interface to be able to find and control it. Please note that pyds9
is not available on the Windows platform.</p>
</section>
<section id="source-code-installation">
<h4>Source Code Installation<a class="headerlink" href="#source-code-installation" title="Link to this heading">¶</a></h4>
<p>The source code for the HAWC pipeline maintained by the SOFIA Data
Processing Systems (DPS) team can be obtained directly from the
DPS, or from the external <a class="reference external" href="https://github.com/SOFIA-USRA/sofia_redux">GitHub repository</a>.
This repository contains all needed configuration
files, auxiliary files, and Python code to run the pipeline on HAWC
data in any observation mode.</p>
<p>After obtaining the source code, install the pipeline with
the command:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>python setup.py install
</pre></div>
</div>
<p>from the top-level directory.</p>
<p>Alternately, a development installation may be performed from inside the
directory with the command:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>pip install -e .
</pre></div>
</div>
<p>After installation, the top-level pipeline interface commands should
be available in the PATH.  Typing:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>redux
</pre></div>
</div>
<p>from the command line should launch the GUI interface, and:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>redux_pipe -h
</pre></div>
</div>
<p>should display a brief help message for the command line interface.</p>
</section>
</section>
<section id="configuration">
<h3>Configuration<a class="headerlink" href="#configuration" title="Link to this heading">¶</a></h3>
<p>The DRP pipeline requires a valid and complete configuration file to
run. Configuration files are written in plain text, in the INI format
readable by the configobj Python library. These files are divided into
sections, specified by brackets (e.g. [section]), each of which may
contain keyword-value pairs or subsections (e.g. [[subsection]]). The
HAWC configuration file must contain the following sections:</p>
<ul class="simple">
<li><p>Data configuration, including specifications for input and output
file names and formats, and specifications for metadata handling</p></li>
<li><p>Pipeline mode definitions for each supported instrument mode,
including the FITS keywords that define the mode and the list of
steps to run</p></li>
<li><p>Pipeline step parameter definitions (one section for each pipeline
step defined)</p></li>
</ul>
<p>The pipeline is usually run with a default configuration file
(<em>sofia_redux/instruments/hawc/data/config/pipeconf.cfg</em>),
which defines all standard
reduction steps and default parameters. It may be overridden with
date-specific default values, defined in
(<em>sofia_redux/instruments/hawc/data/config/date_overrides/</em>), or with
user-defined parameters. Override configuration files may contain any
subset of the values in the full configuration file. See <a class="reference internal" href="#config-appendix"><span class="std std-ref">Appendix: Sample Configuration Files</span></a>
for examples of override configuration files as well as the full default
file.</p>
<p>The scan map reconstruction algorithm, run as a single pipeline step for
Scan and Scan-Pol mode data, also has its own separate set of configuration
files. These files are stored in the scan module, in
<em>sofia_redux/scan/data/configurations</em>. They are read from this sub-directory
in the order specified below.</p>
<p>Upon launch, scan map step will invoke the default configuration files
(<em>default.cfg</em>) in the following order:</p>
<ol class="arabic simple">
<li><p>Global defaults from <em>sofia_redux/scan/data/config/default.cfg</em></p></li>
<li><p>Instrument overrides from <em>sofia_redux/scan/data/config/hawc_plus/default.cfg</em></p></li>
</ol>
<p>Any configuration file may invoke further (nested) configurations, which
are located and loaded in the same order as above. For example,
<em>hawc_plus/default.cfg</em> invokes <em>sofia/default.cfg</em> first,
which contains settings for SOFIA instruments not specific to HAWC.</p>
<p>There are also modified configurations for “faint”, “deep”, or “extended”
sources, when one of these flags is set while running the scan map step. For
example, the faint mode reduction parses <em>faint.cfg</em> from the above
locations, after <em>default.cfg</em> was parsed. Similarly, there are
<em>extended.cfg</em> and <em>deep.cfg</em> files specifying modified configurations for
extended and deep modes, and a <em>scanpol.cfg</em> file specifying configurations
specifically for Scan-Pol mode.</p>
<p>See <a class="reference internal" href="#config-appendix"><span class="std std-ref">Appendix: Sample Configuration Files</span></a> for a full listing of the default configuration
for the scan map algorithm.</p>
</section>
<section id="input-data">
<h3>Input Data<a class="headerlink" href="#input-data" title="Link to this heading">¶</a></h3>
<p>The HAWC pipeline takes as input raw HAWC data files, which contain
binary tables of instrument readouts and metadata. The FITS headers
contain data acquisition and observation parameters and, combined with
the pipeline configuration files and other auxiliary files on disk,
comprise the information necessary to complete all steps of the data
reduction process. Some critical keywords are required to be present in
the raw data in order to perform a successful grouping, reduction, and
ingestion into the SOFIA archive. These are defined in the DRP pipeline
in a configuration file that describes the allowed values for each
keyword, in INI format (see <a class="reference internal" href="#kwd-appendix"><span class="std std-ref">Appendix: Required Header Keywords</span></a>).</p>
<p>It is assumed that the input data have been successfully grouped before
beginning reduction. The pipeline considers all input files in a
reduction to be science files that are part of a single homogeneous
reduction group, to be reduced together with the same parameters. The
sole exception is that internal calibrator files (CALMODE=INT_CAL) may
be loaded with their corresponding Chop-Nod or Nod-Pol science files.
They will be reduced separately first, in order to produce flat fields
used in the science reduction.</p>
<section id="auxiliary-files">
<h4>Auxiliary Files<a class="headerlink" href="#auxiliary-files" title="Link to this heading">¶</a></h4>
<p>In order to complete a standard reduction, the pipeline requires a
number of files to be on disk, with locations specified in the DRP
configuration file. Current default files described in the default
configuration are stored along with the code, typically in the
<em>sofia_redux/instruments/hawc/data</em> directory. See below for a table of
all commonly used types of auxiliary files.</p>
<span id="auxfiles"></span><table class="docutils align-default" id="id9">
<caption><span class="caption-number">Table 30 </span><span class="caption-text">Auxiliary files used by DRP reductions for Chop-Nod and Nod-Pol data</span><a class="headerlink" href="#id9" title="Link to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Auxiliary File</p></th>
<th class="head"><p>File Type</p></th>
<th class="head"><p>Pipe Step</p></th>
<th class="head"><p>Comments</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Jump Map</p></td>
<td><p>FITS</p></td>
<td><p>Flux Jump</p></td>
<td><p>Contains jump correction values per pixel</p></td>
</tr>
<tr class="row-odd"><td><p>Phase</p></td>
<td><p>FITS</p></td>
<td><p>Demodulate</p></td>
<td><p>Contains phase delay in seconds for each pixel</p></td>
</tr>
<tr class="row-even"><td><p>Reference Phase</p></td>
<td><p>FITS</p></td>
<td><p>Demod. Plots</p></td>
<td><p>Contains reference phase angles for comparison with the current observation</p></td>
</tr>
<tr class="row-odd"><td><p>Sky Cal</p></td>
<td><p>FITS</p></td>
<td><p>Make Flat</p></td>
<td><p>Contains a master sky flat for use in generating flats from INT_CALs</p></td>
</tr>
<tr class="row-even"><td><p>Flat</p></td>
<td><p>FITS</p></td>
<td><p>Flat Correct</p></td>
<td><p>Contains a back-up flat field, used if INT_CAL files are not available</p></td>
</tr>
<tr class="row-odd"><td><p>IP</p></td>
<td><p>FITS</p></td>
<td><p>Instrumental Polarization</p></td>
<td><p>Contains q and u correction factors by pixel and band</p></td>
</tr>
</tbody>
</table>
<p>The jump map is used in a preparatory step before the pipeline begins
processing to correct raw values for a residual electronic effect that
results in discontinuous jumps in flux values. It is a FITS image that
matches the dimensions of the raw flux values (128 x 41 pixels). Pixels
for which flux jump corrections may be required have integer values
greater than zero. Pixels for which there are no corrections necessary
are zero-valued.</p>
<p>The phase files used in the Demodulate step should be in FITS format,
with two HDUs containing phase information for the R and T arrays,
respectively. The phases are stored as images that specify the timing
delay, in seconds, for each pixel. The reference phase file used in the
Demod Plots step is used for diagnostic purposes only: it specifies a
baseline set of phase angle values, for use in judging the quality of
internal calibrator files.</p>
<p>Normally, the pipeline generates the flat fields used in the Flat
Correct step from internal calibrator (INT_CAL) files taken alongside
the data. To do so, the Make Flats step uses a Sky Cal reference file,
which has four image extensions: R Array Gain, T Array Gain, R Bad Pixel
Mask, and T Bad Pixel Mask. The image in each extension should match the
dimensions of the R and T arrays in the demodulated data (64 x 41
pixels). The Gain images should contain multiplicative floating-point
flat correction factors. The Bad Pixel Mask images should be integer
arrays, with value 0 (good), 1 (bad in R array), or 2 (bad in T array).
Bad pixels, corresponding to those marked 1 or 2 in the mask extensions,
should be set to NaN in the flat images. At a minimum, the primary FITS
header for the flat file should contain the SPECTEL1 and SPECTEL2
keywords, for matching the flat filter to the input demodulated files.</p>
<p>When INT_CAL files are not available, the Flat Correct step may use a
back-up flat file. This file should have the same format as the Sky Cal
file, but the R Array Gain and T Array Gain values should be suitable
for direct multiplication with the flux values in the Flat Correct step.
There should be one back-up flat file available for each filter
passband.</p>
<p>In addition to these files, stored with the DRP code, the pipeline
requires several additional auxiliary files to perform flux calibration.
These are tracked in the <em>pipecal</em> package, used to support SOFIA
flux calibration for several instruments, including HAWC.  The required
files include response coefficient tables, used to correct for
atmospheric opacity, and reference calibration factor tables, used
to calibrate to physical units.</p>
<p>The instrumental response coefficients are stored in ASCII text files,
with at least four white-space delimited columns as follows: filter
wavelength, filter name, response reference value, and fit coefficient
constant term. Any remaining columns are further polynomial terms in the
response fit. The independent variable in the polynomial fit is
indicated by the response filename: if it contains <em>airmass</em>, the
independent variable is zenith angle (ZA); if <em>alt</em>, the independent
variable is altitude in thousands of feet; if <em>pwv</em>, the independent
variable is precipitable water vapor, in <span class="math notranslate nohighlight">\(\mu m\)</span>. The reference
values for altitude, ZA, and PWV are listed in the headers of the text
files, in comment lines preceded with <em>#</em>.</p>
<p>Calibration factors are also stored in ASCII format, and list the
correction factor by mode and HAWC filter band, to be applied to
opacity-corrected data.</p>
<p>Some additional auxiliary files are used in reductions of flux
standards, to assist in deriving the flux calibration factors applied
to science observations.  These include filter definition tables
and standard flux tables, by date and source.</p>
<table class="docutils align-default" id="id10">
<caption><span class="caption-number">Table 31 </span><span class="caption-text">Auxiliary files used for calibration (all modes)</span><a class="headerlink" href="#id10" title="Link to this table">¶</a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Auxiliary File</p></th>
<th class="head"><p>File Type</p></th>
<th class="head"><p>Pipe Step</p></th>
<th class="head"><p>Comments</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Response</p></td>
<td><p>ASCII</p></td>
<td><p>Opacity Correct</p></td>
<td><p>Contains instrumental response coefficients by altitude, ZA</p></td>
</tr>
<tr class="row-odd"><td><p>Calibration Factor</p></td>
<td><p>ASCII</p></td>
<td><p>Calibrate</p></td>
<td><p>Contains reference calibration factors by filter band, mode</p></td>
</tr>
<tr class="row-even"><td><p>Filter definition</p></td>
<td><p>ASCII</p></td>
<td><p>Standard Photometry</p></td>
<td><p>Contains filter wavelength band and standard aperture definitions</p></td>
</tr>
<tr class="row-odd"><td><p>Standard flux</p></td>
<td><p>ASCII</p></td>
<td><p>Standard Photometry</p></td>
<td><p>Contains reference flux values for a known source, by filter band</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="automatic-mode-execution">
<h3>Automatic Mode Execution<a class="headerlink" href="#automatic-mode-execution" title="Link to this heading">¶</a></h3>
<p>The DPS pipeline infrastructure runs a pipeline on previously-defined
reduction groups as a fully-automatic black box. To do so, it creates an
input manifest (<em>infiles.txt</em>) that contains relative paths to the input
files (one per line). The command-line interface to the
pipeline is run as:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>redux_pipe infiles.txt
</pre></div>
</div>
<p>The command-line interface will read in the specified input files, use
their headers to determine the observation mode, and accordingly
the steps to run and any intermediate files to save. Output files are
written to the current directory, from which the pipeline was called.
After reduction is complete, the script will generate an output manifest
(<em>outfiles.txt</em>) containing the relative paths to all output FITS files
generated by the pipeline.</p>
<p>Optionally, in place of a manifest file, file paths to input files may
be directly specified on the command line.  Input files may be raw
FITS files, or may be intermediate products previously produced
by the pipeline.  For example, this command will complete the reduction
for a set of FITS files in the current directory, previously reduced
through the calibration step of the pipeline:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>redux_pipe *CAL*.fits
</pre></div>
</div>
<p>To customize batch reductions from the command line, the <em>redux_pipe</em> interface
accepts a configuration file on the command line.  This file may contain
any subset of the full configuration file, specifying any non-default
parameters for pipeline steps.  An output directory for pipeline products
and the terminal log level may also be set on the command line.</p>
<p>The full set of optional command-line parameters accepted by the <em>redux_pipe</em>
interface are:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>-h, --help            show this help message and exit
-c CONFIG, --configuration CONFIG
                      Path to Redux configuration file.
-o OUTDIR, --out OUTDIR
                      Path to output directory.
-l LOGLEVEL, --loglevel LOGLEVEL
                      Log level.
</pre></div>
</div>
</section>
<section id="manual-mode-execution">
<h3>Manual Mode Execution<a class="headerlink" href="#manual-mode-execution" title="Link to this heading">¶</a></h3>
<p>In manual mode, the pipeline may be run interactively, via a graphical
user interface (GUI) provided by the Redux package.  The GUI is launched by
the command:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>redux
</pre></div>
</div>
<p>entered at the terminal prompt (<a class="reference internal" href="#hawc-startup"><span class="std std-numref">Fig. 105</span></a>).  The GUI allows
output directory specification, but it may write initial or temporary
files to the current directory, so it is recommended to start the
interface from a location to which the user has write privileges.</p>
<p>From the command line, the <em>redux</em> interface accepts an optional config file
(<em>-c</em>) or log level specification (<em>-l</em>), in the same way the <em>redux_pipe</em>
command does.  Any pipeline parameters provided to the interface in a
configuration file will be used to set default values; they will still be
editable from the GUI.</p>
<figure class="align-default" id="hawc-startup">
<img alt="Startup screen showing an outline of an airplane with an open telescope door on a blue background showing faint spiral arms and stylized stars." src="../../../_images/startup4.png" />
<figcaption>
<p><span class="caption-number">Fig. 105 </span><span class="caption-text">Redux GUI startup.</span><a class="headerlink" href="#hawc-startup" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<section id="basic-workflow">
<h4>Basic Workflow<a class="headerlink" href="#basic-workflow" title="Link to this heading">¶</a></h4>
<p>To start an interactive reduction, select a set of input files, using
the File menu (<strong>File-&gt;Open New Reduction</strong>). This will bring up a file
dialog window (see <a class="reference internal" href="#hawc-open-new"><span class="std std-numref">Fig. 106</span></a>). All files selected will be reduced
together as a single reduction set.</p>
<p>Redux will decide the appropriate reduction steps from the input files,
and load them into the GUI, as in <a class="reference internal" href="#hawc-reduction-steps"><span class="std std-numref">Fig. 107</span></a>.</p>
<figure class="align-default" id="hawc-open-new">
<img alt="File system dialog window showing selected filenames." src="../../../_images/open_new4.png" />
<figcaption>
<p><span class="caption-number">Fig. 106 </span><span class="caption-text">Open new reduction.</span><a class="headerlink" href="#hawc-open-new" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<figure class="align-default" id="hawc-reduction-steps">
<img alt="GUI window showing reduction steps with Edit and Run buttons. A log window is displayed with text messages from a reduction." src="../../../_images/reduction_steps4.png" />
<figcaption>
<p><span class="caption-number">Fig. 107 </span><span class="caption-text">Sample reduction steps. Log output from the pipeline is
displayed in the <strong>Log</strong> tab.</span><a class="headerlink" href="#hawc-reduction-steps" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<p>Each reduction step has a number of parameters that can be edited
before running the step. To examine or edit these parameters,
click the <strong>Edit</strong> button next to the step name to bring up the
parameter editor for that step (<a class="reference internal" href="#hawc-parameters"><span class="std std-numref">Fig. 108</span></a>). Within the
parameter editor, all values may be edited.  Click <strong>OK</strong> to save the
edited values and close the window. Click <strong>Reset</strong> to restore any
edited values to their last saved values.  Click <strong>Restore Defaults</strong>
to reset all values to their stored defaults.
Click <strong>Cancel</strong> to discard all changes to the parameters and
close the editor window.</p>
<figure class="align-default" id="hawc-parameters">
<img alt="An Edit Parameters dialog window, showing various selection widgets." src="../../../_images/parameters4.png" />
<figcaption>
<p><span class="caption-number">Fig. 108 </span><span class="caption-text">Sample parameter editor for a pipeline step.</span><a class="headerlink" href="#hawc-parameters" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<p>The current set of parameters can be displayed, saved to a file,
or reset all at once using the <strong>Parameters</strong> menu. A previously
saved set of parameters can also be restored for use with the
current reduction (<strong>Parameters -&gt; Load Parameters</strong>).</p>
<p>After all parameters for a step have been examined and set to the
user’s satisfaction, a processing step can be run on all loaded
files either by clicking <strong>Step</strong>, or the <strong>Run</strong> button next to the
step name. Each processing step must be run in order, but if a
processing step is selected in the <strong>Step through:</strong> widget,
then clicking <strong>Step</strong> will treat all steps up through the selected
step as a single step and run them all at once. When a step has
been completed, its buttons will be grayed out and inaccessible.
It is possible to undo one previous step by clicking <strong>Undo</strong>.
All remaining steps can be run at once by clicking <strong>Reduce</strong>.
After each step, the results of the processing may be displayed
in a data viewer. After running a pipeline step or reduction,
click <strong>Reset</strong> to restore the reduction to the initial state,
without resetting parameter values.</p>
<p>Files can be added to the reduction set (<strong>File -&gt; Add Files</strong>) or
removed from the reduction set (<strong>File -&gt; Remove Files</strong>), but
either action will reset the reduction for all loaded files.
Select the <strong>File Information</strong> tab to display a table of information
about the currently loaded files (<a class="reference internal" href="#hawc-file-info"><span class="std std-numref">Fig. 109</span></a>).</p>
<figure class="align-default" id="hawc-file-info">
<img alt="A table display showing filenames and FITS keyword values." src="../../../_images/file_info4.png" />
<figcaption>
<p><span class="caption-number">Fig. 109 </span><span class="caption-text">File information table.</span><a class="headerlink" href="#hawc-file-info" title="Link to this image">¶</a></p>
</figcaption>
</figure>
</section>
<section id="display-features">
<h4>Display Features<a class="headerlink" href="#display-features" title="Link to this heading">¶</a></h4>
<p>The Redux GUI displays images for quality analysis and display (QAD)
in the DS9 FITS viewer.  DS9 is a standalone image display
tool with an extensive feature set.  See the SAO DS9 site
(<a class="reference external" href="http://ds9.si.edu/">http://ds9.si.edu/</a>) for more usage information.</p>
<p>After each pipeline step completes, Redux may load the produced images
into DS9.  Some display options may be customized directly in DS9;
some commonly used options are accessible from the Redux interface, in the
<strong>Data View</strong> tab (<a class="reference internal" href="#hawc-data-view"><span class="std std-numref">Fig. 110</span></a>).</p>
<figure class="align-default" id="hawc-data-view">
<img alt="Data viewer settings with various widgets and buttons to control display parameters and analysis tools." src="../../../_images/data_view4.png" />
<figcaption>
<p><span class="caption-number">Fig. 110 </span><span class="caption-text">Data viewer settings and tools.</span><a class="headerlink" href="#hawc-data-view" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<p>From the Redux interface, the <strong>Display Settings</strong> can be used to:</p>
<ul class="simple">
<li><p>Set the FITS extension to display (<strong>First</strong>, or edit to enter
a specific extension), or specify that all extensions should
be displayed in a cube or in separate frames.</p></li>
<li><p>Lock individual frames together, in image or WCS coordinates.</p></li>
<li><p>Lock cube slices for separate frames together, in image or
WCS coordinates.</p></li>
<li><p>Set the image scaling scheme.</p></li>
<li><p>Set a default color map.</p></li>
<li><p>Zoom to fit image after loading.</p></li>
<li><p>Tile image frames, rather than displaying a single frame at a
time.</p></li>
</ul>
<p>Changing any of these options in the Data View tab will cause the
currently displayed data to be reloaded, with the new options.
Clicking <strong>Reset Display Settings</strong> will revert any edited options
to the last saved values.  Clicking <strong>Restore Default Display Settings</strong>
will revert all options to their default values.</p>
<p>In the <strong>QAD Tools</strong> section of the <strong>Data View</strong> tab, there are
several additional tools available.</p>
<p>Clicking the <strong>ImExam</strong> button
(scissors icon) launches an event loop in DS9.  After launching it,
bring the DS9 window forward, then use the keyboard to perform interactive
analysis tasks:</p>
<ul class="simple">
<li><p>Type ‘a’ over a source in the image to perform photometry at the
cursor location.</p></li>
<li><p>Type ‘p’ to plot a pixel-to-pixel comparison of all frames at the
cursor location.</p></li>
<li><p>Type ‘s’ to compute statistics and plot a histogram of the data
at the cursor location.</p></li>
<li><p>Type ‘c’ to clear any previous photometry results or active plots.</p></li>
<li><p>Type ‘h’ to print a help message.</p></li>
<li><p>Type ‘q’ to quit the ImExam loop.</p></li>
</ul>
<p>The photometry settings (the image window considered, the model fit,
the aperture sizes, etc.) may be customized in the <strong>Photometry Settings</strong>.
Plot settings (analysis window size, shared plot axes, etc.) may be
customized in the <strong>Plot Settings</strong>.
After modifying these settings, they will take effect only for new
apertures or plots (use ‘c’ to clear old ones first).  As for the display
settings, the reset button will revert to the last saved values
and the restore button will revert to default values.
For the pixel-to-pixel and histogram plots, if the cursor is contained within
a previously defined DS9 region (and the <code class="xref py py-obj docutils literal notranslate"><span class="pre">regions</span></code> package is installed),
the plot will consider only pixels within the region.  Otherwise, a window
around the cursor is used to generate the plot data.  Setting the window
to a blank value in the plot settings will use the entire image.</p>
<p>Clicking the <strong>Header</strong> button (magnifying glass icon) from the
<strong>QAD Tools</strong> section opens a new window that displays headers
from currently loaded FITS files in text form (<a class="reference internal" href="#hawc-headers"><span class="std std-numref">Fig. 111</span></a>).
The extensions displayed depends on the extension
setting selected (in <strong>Extension to Display</strong>).  If a particular extension is
selected, only that header will be displayed.  If all extensions
are selected (either for cube or multi-frame display), all extension
headers will be displayed.  The buttons at the bottom of the window
may be used to find or filter the header text, or generate a table
of header keywords.  For filter or table display, a comma-separated
list of keys may be entered in the text box.</p>
<p>Clicking the <strong>Save Current Settings</strong> button (disk icon) from the
<strong>QAD Tools</strong> section saves all current display and photometry
settings for the current user.  This allows the user’s settings to
persist across new Redux reductions, and to be loaded when Redux
next starts up.</p>
<figure class="align-default" id="hawc-headers">
<img alt="A dialog window showing a sample FITS header in plain text." src="../../../_images/headers4.png" />
<figcaption>
<p><span class="caption-number">Fig. 111 </span><span class="caption-text">QAD FITS header viewer.</span><a class="headerlink" href="#hawc-headers" title="Link to this image">¶</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="important-parameters">
<h3>Important Parameters<a class="headerlink" href="#important-parameters" title="Link to this heading">¶</a></h3>
<p>Below are some useful parameters for HAWC reductions.
Parameters for most pipeline steps may be set directly as key/value
pairs in pipeline configuration files; most scan map parameters are
added to the <em>options</em> parameter string in pipeline configuration files.  All
parameters listed are accessible and editable from the Redux GUI
interface as well.</p>
<p>The pipeline steps are as named in
the configuration file, in the order they are typically run. Not all steps
are run for all modes.  Note that this list is
not exhaustive; see the HAWC+ DRP Developer’s Manual or the code itself
for more information.</p>
<ul class="simple">
<li><p><strong>checkhead</strong></p>
<ul>
<li><p><em>abort</em>: Set to False to allow the pipeline to attempt to continue
reduction despite incorrect header keywords. Default is True.</p></li>
</ul>
</li>
<li><p><strong>demodulate</strong></p>
<ul>
<li><p><em>phasefile</em>: Set to a FITS file for per-pixel phase shifts, or to
a floating point number to apply the same phase shift to all
pixels (in seconds of delay). Default is typically a file in
<em>hawc/pipeline/data/phasefiles</em>.</p></li>
<li><p><em>phaseoffset</em>: Set to a floating point number to apply an offset
to the specified phase file.  The value should be specified in
degrees: it is usually determined from the median offset reported
by the demodulation plots for the INT_CAL files. Default is 0.0.</p></li>
<li><p><em>track_tol</em>: If non-negative, the pipeline step will use this
number as the tracking tolerance in arcseconds. Samples with
tracking deviation larger than this number will be rejected. If
set to ‘beam’, the beam size for the filter band will be used. If
set to ‘centroidexp’, the CentroidExpMsec data stream will be used
to flag data, rather than the TrackErrAoi3/4 data stream. Set to
-1 to turn off tracking rejection entirely. Default is
centroidexp.</p></li>
<li><p><em>data_sigma</em>: Sigma threshold for clipping data means; used in
calculating variance. Default is 5.0.</p></li>
</ul>
</li>
<li><p><strong>flat</strong></p>
<ul>
<li><p><em>flatfile</em>: Set to a file glob to identify flats to use in
processing. Default is “flats/*OFT*.fits”.</p></li>
<li><p><em>flatfitkeys</em>: Header keywords to match between data and flat
fields. Default is “`SPECTEL1’, ‘MISSN-ID’, ‘FILEGPID’,
‘SCRIPTID’”.</p></li>
<li><p><em>bkupflat</em>: File glob specifying back-up flats in case <em>flatfile</em>
does not exist. Default is
“$DPS_HAWCPIPE/pipeline/data/flats/*OFT.fits”.</p></li>
</ul>
</li>
<li><p><strong>split</strong></p>
<ul>
<li><p><em>rtarrays</em>: Set to ‘RT’ to use both R and T arrays, ‘R’ for R
only, or ‘T’ for T only. Default is ‘RT’.</p></li>
<li><p><em>nod_tol</em>: Percent difference between the number of chop cycles
in each nod position that will be tolerated for continuing the
reduction. Set higher to reject fewer data files. Default is 50.0.</p></li>
</ul>
</li>
<li><p><strong>combine</strong></p>
<ul>
<li><p><em>sigma</em>: Reject outliers more than this many sigma from the mean.
Default is 3.0.</p></li>
<li><p><em>sum_sigma</em>: Reject additional outliers in R+T more than this
many sigma from the mean. Default is 4.0.</p></li>
</ul>
</li>
<li><p><strong>scanmap</strong></p>
<ul>
<li><p><em>use_frames</em>: Frames (time samples) to use from the reduction. Specify
a particular range, as ‘400:-400’ or ‘400:1000’</p></li>
<li><p><em>grid</em>: If set, the output pixel size will be modified from the default
value to the specified value, in arcsec. The output flux scale will also
be modified accordingly, for flux conservation.</p></li>
<li><p><em>deep</em>: If set, faint point-like emission is prioritized.</p></li>
<li><p><em>faint</em>: If set, faint emission (point-like or extended) is prioritized.</p></li>
<li><p><em>extended</em>: If set, extended emission is prioritized. This may increase
noise on large angular scales.</p></li>
<li><p><em>options</em>: Additional options to pass to the scan map algorithm.  Options
should be specified by key=value pairs, separated by spaces.  For example,
‘rounds=10 sigmaclip=True’.  See <a class="reference internal" href="#scanmap-glossary"><span class="std std-ref">Appendix: Scan Map Option Glossary</span></a> for
a full list of available options.</p></li>
</ul>
</li>
<li><p><strong>scanmappol</strong></p>
<ul>
<li><p><em>save_intermediate</em>: If set, individual output files from the scan
map algorithm are saved in separate files.  This is primarily
for diagnostic use.</p></li>
<li><p><em>vpa_tol</em>: If differences between telescope angles (VPA) within
a scanpol group are more than this value, this step will issue a warning.</p></li>
<li><p><em>use_frames</em>: Frames (time samples) to use from the reduction. Specify
a particular range, as ‘400:-400’ or ‘400:1000’</p></li>
<li><p><em>grid</em>: If set, the output pixel size will be modified from the default
value to the specified value, in arcsec. The output flux scale will also
be modified accordingly, for flux conservation.</p></li>
<li><p><em>deep</em>: If set, faint point-like emission is prioritized.</p></li>
<li><p><em>faint</em>: If set, faint emission (point-like or extended) is prioritized.</p></li>
<li><p><em>extended</em>: If set, extended emission is prioritized. This may increase
noise on large angular scales.</p></li>
<li><p><em>options</em>: Additional options to pass to the scan map algorithm.  Options
should be specified by key=value pairs, separated by spaces.  For example,
‘rounds=10 sigmaclip=True’.  See <a class="reference internal" href="#scanmap-glossary"><span class="std std-ref">Appendix: Scan Map Option Glossary</span></a> for
a full list of available options.</p></li>
</ul>
</li>
<li><p><strong>stokes</strong></p>
<ul>
<li><p><em>erri</em>: Method for inflating errors in I from standard deviation
across HWP angles. Can be median, mean, or none. Default is none.</p></li>
<li><p><em>removeR1stokesi</em>: Set to False to keep the R1 array in the Stokes
I image. Default is True.</p></li>
</ul>
</li>
<li><p><strong>scanstokes</strong></p>
<ul>
<li><p><em>zero_level_method</em>: Statistic for zero-level calculation
(‘mean’, ‘median’, or ‘none’).
If ‘none’, the zero-level will not be corrected.  For the other
options, either a mean or median statistic will be used to
determine the zero-level value from the region set by the
region and radius parameters.</p></li>
<li><p><em>zero_level_region</em>: If set to ‘header’, the zero-level region
will be determined from the ZERO_RA, ZERO_DEC, ZERO_RAD keywords
(for RA center, Dec center, and radius, respectively).
If set to ‘auto’, a mean- or median-filter will be
applied to the R and T images, with the radius specified by the
zero_level_radius parameter.  The lowest negative local
average that is negative in both R and T for all HWP angles
is assumed to be the zero level.  R and T values are applied
separately, from the value of the average at the same pixel.
Otherwise, a region may be directly provided as a list of
[RA center, Dec center, radius], in degrees.</p></li>
<li><p><em>zero_level_radius</em> : Filter radius for zero-level calculation,
in arcseconds (per band).  Used only for zero_level_region = ‘auto’.</p></li>
<li><p><em>zero_level_sigma</em> : Sigma value for statistics clipping.  Ignored for
zero_level_region = ‘auto’.</p></li>
</ul>
</li>
<li><p><strong>wcs</strong></p>
<ul>
<li><p><em>offsibs_x</em>: Offset in pixels along X between SIBS_X and actual
target position on array. Should be a comma-separated list of 5
numbers, one for each band; for example, ‘-0.9, 0.0, 1.1, 0.0,
1.1’. Default may vary over time.</p></li>
<li><p><em>offsibs_y</em>: Offset in pixels along Y between SIBS_Y and actual
target position on array, as for <em>offsibs_x</em>. Default may vary
over time.</p></li>
</ul>
</li>
<li><p><strong>ip</strong></p>
<ul>
<li><p><em>qinst</em>: Fractional instrumental polarization in q. Should be a
comma-separated list of 5 numbers, one for each band; for example,
‘-0.01191, 0.0, -0.01787, -0.00055, -0.01057’. Default may vary
over time.</p></li>
<li><p><em>uinst</em>: Fractional instrumental polarization in u, as for
<em>qinst</em>.</p></li>
<li><p><em>fileip</em>: FITS file specifying IP corrections for each pixel and
band. If set to ‘uniform’, the step will use the <em>qinst</em> and
<em>uinst</em> values; otherwise, these values are ignored if fileip is
specified.</p></li>
</ul>
</li>
<li><p><strong>rotate</strong></p>
<ul>
<li><p><em>gridangle</em>: Detector angle offset, in degrees. Should be a
comma-separated list of 5 numbers, one for each band; for example,
‘-89.69, 0.0, -104.28, 37.42, 119.62’. Default may vary over time.</p></li>
</ul>
</li>
<li><p><strong>bgsubtract</strong></p>
<ul>
<li><p><em>bgslope</em>: Number of iterations to run with slope term. If zero,
slope will not be fit (i.e. residual gains will not be corrected).
Default is 0.</p></li>
<li><p><em>bgoffset</em>: Number of iterations to run with offset term. If zero,
offset will not be fit (i.e. residual background will not be
removed). Default is 10.</p></li>
<li><p><em>qubgsubtract</em>: Set to True to calculate and remove offsets in Q
and U maps, in addition to Stokes I. Default is True; must be set
to False for Chop-Nod data.</p></li>
</ul>
</li>
<li><p><strong>binpixels</strong></p>
<ul>
<li><p><em>block_size</em>: Bin size, in pixels.  The value provided must divide
the 64x40 array evenly into square blocks.  Values 2, 4, or 8 will
work. If set to 1, no binning will be performed. Default value
is 1.</p></li>
</ul>
</li>
<li><p><strong>merge</strong></p>
<ul>
<li><p><em>cdelt</em>: Pixel size in arcseconds of output map, one number per
band. Decrease to sub-sample the input pixels more. Default is
‘1.21, 1.95, 1.95, 3.40, 4.55’, half the detector pixel scale
(beam size / 4).</p></li>
<li><p><em>fwhm</em>: FWHM in arcseconds of Gaussian smoothing kernel, by band.
Make larger for more smoothing. Default is ‘4.84, 7.80, 7.80,
13.6, 18.2’, for beam-size smoothing.</p></li>
<li><p><em>radius</em>: Integration radius for input pixels, by band. Set larger
to consider more pixels when calculating output map. Default is
‘9.68, 15.6, 15.6, 27.2, 36.4’ (beam-size * 2).</p></li>
<li><p><em>fit_order</em>: Polynomial fit order for local regression. Default is 2.</p></li>
<li><p><em>errflag</em>: Set to True to use error image for weighting. Default
is True.</p></li>
<li><p><em>edge_threshold</em>: Threshold to set edge pixels to NaN.
Range is 0-1; 0 means keep all edge pixels. Higher values keep fewer
pixels.</p></li>
<li><p><em>adaptive_algorithm</em>: If ‘shaped’ or ‘scaled’, adaptive smoothing
will be used, varying the kernel size according to the data. If ‘shaped’,
the kernel shape and rotation angle may also vary.  Set to ‘none’ to
turn off adaptive smoothing.</p></li>
<li><p><em>fit_threshold</em>: Deviation from weighted mean to allow for higher order
fit. Set to 0 to turn off.  Positive values replace bad
values with the mean value in the window; negative values
replace bad values with NaN.</p></li>
<li><p><em>bin_cdelt</em>: If set, and data was previously binned via the binpixels
step, then the input cdelt and radius will be multiplied by the binning
factor. If not set, the provided cdelt will be used directly. This
allows useful default behavior for binned data, but still
allows for tunable output pixel sizes.</p></li>
</ul>
</li>
<li><p><strong>region</strong></p>
<ul>
<li><p><em>skip</em>: Set to a number <span class="math notranslate nohighlight">\(i\)</span> to keep vectors every
<span class="math notranslate nohighlight">\(i\)</span>th pixel. Default is 2 (as appropriate for
cdelt=beamsize/4 in merge step).</p></li>
<li><p><em>mini</em>: Do not keep vectors from pixels with Stokes I flux less
than this fraction of peak flux. Default is 0.0.</p></li>
<li><p><em>minisigi</em>: Do not keep vectors from pixels with Stokes I flux
less than this many sigma. Default is 200.</p></li>
<li><p><em>minp</em>: Do not keep vectors with percent polarization less than
this value. Default is 0%.</p></li>
<li><p><em>maxp</em>: Do not keep vectors with percent polarization greater than
this value. Default is 50%.</p></li>
<li><p><em>sigma</em>: Do not keep vectors with <span class="math notranslate nohighlight">\(p / \sigma_p\)</span> less than
this value. Default is 3.0.</p></li>
<li><p><em>length</em>: Scale factor for polarization vectors in DS9 region
file, in pixels. Default is 10 (i.e. a 10% polarization vector is
the length of one pixel).</p></li>
<li><p><em>rotate</em>: Plot rotated (B field) vectors in DS9 region file.
Default is True.</p></li>
<li><p><em>debias</em>: Plot debiased vectors in DS9 region file. Default is
True.</p></li>
</ul>
</li>
<li><p><strong>polmap</strong></p>
<ul>
<li><p><em>maphdu</em>: Extension to use for the plot. Default is ‘STOKES I’.</p></li>
<li><p><em>lowhighscale</em>: [low, high] percentile values to use for image
scaling.  Default is 0.25,99.75.</p></li>
<li><p><em>scalevec</em>: Scale factor for polarization vectors in polmap image.
Default is 0.0003.</p></li>
<li><p><em>scale</em>: If True, plotted vectors are scaled by their magnitude.
If False, all vectors are plotted at the same length.  Default is
True.</p></li>
<li><p><em>rotate</em>: Plot rotated (B field) vectors in polmap image. Default
is True.</p></li>
<li><p><em>debias</em>: Use debiased polarizations for plotting.  Default is True.</p></li>
<li><p><em>colorvec</em>: Color to use for vectors in polmap image. Default is
‘black’.</p></li>
<li><p><em>colormap</em>: Color map to use in polmap image. Default is
‘plasma’.  Any valid Matplotlib color map name may be specified.</p></li>
<li><p><em>ncontours</em>: Number of contour levels.  Set to 0 to turn off contours.
Default is 30.</p></li>
<li><p><em>colorcontour</em>: Color to use for contour lines in polmap image.
Default is ‘gray’.</p></li>
<li><p><em>fillcontours</em>: If True, contours are filled. Default is True.</p></li>
<li><p><em>grid</em>: If True, a coordinate grid is overlaid.  Default is True.</p></li>
<li><p><em>title</em>: Title for the plot.  If set to ‘info’, the title is
auto-generated from the FITS file information.  Any other string
will be used directly as the title.  Default is ‘info’.</p></li>
<li><p><em>centercrop</em>: If True, the plot is cropped to the dimensions specified
in the <em>centercropparams</em>.  Default is False.</p></li>
<li><p><em>centercropparams</em>: Specifies the crop region if <em>centercrop</em> = True.
Should be specified as [RA, Dec, width, height] in decimal degrees.</p></li>
<li><p><em>watermark</em>: If set to a non-empty string, the text will be
added to the lower-right of the image as a semi-transparent watermark.</p></li>
</ul>
</li>
<li><p><strong>imgmap</strong></p>
<ul>
<li><p><em>maphdu</em>: Extension to use for the plot. Default is ‘STOKES I’.</p></li>
<li><p><em>lowhighscale</em>: [low, high] percentile values to use for image
scaling.  Default is 0.25,99.75.</p></li>
<li><p><em>colormap</em>: Color map to use in polmap image. Default is
‘plasma’.  Any valid Matplotlib color map name may be specified.</p></li>
<li><p><em>ncontours</em>: Number of contour levels.  Set to 0 to turn off contours.
Default is 0.</p></li>
<li><p><em>colorcontour</em>: Color to use for contour lines in polmap image.
Default is ‘gray’.</p></li>
<li><p><em>fillcontours</em>: If True, contours are filled. Default is True.</p></li>
<li><p><em>grid</em>: If True, a coordinate grid is overlaid.  Default is False.</p></li>
<li><p><em>title</em>: Title for the plot.  If set to ‘info’, the title is
auto-generated from the FITS file information.  Any other string
will be used directly as the title.  Default is ‘info’.</p></li>
<li><p><em>centercrop</em>: If True, the plot is cropped to the dimensions specified
in the <em>centercropparams</em>.  Default is False.</p></li>
<li><p><em>centercropparams</em>: Specifies the crop region if <em>centercrop</em> = True.
Should be specified as [RA, Dec, width, height] in decimal degrees.</p></li>
<li><p><em>watermark</em>: If set to a non-empty string, the text will be
added to the lower-right of the image as a semi-transparent watermark.</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="data-quality-assessment">
<h2>Data Quality Assessment<a class="headerlink" href="#data-quality-assessment" title="Link to this heading">¶</a></h2>
<p>After the pipeline has been run on a set of input data, the output
products should be checked to ensure that the data has been properly
reduced. Data quality and quirks can vary widely across individual
observations, but the following general guideline gives some strategies
for approaching quality assessment for HAWC+ data.</p>
<p>For any mode:</p>
<ul class="simple">
<li><p>Check the instrument scientist’s log for any data that is known to be
of poor or questionable quality.</p></li>
<li><p>Check the output to the log file (usually called
<em>redux_[date]_[time].log</em>), written to the same directory as the
output files. Look for messages marked ERROR or WARNING. The log will
also list every parameter used in DRP steps, which may help
disambiguate the parameters as actually-run for the pipeline.</p></li>
<li><p>Check that the expected files were written to disk. There should be,
at a minimum, a DMD, WCS, CAL, and PMP file for Nod-Pol data, and a
CRH and CAL file for Scan data.</p></li>
</ul>
<p>For Nod-Pol or Scan-Pol mode:</p>
<ul class="simple">
<li><p>Display all CAL files together. Verify that no one file looks
unreasonably noisy compared to the others, and that any visible
sources appear in the same locations, according to the world
coordinate system in each file’s header. Particular CAL files may
need to be excluded, and the last steps of the pipeline re-run.</p></li>
<li><p>Check the CAL files for persistent bad pixels or detector features.
If present, the flat field or bad pixel mask may need updating.</p></li>
<li><p>Display the final PMP file. Verify that the mapping completed
accurately, with no unexpected or unusual artifacts. The weighting
flags may need modification, or the smoothing may need to be
increased.</p></li>
<li><p>Overlay the DS9 polarization vector file (<em>*.reg</em>) on the PMP file.
Check for unusually noisy vector maps (e.g. long vectors near the
edges).</p></li>
<li><p>For observations of flux standards, compare the total flux in the
source, via aperture photometry, to a known model. Flux calibration
should be within 20%; if it is not, the calibration factors may need
to be adjusted, or some off-nominal data may need to be excluded from
the reduction.</p></li>
<li><p>For observations of polarimetric standards, verify that the total
polarization (Q/I and U/I) is less than 0.6% in regions that should
have zero total polarization. If it is not, the instrumental
polarization parameters may need adjusting.</p></li>
<li><p>Check that sources appear at the expected coordinates. If they do
not, the boresight offsets used by the pipeline may need to be
adjusted.</p></li>
<li><p>Check the FHWM and PSF shape of the source. If it is larger than
expected, or not round, there may have been a problem with telescope
guiding or chopping/nodding.</p></li>
<li><p>If there are output products from the chi2 pipeline, review them for
discrepancies between sets of dithers, or excessive noise or
artifacts.</p></li>
</ul>
<p>For Scan or Scan-Pol mode:</p>
<ul class="simple">
<li><p>Check the log for warnings about scans that may have been excluded
from reduction or are of poor quality.</p></li>
<li><p>Display the final CRH image. Check that no unusual artifacts appear
(e.g. holes or “worms” caused by bad pixels that were not properly
excluded from the scans). Try reducing the data with the <em>-fixjumps</em>
option to see if these artifacts improve.</p></li>
<li><p>Check that the map is not unusually large and does not include
patches disconnected from the main image. These may be signs of poor
tracking during the observation or missing metadata in the input FITS
tables. Try reducing each scan individually to see if a bad scan may
be identified and excluded.</p></li>
<li><p>For observations of flux standards, compare the total flux in the
source, via aperture photometry, to a known model. Flux calibration
should be within 20%; if it is not, the calibration factors or the
opacity correction may need to be adjusted.</p></li>
<li><p>Check the FHWM and PSF shape of the source. If it is larger than
expected, or not round, there may have been a problem with telescope
guiding or focus.</p></li>
<li><p>Check that the source is at the expected coordinates. If not, the
boresight offsets may need to be adjusted. Check the SIBSDX and
SIBSDY keywords in the header.</p></li>
<li><p>If the target is not visible in the default reduction, try reducing
the data with the <em>faint</em> option.  Note: this option should be used
for scan mode only; it should not be used for Scan-Pol observations.</p></li>
<li><p>If the target has extended diffuse emission, it may be beneficial to
try reducing the data with the <em>extended</em> option. If applied to
Scan-Pol observations, compare the polarization maps from the regular
pipeline and the output from the extended parameter. Check for
inconsistent vectors in the polarization map. If not sure of the output,
contact the lead Instrument Scientist for feedback.</p></li>
</ul>
</section>
<section id="appendix-scan-map-option-glossary">
<span id="scanmap-glossary"></span><h2>Appendix: Scan Map Option Glossary<a class="headerlink" href="#appendix-scan-map-option-glossary" title="Link to this heading">¶</a></h2>
<table class="longtable docutils align-default" id="id11">
<caption><span class="caption-number">Table 32 </span><span class="caption-text">Configuration Keywords</span><a class="headerlink" href="#id11" title="Link to this table">¶</a></caption>
<colgroup>
<col style="width: 25.0%" />
<col style="width: 25.0%" />
<col style="width: 50.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Keyword</p></th>
<th class="head"><p>Usage in configuration file</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p id="overf-freq"><strong>1overf.freq</strong></p>
</td>
<td><div class="line-block">
<div class="line">[1overf]</div>
<div class="line">freq=&lt;X&gt;</div>
</div>
</td>
<td><p>The target frequency X (Hz) at which the 1/f is measured for logging
global 1/f noise statistics.  The logged quantity is the ratio of the PSD
measured at this frequency to that measured at the reference frequency
<a class="reference internal" href="#overf-ref">1overf.ref</a>.  The actual measurement frequency will always be above the
filter cutoff of <a class="reference internal" href="#drifts">drifts</a> filtering.</p></td>
</tr>
<tr class="row-odd"><td><p id="overf-ref"><strong>1overf.ref</strong></p>
</td>
<td><div class="line-block">
<div class="line">[1overf]</div>
<div class="line">ref=&lt;X&gt;</div>
</div>
</td>
<td><p>The white noise reference frequency X (Hz) used when providing 1/f noise
statistics.  If the value exceeds the Nyquist frequency of the
timestream, then the Nyquist value will be used instead.  See
<a class="reference internal" href="#overf-freq">1overf.freq</a>.</p></td>
</tr>
<tr class="row-even"><td><div class="line-block" id="accel">
<div class="line"><strong>accel</strong></div>
<div class="line">Alias: correlated.accel-mag</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[accel]</div>
<div class="line">&lt;options…&gt;</div>
</div>
</td>
<td><p>Can be used to enable acceleration response decorrelation, or to set
options for it.  See <a class="reference internal" href="#correlated-modality">correlated.&lt;modality&gt;</a> for available options.</p></td>
</tr>
<tr class="row-odd"><td><p id="aclip"><strong>aclip</strong></p>
</td>
<td><p>aclip=&lt;X&gt;</p></td>
<td><p>Clip data when the telescope acceleration is above X arcsec/s^2. Heavy
accelerations can put mechanical energy into the detector system,
changing the shape of the primary, thereby generating bright signals from
the varying illumination of the bright atmosphere. Clipping data when
there is danger of this happening is a good idea.  See <a class="reference internal" href="#accel">accel</a> for
possible modelling of these signals.</p></td>
</tr>
<tr class="row-even"><td><p id="add"><strong>add</strong></p>
</td>
<td><p>add={&lt;key&gt;, &lt;key&gt;=&lt;value&gt;}, …</p></td>
<td><p>Add a key to the configuration.  If only &lt;key&gt; is given, it’s value will
be set to ‘True’.  Multiple keys and values may be added to the
configuration by supplying a comma-separated list.</p></td>
</tr>
<tr class="row-odd"><td><p id="aliases"><strong>aliases</strong></p>
</td>
<td><div class="line-block">
<div class="line">[aliases]</div>
<div class="line">&lt;branch1&gt;=&lt;alias1&gt;</div>
<div class="line">&lt;branch2&gt;=&lt;alias2&gt;</div>
<div class="line">…</div>
</div>
</td>
<td><p>The [aliases] section specifies user defined convenient shorthand
notations for configuration keywords.  For example, if one defines the
alias sky=correlated.sky, then sky.gainrange will actually
reference correlated.sky.gainrange for any configuration operation.
Aliases may also reference other aliases, so sg=sky.gainrange would allow
sg to reference correlated.sky.gainrange.</p></td>
</tr>
<tr class="row-even"><td><div class="line-block" id="altaz">
<div class="line"><strong>altaz</strong></div>
<div class="line">Sets: system=horizontal</div>
</div>
</td>
<td><p>altaz={True, False}</p></td>
<td><p>A conditional switch to reduce in Alt/Az coordinates.  See <a class="reference internal" href="#system">system</a>.</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="array">
<div class="line"><strong>array</strong></div>
<div class="line">Alias for:  correlated.obs-channels</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[array]</div>
<div class="line">&lt;options…&gt;</div>
</div>
</td>
<td><p>An alias for all radiation-sensitive channels of the instrument, or set
options for it.  See <a class="reference internal" href="#correlated-modality">correlated.&lt;modality&gt;</a> for further details.</p></td>
</tr>
<tr class="row-even"><td><div class="line-block" id="atran-altcoeffs">
<div class="line"><strong>atran.altcoeffs</strong></div>
<div class="line">Instrument: SOFIA</div>
</div>
</td>
<td><p>atran.altcoeffs=&lt;c0&gt;,&lt;c1&gt;,&lt;c2&gt;,…&lt;cN&gt;</p></td>
<td><p>The polynomial coefficients used to determine the altitude factor when
determining the atmospheric transmission correction.  Used to fit for
an altitude relative to 41 kft in units of kft.</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="atran-amcoeffs">
<div class="line"><strong>atran.amcoeffs</strong></div>
<div class="line">Instrument: SOFIA</div>
</div>
</td>
<td><p>atran.amcoeffs=&lt;c0&gt;,&lt;c1&gt;,&lt;c2&gt;,…&lt;cN&gt;</p></td>
<td><p>The polynomial coefficients used to determine the air mass factor when
determining the atmospheric transmission correction.  Used to fit for
the air mass relative to sqrt(2) (an elevation of 45 degrees).</p></td>
</tr>
<tr class="row-even"><td><div class="line-block" id="atran-reference">
<div class="line"><strong>atran.reference</strong></div>
<div class="line">Instrument: SOFIA</div>
</div>
</td>
<td><p>atran.reference=&lt;X&gt;</p></td>
<td><p>The factor (f) used to provide the actual transmission value when
multiplied by the transmission correction value (c).  The
transmission (t) is given as t = f * c where c = am_factor * alt_factor
(see <a class="reference internal" href="#atran-altcoeffs">atran.altcoeffs</a> and <a class="reference internal" href="#atran-amcoeffs">atran.amcoeffs</a>).  The transmission is
related to the opacity (tau) by t = exp(-tau * airmass).</p></td>
</tr>
<tr class="row-odd"><td><p id="beam"><strong>beam</strong></p>
</td>
<td><p>beam=&lt;X&gt;</p></td>
<td><p>Set the instrument beam to X arcseconds.  Also see <a class="reference internal" href="#resolution">resolution</a>.</p></td>
</tr>
<tr class="row-even"><td><div class="line-block" id="beammap">
<div class="line"><strong>beammap</strong></div>
<div class="line">Sets: pixelmap=True</div>
</div>
</td>
<td><p>beammap={True, False}</p></td>
<td><p>A conditional switch that sets <a class="reference internal" href="#pixelmap">pixelmap</a> to True.</p></td>
</tr>
<tr class="row-odd"><td><p id="blacklist"><strong>blacklist</strong></p>
</td>
<td><p>blacklist=&lt;key1&gt;,&lt;key2&gt;,…</p></td>
<td><p>Similar to <a class="reference internal" href="#forget">forget</a>, except it will not set options even if they are
specified at a later time.  This is useful for altogether removing
settings from the configuration.</p></td>
</tr>
<tr class="row-even"><td><p id="blank"><strong>blank</strong></p>
</td>
<td><p>blank=&lt;X&gt;</p></td>
<td><p>Skip data from modelling over points that have a source flux exceeding the
signal-to-noise level X.  This may be useful in reducing the filtering
effect around bright  See <a class="reference internal" href="#clip">clip</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="blind"><strong>blind</strong></p>
</td>
<td><p>blind=&lt;range list&gt;</p></td>
<td><p>Specify a list of blind pixels.  Use data indices and ranges in a
comma-separated form.  Blind channels may be used by some instruments to
estimate instrumental signals, such as temperature fluctuations.
Channels are numbered from 0 (C-style).  See <a class="reference internal" href="#flag">flag</a>.  &lt;range list&gt; is
a comma-separated list of individual channels or channel ranges.  For
example:</p>
<blockquote>
<div><p>blind=10,15:18,33</p>
</div></blockquote>
<p>Would blind channels 10, 15, 16, 17, 18, and 33.</p>
</td>
</tr>
<tr class="row-even"><td><div class="line-block" id="bright">
<div class="line"><strong>bright</strong></div>
<div class="line">Sets: config=bright.cfg</div>
</div>
</td>
<td><p>bright={True, False}</p></td>
<td><p>Use for bright sources (S/N &gt; ~1000).  This setting entirely bypasses all
filtering to produce a very faithful map.  The drawback is more noise.
See <a class="reference internal" href="#config">config</a>, <a class="reference internal" href="#faint">faint</a>, and <a class="reference internal" href="#deep">deep</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="chopped"><strong>chopped</strong></p>
</td>
<td><p>chopped={True, False}</p></td>
<td><p>Used for specifying a chopped data reduction.  Can be set manually or
automatically based on the data itself.  The key
may trigger conditional statements and extra decorrelation steps.
See <a class="reference internal" href="#correlated-modality-trigger">correlated.&lt;modality&gt;.trigger</a>.</p></td>
</tr>
<tr class="row-even"><td><div class="line-block" id="chopper-invert">
<div class="line"><strong>chopper.invert</strong></div>
<div class="line">Instrument: HAWC+</div>
</div>
</td>
<td><p>chopper.invert={True, False}</p></td>
<td><p>An option to flip the direction associated with the analog chopper R/S
signals.</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="chopper-shift">
<div class="line"><strong>chopper.shift</strong></div>
<div class="line">Instrument: HAWC+</div>
</div>
</td>
<td><p>chopper.shift=&lt;N&gt;</p></td>
<td><p>Shift the chopper R/S analog signals by N raw frames (sampled at
203.25 Hz), relative to the detector readout to improve synchronization.
See <a class="reference internal" href="#shift">shift</a>.</p></td>
</tr>
<tr class="row-even"><td><div class="line-block">
<div class="line"><strong>chopper.tolerance</strong></div>
<div class="line">Instrument: HAWC+</div>
</div>
</td>
<td><p>chopper.tolerance=&lt;X&gt;</p></td>
<td><p>Allow setting a tolerance for the chopper position in arcseconds.  If the
actual chopper distance is not within the tolerance from the nominal
chopper amplitude, then the exposure will not be used to avoid smearing.</p></td>
</tr>
<tr class="row-odd"><td><p id="clip"><strong>clip</strong></p>
</td>
<td><p>clip=&lt;X&gt;</p></td>
<td><p>In early generations of the source map, force map pixels with flux below
signal-to-noise level X to zero.   This may help getting lesser
baselines, and filtering artifacts around the brighter peaks.  Often used
together with <a class="reference internal" href="#blank">blank</a> in the intermediate iterations.  See <a class="reference internal" href="#blank">blank</a> and
<a class="reference internal" href="#iteration">iteration</a>.</p></td>
</tr>
<tr class="row-even"><td><div class="line-block" id="cols">
<div class="line"><strong>cols</strong></div>
<div class="line">Alias: correlated.cols</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[cols]</div>
<div class="line">&lt;options…&gt;</div>
</div>
</td>
<td><p>An alias for column based decorrelation of the detector array.  Used to
perform decorrelation, or set decorrelation options.</p></td>
</tr>
<tr class="row-odd"><td><p id="commonwcs"><strong>commonwcs</strong></p>
</td>
<td><p>commonwcs={True, False}</p></td>
<td><p>If the reduction consists of multiple sub-reductions (e.g. a sub
reduction for each HAWC+ subarray), specify that the output map for all
reductions should share a common WCS and equivalent dimensions.</p></td>
</tr>
<tr class="row-even"><td><p id="conditionals"><strong>conditionals</strong></p>
</td>
<td><div class="line-block">
<div class="line">[conditionals]</div>
<div class="line">[[&lt;requirement&gt;]]</div>
<div class="line">&lt;key1&gt;=&lt;value1&gt;</div>
<div class="line">…</div>
</div>
</td>
<td><p>Used to set configuration values in specific circumstances.  Multiple
key=value settings can be applied under each requirement once that
requirement has been fulfilled.  Requirements should take the form
[[&lt;keyword&gt;]] or [[&lt;keyword&gt;&lt;operator&gt;&lt;value&gt;]].  The first will apply
settings should that keyword be set in the configuration.  The more
complex alternative involves comparing one configuration keyword value
with another in the requirement, and apply all settings if evaluated as
true.  &lt;operator&gt; can be one of =, !=, &lt;, &lt;=, &gt;, or &gt;=.</p></td>
</tr>
<tr class="row-odd"><td><p id="config"><strong>config</strong></p>
</td>
<td><p>config=&lt;filename&gt;</p></td>
<td><p>Load a configuration file filename.  Files are looked for in the
following order from lowest to highest priority in the
sofia_scan/scan/data/configurations folder (&lt;c&gt;) and a optional user
configuration directory (~/.sofscan):</p>
<ol class="arabic simple">
<li><p>&lt;c&gt;/&lt;filename&gt;</p></li>
<li><p>~/.sofscan/&lt;filename&gt;</p></li>
<li><p>&lt;c&gt;/&lt;instrument&gt;/&lt;filename&gt;</p></li>
<li><p>~/.sofscan/&lt;instrument&gt;/&lt;filename&gt;</p></li>
</ol>
<p>Whenever a matching file is found, its contents are parsed.  Because of
the ordering, it is convenient to create overriding configurations.  Each
successively loaded file may override the options set before it.
See <a class="reference internal" href="#bright">bright</a>, <a class="reference internal" href="#faint">faint</a>, and <a class="reference internal" href="#deep">deep</a>.</p>
</td>
</tr>
<tr class="row-even"><td><p id="correlated-modality"><strong>correlated.&lt;modality&gt;</strong></p>
</td>
<td><div class="line-block">
<div class="line">[correlated]</div>
<div class="line">[[&lt;modality&gt;]]</div>
<div class="line">&lt;key&gt;=&lt;value&gt;</div>
<div class="line">…</div>
</div>
</td>
<td><p>Remove the correlated noise term across the entire array where &lt;modality&gt;
is the name of the modality on which decorrelation is performed.  E.g.
‘obs-channels’ or ‘gradients’.  This is an effective way of dealing with
most atmospheric and instrumental signals, such as sky noise, ground
pickup, temperature fluctuations, electromagnetic or microphonic pickups.
The decorrelation of each modality can be further controlled by a number
of &lt;key&gt;=&lt;value&gt; settings (see below).  The given decorrelation step must
also appear in the pipeline <a class="reference internal" href="#ordering">ordering</a> before it can be used.  See
<a class="reference internal" href="#division-name">division.&lt;name&gt;</a> and <a class="reference internal" href="#ordering">ordering</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="correlated-modality-gainrange"><strong>correlated.&lt;modality&gt;. gainrange</strong></p>
</td>
<td><div class="line-block">
<div class="line">[correlated]</div>
<div class="line">[[&lt;modality&gt;]]</div>
<div class="line">gainrange=&lt;min&gt;:&lt;max&gt;</div>
</div>
</td>
<td><p>Specify a range of acceptable gains to the given correlated signal
&lt;modality&gt;, relative to the average gain response of the correlated mode.
Channels that exhibit responses outside of this range will be
appropriately flagged in the reduction, and ignored in the modelling
steps until the flag is revised and cleared in another decorrelation
step.  See <a class="reference internal" href="#division-name-gainflag">division.&lt;name&gt;.gainflag</a> and
<a class="reference internal" href="#correlated-modality-signed">correlated.&lt;modality&gt;.signed</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="correlated-modality-nofield"><strong>correlated.&lt;modality&gt;. nofield</strong></p>
</td>
<td><div class="line-block">
<div class="line">[correlated]</div>
<div class="line">[[&lt;modality&gt;]]</div>
<div class="line">nofield={True, False}</div>
</div>
</td>
<td><p>Allow decoupling of the gains of the correlated mode from the gain fields
stored under the channel (initialized from the file specified by
<a class="reference internal" href="#pixeldata">pixeldata</a>).  See <a class="reference internal" href="#pixeldata">pixeldata</a> and <a class="reference internal" href="#source-fixedgains">source.fixedgains</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="correlated-modality-nogains"><strong>correlated.&lt;modality&gt;. nogains</strong></p>
</td>
<td><div class="line-block">
<div class="line">[correlated]</div>
<div class="line">[[&lt;modality&gt;]]</div>
<div class="line">nogains={True, False}</div>
</div>
</td>
<td><p>Disable the solving of gains (i.e. channel responses) to the correlated
signal &lt;modality&gt;.</p></td>
</tr>
<tr class="row-even"><td><p id="correlated-modality-nosignals"><strong>correlated.&lt;modality&gt;. nosignals</strong></p>
</td>
<td><div class="line-block">
<div class="line">[correlated]</div>
<div class="line">[[&lt;modality&gt;]]</div>
<div class="line">nosignals={True, False}</div>
</div>
</td>
<td><p>Disable solving for the correlated signal &lt;modality&gt; whose value stays
fixed.</p></td>
</tr>
<tr class="row-odd"><td><p id="correlated-modality-phases"><strong>correlated.&lt;modality&gt;. phases</strong></p>
</td>
<td><div class="line-block">
<div class="line">[correlated]</div>
<div class="line">[[&lt;modality&gt;]]</div>
<div class="line">phases={True, False}</div>
</div>
</td>
<td><p>Decorrelate the phase data (e.g. for chopped photometry scans) together
with the fast samples.  The same gains are used as for the usual
decorrelation on the fast samples.</p></td>
</tr>
<tr class="row-even"><td><p id="correlated-modality-phasegains"><strong>correlated.&lt;modality&gt;. phasegains</strong></p>
</td>
<td><div class="line-block">
<div class="line">[correlated]</div>
<div class="line">[[&lt;modality&gt;]]</div>
<div class="line">phasegains={True, False}</div>
</div>
</td>
<td><p>Determine the gains from the phase data, rather than from the correlated
fast samples.  You can also set this globally for all correlated
modalities/modes using the <a class="reference internal" href="#phasegains">phasegains</a> keyword.  See <a class="reference internal" href="#phasegains">phasegains</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="correlated-modality-resolution"><strong>correlated.&lt;modality&gt;. resolution</strong></p>
</td>
<td><div class="line-block">
<div class="line">[correlated]</div>
<div class="line">[[&lt;modality&gt;]]</div>
<div class="line">resolution=&lt;X&gt;</div>
</div>
</td>
<td><p>Set the time resolution (in seconds) for the decorrelation of &lt;modality&gt;.
When dealing with 1/f-type signals, you probably want to set this to the
1/f knee time-scale or below if you want optimal sensitivities.  Else,
you may want to try larger values if you want to recover more large-scale
emission and are not too worried about the loss of sensitivity.  See
<a class="reference internal" href="#extended">extended</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="correlated-modality-signed"><strong>correlated.&lt;modality&gt;. signed</strong></p>
</td>
<td><div class="line-block">
<div class="line">[correlated]</div>
<div class="line">[[&lt;modality&gt;]]</div>
<div class="line">signed={True, False}</div>
</div>
</td>
<td><p>by default, gain responses are allowed to be bidirectional, and flagging
affects only those channels or pixels, where absolute gain values fall
outside of the specified range.  When ‘signed’ is set, the gains are
flagged with the signs also taken into account.  I.e., under ‘signed’,
‘gainrange’ or ‘0.3:3.0’ would flag pixels with a gain of -0.8, whereas
the default behaviour is to tolerate them.  See
<a class="reference internal" href="#correlated-modality-gainrange">correlated.&lt;modality&gt;.gainrange</a> and <a class="reference internal" href="#correlated-modality-nogains">correlated.&lt;modality&gt;.nogains</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="correlated-modality-span"><strong>correlated.&lt;modality&gt;. span</strong></p>
</td>
<td><div class="line-block">
<div class="line">[correlated]</div>
<div class="line">[[&lt;modality&gt;]]</div>
<div class="line">span={True, False}</div>
</div>
</td>
<td><p>Make the gains of the correlated modality span scans instead of
integrations (subscans).  You can also set this option for all correlated
modalities at once using the <a class="reference internal" href="#gains-span">gains.span</a> key.</p></td>
</tr>
<tr class="row-even"><td><p id="correlated-modality-trigger"><strong>correlated.&lt;modality&gt;. trigger</strong></p>
</td>
<td><div class="line-block">
<div class="line">[correlated]</div>
<div class="line">[[&lt;modality&gt;]]</div>
<div class="line">trigger=&lt;requirement&gt;</div>
</div>
</td>
<td><p>You can specify a configuration key that is to serve as a trigger for
activating the decorrelation of &lt;modality&gt;.  This is used, for example,
to activate the decorrelation of chopper signals, if and when the
<a class="reference internal" href="#chopped">chopped</a> keyword is specified.  &lt;requirement&gt; may take the form &lt;key&gt;
or &lt;key&gt;&lt;operator&gt;&lt;value&gt;.  If a single &lt;key&gt; is specified, the trigger
will activate if the retrieved value from the configuration evaluates to
True.  Otherwise &lt;operator&gt; (!=, =, &lt;, &lt;=, &gt;, &gt;=) may be used to check
a value in the configuration against &lt;value&gt;.</p></td>
</tr>
<tr class="row-odd"><td><p id="correlated"><strong>correlated.&lt;*&gt;</strong></p>
</td>
<td><p>correlated.*.gainrange=0.3:3.0</p></td>
<td><p>You can use wildcards ‘*’ to set options for all decorrelation steps at
once.  The above example sets the <a class="reference internal" href="#correlated-modality-gainrange">correlated.&lt;modality&gt;.gainrange</a>
value for all currently defined branches (and modalities) to 0.3:3.</p></td>
</tr>
<tr class="row-even"><td><p id="crushbugs"><strong>crushbugs</strong></p>
</td>
<td><p>crushbugs={True, False}</p></td>
<td><p>Allow SOFSCAN to replicate some of the most prominent bugs found in the
original CRUSH.  These bugs currently include:</p>
<ol class="arabic simple">
<li><p>Double adding of frame (time) dependents for FFT fixed filters
(see <a class="reference internal" href="#filter">filter</a>).</p></li>
<li><p>Adding frame (time) dependents N times rather than once during
integration syncing with the source model, where N is the number of
channels.</p></li>
</ol>
<p>The above issues become noticeable after many iterations (see <a class="reference internal" href="#rounds">rounds</a>)
since the fraction by which dependents change are usually very small.
However, after a while you may notice some data being flagged
unnecessarily.  There is a significant bug that has not been covered by
<a class="reference internal" href="#crushbugs">crushbugs</a> in which the real and imaginary interleaved FFT spectrum
(realf0, imagf0, realf1, imagf1, realf2…), as determined by the <a class="reference internal" href="#filter">filter</a>
step, is subtracted from the timestream in addition to it’s inverse
transform (correct method of removal).</p>
</td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="darkcorrect">
<div class="line"><strong>darkcorrect</strong></div>
<div class="line">Instrument: HAWC+</div>
</div>
</td>
<td><p>darkcorrect={True,False}</p></td>
<td><p>Whether to perform the squid dark correction for blind channels.
Otherwise, all blind channels will be flagged as dead.</p></td>
</tr>
<tr class="row-even"><td><p id="datapath"><strong>datapath</strong></p>
</td>
<td><p>datapath=&lt;directory&gt;</p></td>
<td><p>Look for raw data to reduce in the directory &lt;directory&gt;.</p></td>
</tr>
<tr class="row-odd"><td><p id="dataunit"><strong>dataunit</strong></p>
</td>
<td><p>dataunit=&lt;name&gt;</p></td>
<td><p>Specify the units in which the data are stored.  Typically, ‘counts’ or
‘V’, or any of their common multiples such as ‘mV’, ‘uV’ or astropy.units
unit types are accepted.  The conversion from data units to Jansky-based
units is set via the <a class="reference internal" href="#jansky">jansky</a> option, while the choice of units in the
data reduction is set be <a class="reference internal" href="#unit">unit</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="date"><strong>date</strong></p>
</td>
<td><div class="line-block">
<div class="line">[date]</div>
<div class="line">[[&lt;start&gt;–&lt;end&gt;]]</div>
<div class="line">&lt;key&gt;=&lt;value&gt;</div>
<div class="line">…</div>
</div>
</td>
<td><p>A way to set date specific conditional statements.  &lt;start&gt; and &lt;end&gt;
can be specified as ISOT strings or float MJD values, both in the UTC
scale.  Wildcards (‘*’) may also be used to unbound the start or end
time.  E.g.:</p>
<div class="line-block">
<div class="line">[date]</div>
<div class="line">[[2021-12-14T10:00:00–<code class="xref py py-obj docutils literal notranslate"><span class="pre">*</span></code>]]</div>
<div class="line">instrument.gain=-1000</div>
<div class="line">chopped=True</div>
</div>
<p>would set the instrument gain to -1000, and indicate chopped observations
for any time after 10:00 UTC on December 12, 2021.</p>
</td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="deep">
<div class="line"><strong>deep</strong></div>
<div class="line">Sets: config=deep.cfg</div>
</div>
</td>
<td><p>deep={True, False}</p></td>
<td><p>Use for very faint sources which are not all detected in single scans, or
if you think there is too much residual noise (baselines) in the map.
This setting results in the most aggressive filtering and will load the
configuration from ‘deep.cfg’.  The output map is optimally filtered
(smoothed) for point sources.  See <a class="reference internal" href="#config">config</a>, <a class="reference internal" href="#bright">bright</a>, and <a class="reference internal" href="#faint">faint</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="dejump"><strong>dejump</strong></p>
</td>
<td><div class="line-block">
<div class="line">[dejump]</div>
<div class="line">&lt;options…&gt;</div>
</div>
</td>
<td><p>Used to specify options for the ‘dejump’ task which identifies places in
the data stream where detectors jump together (especially SQUIDs under a
transient B-field fluctuation) by the perceived increase in residual
detector noise.  Sub-settings are <a class="reference internal" href="#dejump-level">dejump.level</a> and
<a class="reference internal" href="#dejump-minlength">dejump.minlength</a>.  This will only occur if ‘dejump’ appears in
<a class="reference internal" href="#ordering">ordering</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="dejump-level"><strong>dejump.level</strong></p>
</td>
<td><p>dejump.level=&lt;X&gt;</p></td>
<td><p>The relative noise level at which jumps are identified.  The value should
be strictly greater than 1, with 2.0 being a safe starting point.  Change
with extreme caution, if at all.  See <a class="reference internal" href="#dejump">dejump</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="dejump-minlength"><strong>dejump.minlength</strong></p>
</td>
<td><p>dejump.minlength=&lt;X&gt;</p></td>
<td><p>The minimum length (in seconds) of a coincident detector jump that is
kept alive in the data.  Jumps longer than this threshold will be
re-levelled, wheras shorted jumps will be flagged out entirely.  See
<a class="reference internal" href="#dejump">dejump</a>.</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="derive">
<div class="line"><strong>derive</strong></div>
<div class="line">Sets:</div>
<div class="line">forget = pixeldata, vclip, aclip</div>
<div class="line">blacklist = whiten</div>
<div class="line">write.pixeldata = True</div>
<div class="line">rounds = 30</div>
</div>
</td>
<td><p>derive={True, False}</p></td>
<td><p>A conditional switch which when activated will perform a reduction
suitable for deriving pixel data.  See <a class="reference internal" href="#write-pixeldata">write.pixeldata</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="despike"><strong>despike</strong></p>
</td>
<td><div class="line-block">
<div class="line">[despike]</div>
<div class="line">&lt;options…&gt;</div>
</div>
</td>
<td><p>Used to define despiking options.  SOFSCAN allows the use of up to three
different spiking steps, each configurable on its own.  In order to be
enabled, ‘despike’ must be specified in <a class="reference internal" href="#ordering">ordering</a>.  To specify a
despiking method, S/N levels and flagging criteria, please see the
various despiking options below.</p></td>
</tr>
<tr class="row-odd"><td><p id="despike-blocks"><strong>despike.blocks</strong></p>
</td>
<td><p>despike.blocks={True, False}</p></td>
<td><p>Flag out an entire ‘drifts’ block of data around any spikes found.  This
is probably an overkill in most cases, but may be useful if spikes are
due to discontinuities (jumps) in individual detectors.  See <a class="reference internal" href="#drifts">drifts</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="despike-flagcount"><strong>despike.flagcount</strong></p>
</td>
<td><p>despike.flagcount=&lt;N&gt;</p></td>
<td><p>Tolerate (without pixel flagging) up to N spikes in each pixel.</p></td>
</tr>
<tr class="row-odd"><td><p id="despike-flagfraction"><strong>despike.flagfraction</strong></p>
</td>
<td><p>dispike.flagfraction=&lt;X&gt;</p></td>
<td><p>Tolerate (without pixel flagging) spikes up to fraction X of the scan
frames in each channel.</p></td>
</tr>
<tr class="row-even"><td><p id="despike-framespikes"><strong>despike.framespikes</strong></p>
</td>
<td><p>despike.framespikes=&lt;N&gt;</p></td>
<td><p>Tolerate up to N spikes per frame.</p></td>
</tr>
<tr class="row-odd"><td><p id="despike-level"><strong>despike.level</strong></p>
</td>
<td><p>despike.level=&lt;X&gt;</p></td>
<td><p>Despike at an S/N level of X.</p></td>
</tr>
<tr class="row-even"><td><p id="despike-method"><strong>despike.method</strong></p>
</td>
<td><p>despike.method=&lt;name&gt;</p></td>
<td><p>SOFSCAN offsets a choice of despiking methods to choose from.  Each of
these have their own pros and cons, and may produce different results and
side effects in different environments.  The following methods are
currently available:</p>
<ul class="simple">
<li><p><em>neighbours</em>: Despike by comparing neighbouring samples of data from
the same channel.</p></li>
<li><p><em>absolute</em>: Flag data that deviates by the specified S/N level
(<a class="reference internal" href="#despike-level">despike.level</a>).</p></li>
<li><p><em>gradual</em>: Like <em>absolute</em> but proceeds more cautiously, removing only
a fraction of the most offending spikes at each turn.</p></li>
<li><p><em>multires</em>: Look for spikes wider than just a single sample.</p></li>
</ul>
<p>All methods will flag pixels and frames if these have too many spikes.
The flagging of spiky channels and frames is controlled by the
<a class="reference internal" href="#despike-flagcount">despike.flagcount</a>, <a class="reference internal" href="#despike-flagfraction">despike.flagfraction</a>, and <a class="reference internal" href="#despike-framespikes">despike.framespikes</a>
keys.</p>
</td>
</tr>
<tr class="row-odd"><td><p id="division-name"><strong>division.&lt;name&gt;</strong></p>
</td>
<td><div class="line-block">
<div class="line">[division]</div>
<div class="line">[[&lt;name&gt;]]</div>
<div class="line">value=&lt;group1&gt;,&lt;group2&gt;,…</div>
</div>
</td>
<td><p>An option to specify user-defined channel divisions containing specific
channel groups.  This may be useful when creating a new modality.  All
named groups must be available in the reduction in order to be included
in the &lt;name&gt; division.  A channel division contains all channel groups
relating to a modality of the same name.  See <a class="reference internal" href="#correlated-modality">correlated.&lt;modality&gt;</a>,
<a class="reference internal" href="#division-name-gainfield">division.&lt;name&gt;.gainfield</a>, <a class="reference internal" href="#division-name-gainflag">division.&lt;name&gt;.gainflag</a>,
<a class="reference internal" href="#division-name-id">division.&lt;name&gt;.id</a>, and <a class="reference internal" href="#group">group</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="division-name-gainfield"><strong>division.&lt;name&gt;.gainfield</strong></p>
</td>
<td><div class="line-block">
<div class="line">[division]</div>
<div class="line">[[&lt;name&gt;]]</div>
<div class="line">gainfield=&lt;attribute&gt;</div>
</div>
</td>
<td><p>Specify which attribute of the channel data such as ‘coupling’ or
‘nonlinearity’ should be used to provide gain values for the correlated
modality &lt;name&gt;.  See <a class="reference internal" href="#correlated-modality">correlated.&lt;modality&gt;</a> and <a class="reference internal" href="#division-name">division.&lt;name&gt;</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="division-name-gainflag"><strong>division.&lt;name&gt;.gainflag</strong></p>
</td>
<td><div class="line-block">
<div class="line">[division]</div>
<div class="line">[[&lt;name&gt;]]</div>
<div class="line">gainflag={&lt;N&gt;, &lt;flag&gt;}</div>
</div>
</td>
<td><p>Set the gain flag used for flagging out-of-range gain values for the
correlated modality &lt;name&gt;.  An integer (&lt;N&gt;) or flag name (&lt;flag&gt;) may
be specified.  Take care if using an integer to ensure its value matches
the desired flag.  If not specified, the default is ‘GAIN’.</p></td>
</tr>
<tr class="row-even"><td><p id="division-name-id"><strong>division.&lt;name&gt;.id</strong></p>
</td>
<td><div class="line-block">
<div class="line">[division]</div>
<div class="line">[[&lt;name&gt;]]</div>
<div class="line">id=&lt;ID&gt;</div>
</div>
</td>
<td><p>Specify a shorthand ID for the modality &lt;name&gt;.  This is usually a
two-letter abbreviation of &lt;name&gt;.  If not supplied, defaults to &lt;name&gt;.</p></td>
</tr>
<tr class="row-odd"><td><p id="downsample"><strong>downsample</strong></p>
</td>
<td><p>downsample={N, auto}</p></td>
<td><p>Downsample the data by a factor of N.  At times the raw data is sampled
at unnecessarily high frequencies.  By downsampling, you can ease the
memory requirement and speed up the reduction.  You can also set the
value to ‘auto’ (default), in which case an optimal downsampling rate is
determined based on the typical scanning speeds so that the loss of
information will be insignificant due to unintended smearing of the data.</p></td>
</tr>
<tr class="row-even"><td><p id="drifts"><strong>drifts</strong></p>
</td>
<td><p>drifts={X, max, auto}</p></td>
<td><p>Filter low frequencies below the characteristic timescale of X seconds as
an effective way of dealing with 1/f noise.  You can also use ‘auto’
to determine the filtering timescales automatically, based on
<a class="reference internal" href="#sourcesize">sourcesize</a>, scanning speeds and instrument <a class="reference internal" href="#stability">stability</a> time-scales.  The
‘max’ value is also accepted, producing results identical to that of
<a class="reference internal" href="#offsets">offsets</a>.</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="ecliptic">
<div class="line"><strong>ecliptic</strong></div>
<div class="line">Sets: system=ecliptic</div>
</div>
</td>
<td><p>ecliptic={True, False}</p></td>
<td><p>Reduce using ecliptic coordinates (for mapping).</p></td>
</tr>
<tr class="row-even"><td><div class="line-block" id="equatorial">
<div class="line"><strong>equatorial</strong></div>
<div class="line">Sets: system=equatorial</div>
</div>
</td>
<td><p>equatorial={True, False}</p></td>
<td><p>Reduce using equatorial coordinates (for mapping).</p></td>
</tr>
<tr class="row-odd"><td><p id="estimator"><strong>estimator</strong></p>
</td>
<td><p>estimator={median, maximum-likelihood}</p></td>
<td><p>The estimator to use in deriving signal models.  ‘median’ estimators are
less sensitive to the presence of bright sources in the data, therefore
it is the default for when <a class="reference internal" href="#bright">bright</a> is specified (see ‘bright.cfg’).
When medians are used, the corresponding models are reported on the log
output in square brackets ([]).  See <a class="reference internal" href="#gains-estimator">gains.estimator</a> and
<a class="reference internal" href="#weighting-method">weighting.method</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="exposureclip"><strong>exposureclip</strong></p>
</td>
<td><p>exposureclip=&lt;X&gt;</p></td>
<td><p>Flag (clip) map pixels whose relative time coverage is less than the
specified value X.  This is helpful for discarding the underexposed noisy
edges of the map.  See <a class="reference internal" href="#noiseclip">noiseclip</a> and <a class="reference internal" href="#clip">clip</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="extended"><strong>extended</strong></p>
</td>
<td><p>extended={True, False}</p></td>
<td><p>Try to better preserve extended structures.  This setting can be used
alone or in combination with brightness options.  For bright structures
recovery up to FOV (or beyond) should be possible.  Faint structures
~1/4 FOV to ~FOV scales are maximally obtainable.  See <a class="reference internal" href="#sourcesize">sourcesize</a>,
<a class="reference internal" href="#bright">bright</a>, <a class="reference internal" href="#faint">faint</a>, and <a class="reference internal" href="#deep">deep</a>.</p></td>
</tr>
<tr class="row-even"><td><div class="line-block" id="faint">
<div class="line"><strong>faint</strong></div>
<div class="line">Sets: config=faint.cfg</div>
</div>
</td>
<td><p>faint={True, False}</p></td>
<td><p>Use with faint sources (S/N &lt; ~30) when the source is faint but still
visible in a single scan.  This setting applies some more aggressive
filtering of the timestreams, and extended structures.  It will result
in applying the configuration settings found in ‘faint.cfg’.  See <a class="reference internal" href="#bright">bright</a>
and <a class="reference internal" href="#deep">deep</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="fifi-ls-insert-source"><strong>fifi_ls.insert_source</strong></p>
</td>
<td><div class="line-block">
<div class="line">[fifi_ls]</div>
<div class="line">insert_source={True, False}</div>
</div>
</td>
<td><p>Used in conjunction with <a class="reference internal" href="#fifi-ls-resample">fifi_ls.resample</a>.  If True, the source
model is injected back into the irregular frame data.  If False, the
detected correlations and drifts are removed from the original frame
data.  If using a filter, it is advisable to set this parameter to
True, as the filtered signals cannot be removed from the original data.</p></td>
</tr>
<tr class="row-even"><td><p id="fifi-ls-resample"><strong>fifi_ls.resample</strong></p>
</td>
<td><div class="line-block">
<div class="line">[fifi_ls]</div>
<div class="line">resample={True, False}</div>
</div>
</td>
<td><p>If set to True, and reducing FIFI-LS data, instructs the reduction to
perform a few additional steps post-reduction.  This is to set the
irregular frame data to a state where it can then be manually passed
into a more robust resampler to generate a final output map, rather
than using the default nearest neighbor method.  Please see
<a class="reference internal" href="#fifi-ls-insert-source">fifi_ls.insert_source</a> for more details.</p></td>
</tr>
<tr class="row-odd"><td><p id="fifi-ls-uncorrected"><strong>fifi_ls.uncorrected</strong></p>
</td>
<td><div class="line-block">
<div class="line">[fifi_ls]</div>
<div class="line">uncorrected={True, False}</div>
</div>
</td>
<td><p>If set to True, and reducing FIFI-LS data, instructs the reduction to
use the uncorrected wavelength, data, and error values present in the
UNCORRECTED_LAMBDA, UNCORRECTED_FLUX, and UNCORRECTED_STDDEV HDUs rather
than the LAMBDA, FLUX, and STDDEV HDUs.</p></td>
</tr>
<tr class="row-even"><td><p id="fillgaps"><strong>fillgaps</strong></p>
</td>
<td><p>fillgaps={True, False}</p></td>
<td><p>Fill any gaps in the timestream data with empty frames so that time
windows in the reduction work as expected and that no surprise
discontinuities can cause real trouble.</p></td>
</tr>
<tr class="row-odd"><td><p id="filter"><strong>filter</strong></p>
</td>
<td><div class="line-block">
<div class="line">[filter]</div>
<div class="line">value={True, False}</div>
</div>
</td>
<td><p>Activate spectral filtering of timestreams.  The filter components are
set by <a class="reference internal" href="#filter-ordering">filter.ordering</a> and can be configured and activated separately.
See <a class="reference internal" href="#crushbugs">crushbugs</a>, <a class="reference internal" href="#filter-ordering">filter.ordering</a>, <a class="reference internal" href="#filter-motion">filter.motion</a>, <a class="reference internal" href="#filter-kill">filter.kill</a>,
and <a class="reference internal" href="#filter-whiten">filter.whiten</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="filter-kill"><strong>filter.kill</strong></p>
</td>
<td><div class="line-block">
<div class="line">[filter]</div>
<div class="line">[[kill]]</div>
<div class="line">value={True, False}</div>
</div>
</td>
<td><p>Allows completely quenching certain frequencies in the timestream data.
To activate, both this option and the <a class="reference internal" href="#filter">filter</a> umbrella option must
evaluate as True.  The bands of the kill-filter are set by
<a class="reference internal" href="#filter-kill-bands">filter.kill.bands</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="filter-kill-bands"><strong>filter.kill.bands</strong></p>
</td>
<td><div class="line-block">
<div class="line">[filter]</div>
<div class="line">[[kill]]</div>
<div class="line">bands=&lt;f1&gt;:&lt;f2&gt;, &lt;f3&gt;:&lt;f4&gt;, …</div>
</div>
</td>
<td><p>Provide a comma-separated list of frequency ranges (Hz) that are to be
quenched by the kill filter.  E.g.:</p>
<blockquote>
<div><p>filter.kill.bands=0.35:0.37,9.8:10.2.</p>
</div></blockquote>
<p>See <a class="reference internal" href="#filter">filter</a> and <a class="reference internal" href="#filter-kill">filter.kill</a>.</p>
</td>
</tr>
<tr class="row-even"><td><p id="filter-motion"><strong>filter.motion</strong></p>
</td>
<td><div class="line-block">
<div class="line">[filter]</div>
<div class="line">[[motion]]</div>
<div class="line">value={True, False}</div>
</div>
</td>
<td><p>The (typically) periodic motion of the scanning can induce vibrations in
the telescope and instrument.  Since these signals will be in sync with
the scanning motion, they will produce definite mapping artifacts (e.g.
broad pixels near the map edges).  The motion filter lets you perform
spectral filtering on those frequencies where most of the scanning motion
is concentrated.  To activate, bot this option and the <a class="reference internal" href="#filter">filter</a> umbrella
options must be set.  The identification of rejected motion frequencies
is controlled by the <a class="reference internal" href="#filter-motion-s2n">filter.motion.s2n</a> <a class="reference internal" href="#filter-motion-above">filter.motion.above</a>, and
<a class="reference internal" href="#filter-motion-range">filter.motion.range</a> sub-keys.</p></td>
</tr>
<tr class="row-odd"><td><p id="filter-motion-above"><strong>filter.motion.above</strong></p>
</td>
<td><div class="line-block">
<div class="line">[filter]</div>
<div class="line">[[motion]]</div>
<div class="line">above=X</div>
</div>
</td>
<td><p>The fraction, relative to the peak spectral component of the scanning
motion, above which to filter motion.  E.g.:</p>
<blockquote>
<div><p>filter.motion.above=0.1</p>
</div></blockquote>
<p>will identify components that are at least 10% of the main component
amplitude.  See <a class="reference internal" href="#filter-motion">filter.motion</a>, <a class="reference internal" href="#filter-motion-s2n">filter.motion.s2n</a>, and
<a class="reference internal" href="#filter-motion-range">filter.motion.range</a>.</p>
</td>
</tr>
<tr class="row-even"><td><p id="filter-motion-harmonics"><strong>filter.motion.harmonics</strong></p>
</td>
<td><div class="line-block">
<div class="line">[filter]</div>
<div class="line">[[motion]]</div>
<div class="line">harmonics=&lt;N&gt;</div>
</div>
</td>
<td><p>Kill not just the dominant motion frequencies, but also up to N harmonics
of these.  This may be useful when the motion response is non-linear.
Otherwise, it’s an overkill.  See <a class="reference internal" href="#filter-motion-odd">filter.motion.odd</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="filter-motion-odd"><strong>filter.motion.odd</strong></p>
</td>
<td><div class="line-block">
<div class="line">[filter]</div>
<div class="line">[[motion]]</div>
<div class="line">odd={True, False}</div>
</div>
</td>
<td><p>When set, together with the <a class="reference internal" href="#filter-motion-harmonics">filter.motion.harmonics</a> setting, this
option instructs SOFSCAN to restrict the motion filter to the odd
harmonics only of the principle frequencies of the scanning motion.
See <a class="reference internal" href="#filter-motion-harmonics">filter.motion.harmonics</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="filter-motion-range"><strong>filter.motion.range</strong></p>
</td>
<td><div class="line-block">
<div class="line">[filter]</div>
<div class="line">[[motion]]</div>
<div class="line">range=&lt;min&gt;:&lt;max&gt;</div>
</div>
</td>
<td><p>Set the frequency range (Hz) in which the motion filter operates.  See
<a class="reference internal" href="#filter-motion">filter.motion</a>, <a class="reference internal" href="#filter-motion-above">filter.motion.above</a>, and <a class="reference internal" href="#filter-motion-s2n">filter.motion.s2n</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="filter-motion-s2n"><strong>filter.motion.s2n</strong></p>
</td>
<td><div class="line-block">
<div class="line">[filter]</div>
<div class="line">[[motion]]</div>
<div class="line">s2n=&lt;X&gt;</div>
</div>
</td>
<td><p>The minimum significance of the motion spectral component to be
considered for filtering.  See <a class="reference internal" href="#filter-motion">filter.motion</a>, <a class="reference internal" href="#filter-motion-above">filter.motion.above</a>,
and <a class="reference internal" href="#filter-motion-range">filter.motion.range</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="filter-motion-stability"><strong>filter.motion.stability</strong></p>
</td>
<td><div class="line-block">
<div class="line">[filter]</div>
<div class="line">[[motion]]</div>
<div class="line">stability=&lt;X&gt;</div>
</div>
</td>
<td><p>Define a stability timescale (seconds) for the motion response.  When not
set, it is assumed that the detectors respond to the same amount to the
vibrations induced by the scanning motion during the entire duration of a
scan.  If a timescale shorter than the scan length is set, then the
filtering will become more aggressive to incorporate the AM modulation of
detector signals on timescales shorter than this stability value.  See
<a class="reference internal" href="#filter-motion-range">filter.motion.range</a> and <a class="reference internal" href="#filter-motion-stability">filter.motion.stability</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="filter-mrproper"><strong>filter.mrproper</strong></p>
</td>
<td><div class="line-block">
<div class="line">[filter]</div>
<div class="line">mrproper={True, False}</div>
</div>
</td>
<td><p>Enables the explicit re-levelling of the filtered signal.  In practice,
the re-levelling is unlikely to significantly improve the filter’s
effectiveness.  At the same time, it does slow it down somewhat, which is
why it is off by default.</p></td>
</tr>
<tr class="row-even"><td><p id="filter-ordering"><strong>filter.ordering</strong></p>
</td>
<td><div class="line-block">
<div class="line">[filter]</div>
<div class="line">ordering=&lt;filter1&gt;,&lt;filter2&gt;,…</div>
</div>
</td>
<td><p>A comma-separated list of spectral filters, in the order they are to be
applied.  The default is ‘motion, kill, whiten’ which firstly applies the
motion filter, then kills specified spectral bands, and finally applies
noise whitening on the remainder.  Each of the components can be
controlled separately with the appropriate sub-keys of <a class="reference internal" href="#filter">filter</a> with the
same names.  See <a class="reference internal" href="#filter-motion">filter.motion</a>, <a class="reference internal" href="#filter-whiten">filter.whiten</a>, and <a class="reference internal" href="#filter-kill">filter.kill</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="filter-whiten"><strong>filter.whiten</strong></p>
</td>
<td><div class="line-block">
<div class="line">[filter]</div>
<div class="line">[[whiten]]</div>
<div class="line">value={True, False}</div>
</div>
</td>
<td><p>Use a noise whitening algorithm.  White noise assures that the noise in
the map is independent pixel-to=pixel.  Otherwise noise may be correlated
on specific scales.  Whitening is also useful to get rid of any signals
(still) not modelled by other reduction steps.  It should always be a
last resort only, as the modeling of signals is generally preferred.  To
activate, both this option and the <a class="reference internal" href="#filter">filter</a> umbrella option must evaluate
to True.  See <a class="reference internal" href="#filter">filter</a>, <a class="reference internal" href="#whiten">whiten</a>, <a class="reference internal" href="#filter-whiten-level">filter.whiten.level</a>,
<a class="reference internal" href="#filter-whiten-minchannels">filter.whiten.minchannels</a>, and <a class="reference internal" href="#filter-whiten-proberange">filter.whiten.proberange</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="filter-whiten-level"><strong>filter.whiten.level</strong></p>
</td>
<td><div class="line-block">
<div class="line">[filter]</div>
<div class="line">[[whiten]]</div>
<div class="line">level=&lt;X&gt;</div>
</div>
</td>
<td><p>Specify the noise whitening level at X times the average (median)
spectral noise level.  Spectral channels that have noise in excess of the
critical level will be appropriately filtered to bring them back in line.
Value clearly above 1 are recommended, and typically values around
1.5-2 are useful without over filtering.  See <a class="reference internal" href="#filter-whiten">filter.whiten</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="filter-whiten-minchannels"><strong>filter.whiten.minchannels</strong></p>
</td>
<td><div class="line-block">
<div class="line">[filter]</div>
<div class="line">[[whiten]]</div>
<div class="line">minchannels=&lt;N&gt;</div>
</div>
</td>
<td><p>Make sure that at least N channels are used for estimating the white
noise levels, even if the specified probe range is smaller of falls
outside of the available spectrum.  In such cases, SOFSCAN will
automatically expand the requested range to include at least N spectral
channels, or as many as possible if the spectral range itself is too
small.  See <a class="reference internal" href="#filter-whiten">filter.whiten</a> and <a class="reference internal" href="#filter-whiten-proberange">filter.whiten.proberange</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="filter-whiten-proberange"><strong>filter.whiten.proberange</strong></p>
</td>
<td><div class="line-block">
<div class="line">[filter]</div>
<div class="line">[[whiten]]</div>
<div class="line">proberange={&lt;from&gt;:&lt;to&gt;, auto}</div>
</div>
</td>
<td><p>Specify the spectral range (Hz) in which to measure the white noise level
before whitening.  It is best to use the truly flat part of the available
spectral range where no 1/f, resonances, or lowpass roll-off are present.
Wildcards (‘*’) can be used for specifying open ranges.  ‘auto` can be
used to automatically adjust the probing range to the upper part of the
spectrum occupied by point sources.  See <a class="reference internal" href="#filter-whiten">filter.whiten</a> and
<a class="reference internal" href="#filter-whiten-minchannels">filter.whiten.minchannels</a>.</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="final">
<div class="line"><strong>final</strong></div>
<div class="line">Alias: iteration.-1</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[final]</div>
<div class="line">&lt;key&gt;=&lt;value&gt;</div>
<div class="line">…</div>
</div>
</td>
<td><p>An alias for settings to be applied on the last iteration.  See <a class="reference internal" href="#last">last</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="fits-key"><strong>fits.&lt;key&gt;</strong></p>
</td>
<td><p>&lt;configuration_key&gt;={?fits.&lt;key&gt;}</p></td>
<td><p>A way to reference FITS header keyword values from the configuration.
For example:</p>
<blockquote>
<div><p>intcalfreq={?fits.DIAG_HZ}</p>
</div></blockquote>
<p>will always retrieve ‘intcalfreq’ in the configuration from the ‘DIAG_HZ’
key in the FITS header.</p>
</td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="fits-addkeys">
<div class="line"><strong>fits.addkeys</strong></div>
<div class="line">Telescope: SOFIA</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[fits]</div>
<div class="line">addkeys=&lt;key1&gt;,&lt;key2&gt;,…</div>
</div>
</td>
<td><p>Specify a comma-separated list of keys that should be migrated from the
first scan to the image header, in addition to the list of required SOFIA
header keys.</p></td>
</tr>
<tr class="row-even"><td><div class="line-block" id="fixjumps">
<div class="line"><strong>fixjumps</strong></div>
<div class="line">Instrument: HAWC+</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[fixjumps]</div>
<div class="line">value={True, False}</div>
</div>
</td>
<td><p>Attempt to ‘fix’ residual flux jumps that result from imprecise
correction in the MCE.  Long jumps are re-levelled, while shorter ones
are flagged out to minimize impact on source structure.  Alternatively,
the same can be applied on a per-subarray basis as well as via the
<a class="reference internal" href="#fixjumps-sub">fixjumps.&lt;sub&gt;</a> option.</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="fixjumps-detect">
<div class="line"><strong>fixjumps.detect</strong></div>
<div class="line">Instrument: HAWC+</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[fixjumps]</div>
<div class="line">detect = &lt;X&gt;</div>
</div>
</td>
<td><p>If <a class="reference internal" href="#fixjumps">fixjumps</a> is set to True, attempt to locate and correct any
unreported jumps in the data.  &lt;X&gt; is a threshold value used to locate
possible jumps such that diff = d - shift(d, 1), mad = medabsdev(diff),
and possible jumps occur at abs(diff) &gt;= &lt;X&gt; * mad.</p></td>
</tr>
<tr class="row-even"><td><div class="line-block" id="fixjumps-sub">
<div class="line"><strong>fixjumps.&lt;sub&gt;</strong></div>
<div class="line">Instrument: HAWC+</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[fixjumps]</div>
<div class="line">&lt;sub&gt; = {True, False}</div>
</div>
</td>
<td><p>The same as <a class="reference internal" href="#fixjumps">fixjumps</a> but performed on a per-subarray basis.  &lt;sub&gt;
may be currently one of {r0, r1, t0, t1}.</p></td>
</tr>
<tr class="row-odd"><td><p id="flag"><strong>flag</strong></p>
</td>
<td><div class="line-block">
<div class="line">[flag]</div>
<div class="line">&lt;field&gt;=&lt;list&gt;</div>
<div class="line">…</div>
</div>
</td>
<td><p>Flag channels based on ranges of values or values within certain ranges.
Here, &lt;field&gt; refers to a specific attribute of the channel data on which
to base the flagging.  For example:</p>
<div class="line-block">
<div class="line">[flag]</div>
<div class="line">col=10,20:22</div>
<div class="line">pin_gain=-1:0</div>
</div>
<p>Would flag channel columns 10, 20, 21, and 22 and any channels where
pin gain is between -1 and 0.  All such channels will be flagged as
‘DEAD’ and this process occurs only once following a scan read.  Note
that &lt;list&gt; may contain range elements with <code class="xref py py-obj docutils literal notranslate"><span class="pre">*</span></code> marking an open bound.
the colon (:) is preferred over hyphen (-) to mark ranges in order to
effectively distinguish negative numbers, although a hyphen will still
work as expected for purely positive values.</p>
</td>
</tr>
<tr class="row-even"><td><p id="flatweights"><strong>flatweights</strong></p>
</td>
<td><p>flatweights={True, False}</p></td>
<td><p>Override the channel weights from <a class="reference internal" href="#pixeldata">pixeldata</a> with their average value.
This way all channels carry the same uniformed initial weight.  It can be
useful when the <a class="reference internal" href="#pixeldata">pixeldata</a> weights are suspect for some reason.</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="focalplane">
<div class="line"><strong>focalplane</strong></div>
<div class="line">Sets: system=focalplane</div>
</div>
</td>
<td><p>focalplane={True, False}</p></td>
<td><p>Produce maps in focal-plane coordinates.  This is practical only for
beam-mapping.  Thus, focal-plane coordinates are default when
<a class="reference internal" href="#source-type">source.type</a> is set to ‘pixelmap’.  See <a class="reference internal" href="#pixelmap">pixelmap</a> and <a class="reference internal" href="#source-type">source.type</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="focus-direction-coeff"><strong>focus.&lt;direction&gt;coeff</strong></p>
</td>
<td><p>focus.&lt;direction&gt;coeff=&lt;X&gt;</p></td>
<td><p>Used to convert the asymmetry and elongation parameters of an elliptical
model of the source to focus values (in mm) using focus=-1/coeff * param
where coeff is the value supplied here, and param is the asymmetry x or
y factor for directions x and y, and param is the elongation factor for
the z direction.  &lt;direction&gt; may take values of x, y, or z.</p></td>
</tr>
<tr class="row-odd"><td><p id="focus-direction-scatter"><strong>focus.&lt;direction&gt;scatter</strong></p>
</td>
<td><p>focus.&lt;direction&gt;scatter=&lt;X&gt;</p></td>
<td><p>Adds extra noise to the reported focus measurements in the x, y, and/or
z &lt;direction&gt;.  RMS values should be provided in units of mm.</p></td>
</tr>
<tr class="row-even"><td><p id="focus-significance"><strong>focus.significance</strong></p>
</td>
<td><p>focus.significance=&lt;X&gt;</p></td>
<td><p>Require focus calculation factors (asymmetry and elongation) to have a
signal-to-noise ratio of greater than &lt;X&gt; in order for the focus results
to be reported in the x, y, and z directions.</p></td>
</tr>
<tr class="row-odd"><td><p id="focus-elong0"><strong>focus.elong0</strong></p>
</td>
<td><p>focus.elong0=&lt;X&gt;</p></td>
<td><p>Subtracts an offset correction from the elongation of an elliptical
model of the source when and if focus calculations are performed.  &lt;X&gt;
should be supplied as a percentage value.</p></td>
</tr>
<tr class="row-even"><td><p id="forget"><strong>forget</strong></p>
</td>
<td><p>forget=&lt;key&gt;, …</p></td>
<td><p>Forget any prior values set for &lt;key&gt;, effectively removing it from the
configuration.  New values may always be set, but you may also re-set
a previously forgotten key using the <a class="reference internal" href="#recall">recall</a> command.  If &lt;key&gt; is set
to ‘conditionals’ or ‘blacklist’, all currently stored conditionals or
blacklisted keys will be removed.  See <a class="reference internal" href="#blacklist">blacklist</a> and <a class="reference internal" href="#conditionals">conditionals</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="frames"><strong>frames</strong></p>
</td>
<td><p>frames=&lt;from&gt;:&lt;to&gt;</p></td>
<td><p>Read only the specified frame ranges from the data.  Maybe useful for
quick peeks at the data without processing the full scan, or when a part
of the data is corrupted near the start or end of a scan.</p></td>
</tr>
<tr class="row-even"><td><p id="gain"><strong>gain</strong></p>
</td>
<td><p>gain=&lt;X&gt;</p></td>
<td><p>Specify an instrument gain of X from the detector stage (or fixed signal
stage) to the readout.  Many instruments may automatically determine the
relevant gain based on their data headers.  For others, the gains may
have to be adjusted by hand, especially if they are changing.  Upon
reading the scans, SOFSCAN will divide all data by the specified value,
to bring all scans to a comparable signal level  Conversions to <a class="reference internal" href="#jansky">jansky</a>
area referenced to such gain-scaled data.  See <a class="reference internal" href="#jansky">jansky</a>, <a class="reference internal" href="#dataunit">dataunit</a>, and
<a class="reference internal" href="#scale">scale</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="gainnoise"><strong>gainnoise</strong></p>
</td>
<td><p>gainnoise=&lt;X&gt;</p></td>
<td><p>Add noise to the initial gains.  There is not much use for this option,
other than checking the robustness of the reduction on the initial gain
assumption.  Since gains are usually measured in the reduction itself,
typical reductions should not depend a lot on the initial gain values.
See <a class="reference internal" href="#uniform">uniform</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="gains"><strong>gains</strong></p>
</td>
<td><div class="line-block">
<div class="line">[gains]</div>
<div class="line">value={True, False}</div>
</div>
</td>
<td><p>Solve for pixel gains based on their response to the correlated noise
(above).  If not specified, then all decorrelation steps will proceed
without a gain solution.  A model-by-model control is offered by the
<a class="reference internal" href="#correlated-modality-nogains">correlated.&lt;modality&gt;.nogains</a> option.  See <a class="reference internal" href="#gains-estimator">gains.estimator</a> and
<a class="reference internal" href="#correlated-modality-nogains">correlated.&lt;modality&gt;.nogains</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="gains-estimator"><strong>gains.estimator</strong></p>
</td>
<td><div class="line-block">
<div class="line">[gains]</div>
<div class="line">estimator={median, maximum-likelihood}</div>
</div>
</td>
<td><p>Specify the type of estimator (‘median’ or ‘maximum-likelihood’) to be
used for estimating pixel gains to correlated signals.  See <a class="reference internal" href="#estimator">estimator</a>
and <a class="reference internal" href="#correlated-modality">correlated.&lt;modality&gt;</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="gains-span"><strong>gains.span</strong></p>
</td>
<td><div class="line-block">
<div class="line">[gains]</div>
<div class="line">span={True, False}</div>
</div>
</td>
<td><p>Make the gains of all correlated modalities span scans instead of
integrations (subscans).  See <a class="reference internal" href="#correlated-modality-span">correlated.&lt;modality&gt;.span</a>.</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="galactic">
<div class="line"><strong>galactic</strong></div>
<div class="line">Sets: system=galactic</div>
</div>
</td>
<td><p>galactic={True, False}</p></td>
<td><p>Reduce using new galactic coordinates (for mapping).  See <a class="reference internal" href="#system">system</a>,
<a class="reference internal" href="#equatorial">equatorial</a>, and <a class="reference internal" href="#altaz">altaz</a>.</p></td>
</tr>
<tr class="row-even"><td><div class="line-block" id="gradients">
<div class="line"><strong>gradients</strong></div>
<div class="line">Alias: correlated.gradients</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[gradients]</div>
<div class="line">value={True, False}</div>
</div>
</td>
<td><p>Shorthand for the decorrelation of gradients across the detector array.
Such gradients can occur as a result of spatial sky-noise, or as
temperature variation across the detectors.  See
<a class="reference internal" href="#correlated-modality">correlated.&lt;modality&gt;</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="grid"><strong>grid</strong></p>
</td>
<td><p>grid={&lt;X&gt; or &lt;dx&gt;,&lt;dy&gt;}</p></td>
<td><p>Set the map pixelization to X arcseconds.  Pixelization smaller than 2/5
of the beam is recommended.  The default is ~1/5 of the beam.  Non-square
pixelization can be specified using &lt;dx&gt;,&lt;dy&gt; in arcseconds.</p></td>
</tr>
<tr class="row-even"><td><p id="group"><strong>group</strong></p>
</td>
<td><div class="line-block">
<div class="line">[group]</div>
<div class="line">&lt;name&gt;=10:20,45,50:60</div>
<div class="line">…</div>
</div>
</td>
<td><p>Specify a list of channels by IDs or fixed index (usually the same as
storage index C-style 0-based), or ranges thereof that ought to belong
to a group with name &lt;name&gt;.  See <a class="reference internal" href="#division-name">division.&lt;name&gt;</a>.</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="gyrocorrect">
<div class="line"><strong>gyrocorrect</strong></div>
<div class="line">Instrument: HAWC+</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[gyrocorrect]</div>
<div class="line">&lt;options…&gt;</div>
</div>
</td>
<td><p>If present in the configuration, correct for gyrodrifts based on
guide-star relock data stored in the scan headers.  This is not normally
needed when the gyros function properly.  Occasionally however, they
drift a fair bit, and this option can activate the correction scheme on
demand.  See <a class="reference internal" href="#gyrocorrect-max">gyrocorrect.max</a>.</p></td>
</tr>
<tr class="row-even"><td><div class="line-block" id="gyrocorrect-max">
<div class="line"><strong>gyrocorrect.max</strong></div>
<div class="line">Instrument: HAWC+</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[gyrocorrect]</div>
<div class="line">max=&lt;X&gt;</div>
</div>
</td>
<td><p>Set a limit to how large of a gyro drift can be corrected for.  When
drifts larger than X arcseconds are found in the scan, the correction is
skipped for single scan reductions or dropped from the set in multi-scan
reductions.</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="horizontal">
<div class="line"><strong>horizontal</strong></div>
<div class="line">Sets: system=horizontal</div>
</div>
</td>
<td><p>horizontal={True, False}</p></td>
<td><p>Reduce in horizontal coordinates (for mapping).  This is often useful for
determining pointing offsets or for pixel location mapping.  See <a class="reference internal" href="#system">system</a>
and <a class="reference internal" href="#pixelmap">pixelmap</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="indexing"><strong>indexing</strong></p>
</td>
<td><div class="line-block">
<div class="line">[indexing]</div>
<div class="line">value={True, False}</div>
</div>
</td>
<td><p>Allow the use of data indexing to speed up coordinate calculations for
mapping.  Without indexing the map coordinates are calculated at each
mapping step.  This can be slow because of the complexity of the
spherical projections, which often require several complex math
evaluations.  With indexing enabled, the calculations are only performed
once, and the relevant data is stored for future use.  However, this
increases the memory requirement of SOFSCAN.  This, indexing may be
disabled for very large reductions.  Alternatively, one may control the
amount of memory such indexing may use via the <a class="reference internal" href="#indexing-saturation">indexing.saturation</a>
option.  See <a class="reference internal" href="#grid">grid</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="indexing-check-memory"><strong>indexing.check_memory</strong></p>
</td>
<td><div class="line-block">
<div class="line">[indexing]</div>
<div class="line">check_memory=&lt;True,False&gt;</div>
</div>
</td>
<td><p>If True (default), performs a memory check to see if enough space
exists in memory to index scans.  This should only really be turned
off when running unit tests on a Windows virtual maching.  See
<a class="reference internal" href="#indexing">indexing</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="indexing-saturation"><strong>indexing.saturation</strong></p>
</td>
<td><div class="line-block">
<div class="line">[indexing]</div>
<div class="line">saturation=&lt;X&gt;</div>
</div>
</td>
<td><p>Specify the maximum fraction X of the total available memory that can be
filled before indexing is automatically disabled.  Given a typical 20%
overhead during reduction, values below 0.8 are recommended to avoid
overflows.  See <a class="reference internal" href="#indexing">indexing</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="invert"><strong>invert</strong></p>
</td>
<td><p>invert={True, False}</p></td>
<td><p>Invert signals.  This setting may be useful in creating custom
jackknives, where the user wishes to retain control over which scans are
inverted.  See <a class="reference internal" href="#gain">gain</a>, <a class="reference internal" href="#scale">scale</a>, and <a class="reference internal" href="#jackknife">jackknife</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="iteration"><strong>iteration</strong></p>
</td>
<td><div class="line-block">
<div class="line">[iteration]</div>
<div class="line">[[&lt;N&gt;, &lt;X&gt;, &lt;x%&gt;]]</div>
<div class="line">&lt;key&gt;=&lt;value&gt;</div>
<div class="line">…</div>
</div>
</td>
<td><p>Use as a condition to delay settings until the Nth iteration.  E.g:</p>
<div class="line-block">
<div class="line">[iteration]</div>
<div class="line">[[3]]</div>
<div class="line">smooth=halfbeam</div>
</div>
<p>will specify half-beam smoothing beginning on the 3rd iteration.  Note
that the first iteration is numbered as 1.  Negative values for N are
relative to the last iteration at -1.  For example, -2 references the
penultimate iteration.  A fraction X or percentage x may also be supplied
relative to the maximum number of <a class="reference internal" href="#rounds">rounds</a>.  For example, for a reduction
with 10 rounds, the following settings will all be triggered on the 5th
iteration:</p>
<div class="line-block">
<div class="line">[iteration]</div>
<div class="line">[[5]]</div>
<div class="line">smooth=5.0</div>
<div class="line">[[0.5]]</div>
<div class="line">smooth=6.0</div>
<div class="line">[[-6]]</div>
<div class="line">smooth=7.0</div>
<div class="line">[[50%]]</div>
<div class="line">smooth=8.0</div>
</div>
<p>SOFSCAN will parse options as they are encountered in the configuration,
so the resultant smooth setting on the 5th round will by 8.0.</p>
</td>
</tr>
<tr class="row-odd"><td><p id="jackknife"><strong>jackknife</strong></p>
</td>
<td><div class="line-block">
<div class="line">[jackknife]</div>
<div class="line">value={True, False}</div>
</div>
</td>
<td><p>Jackkniving is a useful technique to produce accurate noise maps from
large datasets.  When the option is used, the scan signals are randomly
inverted so that the source signals in the large datasets will tend to
cancel out, leaving noise maps.  The sign inversion is truly random in
which repeated runs with the ‘jackknife’ flag will produce differenct
jackknives every time.  If you want more control over which scans are
inverted, consider using the <a class="reference internal" href="#invert">invert</a> flag instead.  See <a class="reference internal" href="#invert">invert</a>,
<a class="reference internal" href="#scramble">scramble</a>, <a class="reference internal" href="#jackknife-frames">jackknife.frames</a>, <a class="reference internal" href="#jackknife-channels">jackknife.channels</a>, and
<a class="reference internal" href="#jackknife-alternate">jackknife.alternate</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="jackknife-alternate"><strong>jackknife.alternate</strong></p>
</td>
<td><div class="line-block">
<div class="line">[jackknife]</div>
<div class="line">alternate={True, False}</div>
</div>
</td>
<td><p>Rather than randomly inverting scans for a jackknife, this option will
invert every other scan.  This may be preferred for small datasets,
because it leads to better cancellation of source signals, especially
with an even number of scans, chronologically listed.  To have the
desired effect, use instead of <a class="reference internal" href="#jackknife">jackknife</a>, rather than together with it
(otherwise, the ordered inversion will simply compound the random method
of the standard <a class="reference internal" href="#jackknife">jackknife</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="jackknife-channels"><strong>jackknife.channels</strong></p>
</td>
<td><div class="line-block">
<div class="line">[jackknife]</div>
<div class="line">channels={True, False}</div>
</div>
</td>
<td><p>Jackknife channels, such that they are randomly inverted for the source
model.  Beware however, that channel-wise jackknives are not as
representative of the true noise as the regular scan-wise <a class="reference internal" href="#jackknife">jackknife</a>,
because they will reject spatial correlations and instrumental
channel-to-channel correlations.  See <a class="reference internal" href="#jackknife">jackknife</a>, <a class="reference internal" href="#jackknife-frames">jackknife.frames</a>,
and <a class="reference internal" href="#scramble">scramble</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="jackknife-frames"><strong>jackknife.frames</strong></p>
</td>
<td><div class="line-block">
<div class="line">[jackknife]</div>
<div class="line">frames={True, False}</div>
</div>
</td>
<td><p>Jackknife frames, such that they are randomly inverted for the source
model.  Beware however, that frame jackknives are not as representative
if the true noise as the regular scan-wise <a class="reference internal" href="#jackknife">jackknife</a>, because they will
reject temporal correlations.</p></td>
</tr>
<tr class="row-odd"><td><p id="jansky"><strong>jansky</strong></p>
</td>
<td><div class="line-block">
<div class="line">[jansky]</div>
<div class="line">value=&lt;X&gt;</div>
</div>
</td>
<td><p>Specify the calibration factor from <a class="reference internal" href="#dataunit">dataunit</a> to Jy such that
Jansky’s = dataunit * X.  See <a class="reference internal" href="#dataunit">dataunit</a>, <a class="reference internal" href="#gain">gain</a>, and <a class="reference internal" href="#jansky-inverse">jansky.inverse</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="jansky-inverse"><strong>jansky.inverse</strong></p>
</td>
<td><div class="line-block">
<div class="line">[jansky]</div>
<div class="line">inverse={True, False}</div>
</div>
</td>
<td><p>When used, the <a class="reference internal" href="#jansky">jansky</a> definition is inverted to mean Jy to <a class="reference internal" href="#dataunit">dataunit</a>
such that dataunit = X * Jansky’s.</p></td>
</tr>
<tr class="row-odd"><td><p id="k2jy"><strong>k2jy</strong></p>
</td>
<td><p>k2jy=&lt;X&gt;</p></td>
<td><p>The Jy/K conversion factor to X.  This allows SOFSCAN to calculate a data
conversion to units of Kelvin if <a class="reference internal" href="#jansky">jansky</a> is also defined.  Alternatively,
the conversion to Kelvins can be specified directly via the <a class="reference internal" href="#kelvin">kelvin</a> key.</p></td>
</tr>
<tr class="row-even"><td><p id="kelvin"><strong>kelvin</strong></p>
</td>
<td><p>kelvin=&lt;X&gt;</p></td>
<td><p>Set the conversion to units of Kelvin (or more precisely, to K/beam
units).  X defines the equivalent value of 1 K/beam expressed in the
native <a class="reference internal" href="#dataunit">dataunit</a>.  See <a class="reference internal" href="#dataunit">dataunit</a>, <a class="reference internal" href="#jansky">jansky</a>, and <a class="reference internal" href="#k2jy">k2jy</a>.</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="lab">
<div class="line"><strong>lab</strong></div>
<div class="line">Sets:</div>
<div class="line">blacklist=source, filter.motion, tau, filter, whiten, shift, point</div>
<div class="line">forget=downsample</div>
<div class="line">write.spectrum=True</div>
</div>
</td>
<td><p>lab={True, False}</p></td>
<td><p>A conditional switch that indicates no astronomical observation was made.
Effectively disables most tasks related to telescope motion or source
derivation, and instead writes channel spectra to file.  See
<a class="reference internal" href="#write-spectrum">write.spectrum</a>.</p></td>
</tr>
<tr class="row-even"><td><div class="line-block" id="last">
<div class="line"><strong>last</strong></div>
<div class="line">Alias: iteration.-1</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[last]</div>
<div class="line">&lt;key&gt;=&lt;value&gt;</div>
<div class="line">…</div>
</div>
</td>
<td><p>An alias for settings to be applied on the last iteration.  See <a class="reference internal" href="#final">final</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="lock"><strong>lock</strong></p>
</td>
<td><p>lock=&lt;key1&gt;,&lt;key2&gt;,…</p></td>
<td><p>Set a persistent option value that cannot be changed, cleared, or
blacklisted later (e.g. by conditionally activated settings).  Users may
use locks to ensure that their manually set reduction options are
applied and never overridden.  For the lock to take effect, the option
must not be blacklisted or locked to a different value before.  The
value of a key will be set to its current value.  To release a lock,
the <a class="reference internal" href="#unlock">unlock</a> command may be issued.  See <a class="reference internal" href="#unlock">unlock</a> and <a class="reference internal" href="#blacklist">blacklist</a>.</p></td>
</tr>
<tr class="row-even"><td><div class="line-block" id="los">
<div class="line"><strong>los</strong></div>
<div class="line">Instrument: HAWC+</div>
<div class="line">Alias: correlated.los</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[los]</div>
<div class="line">value={True, False}</div>
</div>
</td>
<td><p>Remove correlations with the second-derivative to the telescope
line-of-sight (LOS) angle.  It is a good proxy for removing pitch-type
acceleration response from the detector timestream.  See
<a class="reference internal" href="#correlated-modality">correlated.&lt;modality&gt;</a>.</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="map">
<div class="line"><strong>map</strong></div>
<div class="line">Sets: source.type=map</div>
</div>
</td>
<td><p>map={True, False}</p></td>
<td><p>A switch to produce a source map on output.</p></td>
</tr>
<tr class="row-even"><td><p id="mappingfraction"><strong>mappingfraction</strong></p>
</td>
<td><p>mappingfraction=&lt;X&gt;</p></td>
<td><p>Specify a minimum fraction of pixels (X) in the array that have to remain
unflagged for creating a map from the scan.  If too many pixels are
flagged in the reduction, it may be a sign of bigger problems,
questioning the reliability of the scan data.  It is best to skip over
problematic scans in order to minimize their impact on the mapping.  See
<a class="reference internal" href="#mappingpixels">mappingpixels</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="mappingpixels"><strong>mappingpixels</strong></p>
</td>
<td><p>mappingpixels=&lt;N&gt;</p></td>
<td><p>Specify a minimum number of pixels (N) which have to be unflagged by the
reduction in order for the scan to contribute to the mapping step.  See
<a class="reference internal" href="#mappingfraction">mappingfraction</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="map-size"><strong>map.size</strong></p>
</td>
<td><div class="line-block">
<div class="line">[map]</div>
<div class="line">size=&lt;dx&gt;{x or X or , or tab or :}&lt;dy&gt;</div>
</div>
</td>
<td><p>Explicitly set the size of the mapped area centered on the source to a dx
by dy arcseconds rectangle.  Normally, the map size is automatically
calculated to contain all of the data.  One may want to restrict mapping
to smaller regions (outside of which there should be no bright signals).
See <a class="reference internal" href="#system">system</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="moving"><strong>moving</strong></p>
</td>
<td><p>moving={True, False}</p></td>
<td><p>Explicitly specify that the object is moving in the celestial frame (such
as solar system objects like plants, asteroids, comets, and moons).  This
way, data will be properly aligned on the coordinates of the first scan.
If the data headers are correctly set up (and interpreted by SOFSCAN),
moving objects can be automatically detected.  This option is there in
case things do not work as expected (e.g., if you notice that your solar
system object smears or moves across the image with the default
reduction.  Currently, this option forces equatorial coordinates.  This
option is also aliased as <a class="reference internal" href="#planetary">planetary</a>.  See <a class="reference internal" href="#system">system</a>.</p></td>
</tr>
<tr class="row-even"><td><div class="line-block" id="multibeam">
<div class="line"><strong>multibeam</strong></div>
<div class="line">Sets: source.type=multibeam</div>
</div>
</td>
<td><p>multibeam={True, False}</p></td>
<td><p>An alias for setting the source type to multibeam.</p></td>
</tr>
<tr class="row-odd"><td><p id="name"><strong>name</strong></p>
</td>
<td><p>name=&lt;filename&gt;</p></td>
<td><p>Specify the output image filename, relative to the directory specified
by <a class="reference internal" href="#outpath">outpath</a>.  When not given, SOFSCAN will choose a file name based on
the source name and scan number(s), which is either:</p>
<blockquote>
<div><p>&lt;sourcename&gt;.&lt;scanno&gt;.fits</p>
</div></blockquote>
<p>or:</p>
<blockquote>
<div><p>&lt;sourcename&gt;.&lt;firstscan&gt;-&lt;lastscan&gt;.fits</p>
</div></blockquote>
<p>For mapping, other source model types (e.g. skydips or pixel maps) may
have different default naming conventions.</p>
</td>
</tr>
<tr class="row-even"><td><p id="nefd-map"><strong>nefd.map</strong></p>
</td>
<td><div class="line-block">
<div class="line">[nefd]</div>
<div class="line">map={True, False}</div>
</div>
</td>
<td><p>True to use apparent map noise (if available, e.g. via
<a class="reference internal" href="#weighting-scans">weighting.scans</a>) to refine the reported NEFD estimate.  Else, the NEFD
estimate will be based on the timestream noise alone.</p></td>
</tr>
<tr class="row-odd"><td><p id="noiseclip"><strong>noiseclip</strong></p>
</td>
<td><p>noiseclip=&lt;X&gt;</p></td>
<td><p>Flag (clip) map pixels with a noise level that is more than X times
higher than the deepest covered parts of the map.  See <a class="reference internal" href="#exposureclip">exposureclip</a> and
<a class="reference internal" href="#clip">clip</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="noslim"><strong>noslim</strong></p>
</td>
<td><p>noslim={True, False}</p></td>
<td><p>After reading the scans, SOFSCAN will discard data from channels flagged
with a hardware problem to free up memory, and to speed up the reduction.
This option overrides this behaviour, and retains all channels for the
reduction whether used or not.</p></td>
</tr>
<tr class="row-odd"><td><p id="notch"><strong>notch</strong></p>
</td>
<td><div class="line-block">
<div class="line">[notch]</div>
<div class="line">value={True, False}</div>
</div>
</td>
<td><p>Enable notch filtering the raw detector timestreams before further
initial processing (e.g. downsampling).  The sub-options
<a class="reference internal" href="#notch-frequencies">notch.frequencies</a>, <a class="reference internal" href="#notch-harmonics">notch.harmonics</a>. and <a class="reference internal" href="#notch-width">notch.width</a> are used to
customize the notch filter response.</p></td>
</tr>
<tr class="row-even"><td><p id="notch-frequencies"><strong>notch.frequencies</strong></p>
</td>
<td><div class="line-block">
<div class="line">[notch]</div>
<div class="line">frequencies=&lt;freq1&gt;, &lt;freq2&gt;,…</div>
</div>
</td>
<td><p>A comma-separated list of frequencies (Hz) to notch out from the raw
detector timestreams.  See <a class="reference internal" href="#notch-harmonics">notch.harmonics</a>. and <a class="reference internal" href="#notch-width">notch.width</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="notch-harmonics"><strong>notch.harmonics</strong></p>
</td>
<td><div class="line-block">
<div class="line">[notch]</div>
<div class="line">harmonics=&lt;N&gt;</div>
</div>
</td>
<td><p>Specify that the notch filter should also notch out N harmonics of the
specified <a class="reference internal" href="#notch-frequencies">notch.frequencies</a>.  If not set, only the list of frequencies
are notched, i.e. the same as ‘harmonics=1’.  For example:</p>
<blockquote>
<div><p>notch.harmonics=2</p>
</div></blockquote>
<p>will notch out the list of frequencies set by <a class="reference internal" href="#notch-frequencies">notch.frequencies</a> as
well as their second harmonics.  See <a class="reference internal" href="#notch-frequencies">notch.frequencies</a> and
<a class="reference internal" href="#notch-width">notch.width</a>.</p>
</td>
</tr>
<tr class="row-even"><td><p id="notch-width"><strong>notch.width</strong></p>
</td>
<td><div class="line-block">
<div class="line">[notch]</div>
<div class="line">width=&lt;X&gt;</div>
</div>
</td>
<td><p>Set the frequency width (Hz) of the notch filter response.  See
<a class="reference internal" href="#notch-frequencies">notch.frequencies</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="obstime"><strong>obstime</strong></p>
</td>
<td><div class="line-block">
<div class="line">[conditionals]</div>
<div class="line">[[obstime&lt;operator&gt;&lt;T&gt;]]</div>
<div class="line">&lt;key&gt;=&lt;value&gt;</div>
<div class="line">…</div>
</div>
</td>
<td><p>Configure settings based on the total observing time of all input scans.
The total obstime is compared agains T (seconds) using &lt;operator&gt;, and
all settings are applied if the requirement is met.  For example:</p>
<div class="line-block">
<div class="line">[conditionals]</div>
<div class="line">[[obstime&gt;60]]</div>
<div class="line">stability=10</div>
</div>
<p>will set the stability value to 10 if the total observation time is
longer than one minute.  Nesting obstime conditions is possible with
some limitations.  It is evaluated only once, after all scans have been
read.  Thus, the condition will have no effect if activated later (e.g.
if nested inside an iteration condition).</p>
</td>
</tr>
<tr class="row-even"><td><div class="line-block" id="offset">
<div class="line"><strong>offset</strong></div>
<div class="line">Instrument: HAWC+</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[offset]</div>
<div class="line">&lt;sub&gt;=&lt;dx&gt;,&lt;dy&gt;</div>
<div class="line">…</div>
</div>
</td>
<td><p>Specify subarray offsets.  For HAWC+ &lt;sub&gt; may take values of ‘R0’, ‘R1’,
‘T0’, and/or ‘T1’.  dx and dy are in units of pixels.  See <a class="reference internal" href="#rotation">rotation</a>.</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="offsets">
<div class="line"><strong>offsets</strong></div>
<div class="line">Sets: forget=drifts</div>
</div>
</td>
<td><p>offsets={True, False}</p></td>
<td><p>Remove the residual DC offsets from the bolometer signals using the
‘offsets’ task in <a class="reference internal" href="#ordering">ordering</a> rather than <a class="reference internal" href="#drifts">drifts</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="ordering"><strong>ordering</strong></p>
</td>
<td><p>ordering=&lt;task1&gt;,&lt;task2&gt;,…</p></td>
<td><p>Specify the order of pipeline elements as a comma-separated list of keys.
See <a class="reference internal" href="#offsets">offsets</a>, <a class="reference internal" href="#correlated-modality">correlated.&lt;modality&gt;</a>, <a class="reference internal" href="#whiten">whiten</a>, and <a class="reference internal" href="#weighting-frames">weighting.frames</a>.</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="organization">
<div class="line"><strong>organization</strong></div>
<div class="line">Telescope: SOFIA</div>
</div>
</td>
<td><p>organization=&lt;text&gt;</p></td>
<td><p>Specify the organization at which SOFSCAN is being used for reducing
data.  The value of this option is stored directly in the FITS ORIGIN
header key as required by the DCS.  If you want the ORIGIN key to be set
properly, you might consider adding the organization option to
‘~/.sofscan/sofia/default.cfg’ as ‘SOFIA Science and Mission Ops’.</p></td>
</tr>
<tr class="row-even"><td><p id="outpath"><strong>outpath</strong></p>
</td>
<td><div class="line-block">
<div class="line">[outpath]</div>
<div class="line">value=&lt;directory&gt;</div>
</div>
</td>
<td><p>Specify the output path where all SOFSCAN output will be written
(including maps etc.).  If not specified, will default to the current
working directory.</p></td>
</tr>
<tr class="row-odd"><td><p id="outpath-create"><strong>outpath.create</strong></p>
</td>
<td><div class="line-block">
<div class="line">[outpath]</div>
<div class="line">create={True, False}</div>
</div>
</td>
<td><p>When set, the output path will be automatically created as necessary.  If
not, SOFSCAN will exit with an error if the output path does not exist.
See <a class="reference internal" href="#outpath">outpath</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="parallel-cores"><strong>parallel.idle</strong></p>
</td>
<td><div class="line-block">
<div class="line">[parallel]</div>
<div class="line">cores={N, x, X%}</div>
</div>
</td>
<td><p>Instruct SOFSCAN to use N number of CPU cores, fraction x of
available processors, or X percent of available processors.  By default
SOFSCAN will try to use 50% of the processing cores in your machine for
decent performance without taking up too many resources.  This option
allow modification of this behaviour according to need.</p></td>
</tr>
<tr class="row-odd"><td><p id="parallel-idle"><strong>parallel.idle</strong></p>
</td>
<td><div class="line-block">
<div class="line">[parallel]</div>
<div class="line">idle={N, x, X%}</div>
</div>
</td>
<td><p>Instruct SOFSCAN to avoid using N number of CPU cores, fraction x of
available processors, or X percent of available processors.</p></td>
</tr>
<tr class="row-even"><td><p id="parallel-jobs"><strong>parallel.jobs</strong></p>
</td>
<td><div class="line-block">
<div class="line">[parallel]</div>
<div class="line">jobs={N, x, X%}</div>
</div>
</td>
<td><p>Instruct SOFSCAN to allow a maximum of N jobs, fraction x of
available cores, or X percent of available cores.  The maximum
number of cores is set by <a class="reference internal" href="#parallel-idle">parallel.idle</a> or <a class="reference internal" href="#parallel-cores">parallel.cores</a>.  This
relates not only to the number of cores, but the number of threads inside
each core, so that:</p>
<blockquote>
<div><p>cores * threads &lt;= parallel.jobs</p>
</div></blockquote>
<p>The default is -1, indicating that the number of jobs is capped by the
number of cores.</p>
</td>
</tr>
<tr class="row-odd"><td><p id="parallel-mode"><strong>parallel.mode</strong></p>
</td>
<td><div class="line-block">
<div class="line">[parallel]</div>
<div class="line">mode=&lt;mode&gt;</div>
</div>
</td>
<td><p>Set the parallel processing mode.  &lt;mode&gt; may be one of:</p>
<blockquote>
<div><ul class="simple">
<li><p><em>scans</em>: process scans in parallel.</p></li>
<li><p><em>ops</em>: process each scan with parallel threads where possible.</p></li>
<li><p><em>hybrid</em>: process as many scans in parallel as possible, each with
an optimal number of threads.</p></li>
</ul>
</div></blockquote>
<p>The default mode is ‘hybrid’.</p>
</td>
</tr>
<tr class="row-even"><td><p id="parallel-scans"><strong>parallel.scans</strong></p>
</td>
<td><div class="line-block">
<div class="line">[parallel]</div>
<div class="line">scans=&lt;True,False&gt;</div>
</div>
</td>
<td><p>Perform the reduction tasks for all scans in parallel.  This is not
recommended when dealing with large data sets due to memory pressure.</p></td>
</tr>
<tr class="row-odd"><td><p id="parallel-source"><strong>parallel.source</strong></p>
</td>
<td><div class="line-block">
<div class="line">[parallel]</div>
<div class="line">source=&lt;True,False&gt;</div>
</div>
</td>
<td><p>Update the scan source models in parallel if True.  This is recommended
when dealing with large sets of data due to better memory management
procedures.</p></td>
</tr>
<tr class="row-even"><td><div class="line-block" id="pcenter">
<div class="line"><strong>pcenter</strong></div>
<div class="line">Instrument: HAWC+</div>
</div>
</td>
<td><p>pcenter={&lt;X&gt; or &lt;x&gt;,&lt;y&gt;}</p></td>
<td><p>Specify the boresight position (pixels) on the detector array.  If a
single value &lt;X&gt; is given, it will be applied to both the &lt;x&gt; and &lt;y&gt;
directions (columns and rows).</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="peakflux">
<div class="line"><strong>peakflux</strong></div>
<div class="line">Instrument: HAWC+</div>
</div>
</td>
<td><p>peakflux={True, False}</p></td>
<td><p>Switch to peak-flux calibration instead of the default aperture flux
calibration.  Recommended for point sources only.</p></td>
</tr>
<tr class="row-even"><td><p id="perimeter"><strong>perimeter</strong></p>
</td>
<td><p>perimeter={&lt;N&gt;, auto}</p></td>
<td><p>To speed up the sizing of the output image for large arrays (e.g. HAWC+)
do not use the positions of each and every pixel.  Instead, identify a
set of pixels that define an array perimeter from N sections around the
centroid of the array.  N values up to a few hundred should be fail-safe
for most typical array layouts, even when these have lots of pixels.</p></td>
</tr>
<tr class="row-odd"><td><p id="phases"><strong>phases</strong></p>
</td>
<td><div class="line-block">
<div class="line">[phases]</div>
<div class="line">value={True, False}</div>
</div>
</td>
<td><p>Decorrelate the phase data (e.g. for chopped observations) for all
correlated modes.  Alternatively, phase decorrelation can be turned on
individually using the <a class="reference internal" href="#correlated-modality-phases">correlated.&lt;modality&gt;.phases</a> options.</p></td>
</tr>
<tr class="row-even"><td><p id="phases-estimator"><strong>phases.estimator</strong></p>
</td>
<td><div class="line-block">
<div class="line">[phases]</div>
<div class="line">estimator={median, maximum-likelihood}</div>
</div>
</td>
<td><p>Overrides the global estimator setting for the phases (e.g. chopper
phases).  The estimator may be either ‘median’ or ‘maximum-likelihood’.
If neither of these, it will default to ‘maximum-likelihood’.  If not
set, the global <a class="reference internal" href="#estimator">estimator</a> will be used.</p></td>
</tr>
<tr class="row-odd"><td><p id="phasegains"><strong>phasegains</strong></p>
</td>
<td><p>phasegains={True, False}</p></td>
<td><p>Use the information in the phases to calculate gains for all correlated
modes.  The default is to use the fast samples for calculating gains.
Alternatively, you can set this property separately for each correlated
modality using <a class="reference internal" href="#correlated-modality-phasegains">correlated.&lt;modality&gt;.phasegains</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="pixeldata"><strong>pixeldata</strong></p>
</td>
<td><p>pixeldata=&lt;filename&gt;</p></td>
<td><p>Specifies a pixel data file, providing initial gains, weights, and flags
for detectors, and possibly other information as well depending on the
specific instrument.  Such files can be produced via the
<a class="reference internal" href="#write-pixeldata">write.pixeldata</a> options (in addition to which you may want to specify
‘forget=pixeldata’ so that flags are determined without prior bias).  See
<a class="reference internal" href="#gainnoise">gainnoise</a>, <a class="reference internal" href="#uniform">uniform</a>, <a class="reference internal" href="#flag">flag</a>, and <a class="reference internal" href="#blind">blind</a>.</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="pixelmap">
<div class="line"><strong>pixelmap</strong></div>
<div class="line">Sets: source.type=pixelmap</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[pixelmap]</div>
<div class="line">value={True, False}</div>
</div>
</td>
<td><p>Effectively the same as ‘source.type=pixelmap’ which is invoked by a
condition.  Used for reducing pixel map data.  Instead of making a single
map from all pixels, separate maps are create for each pixel.  (Note,
this can chew up some memory if you have a lot of pixels).  At the end of
the reduction, SOFSCAN determines the actual pixel offsets in the focal
plane.  See <a class="reference internal" href="#source-type">source.type</a>, <a class="reference internal" href="#skydip">skydip</a>, and <a class="reference internal" href="#grid">grid</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="pixelmap-process"><strong>pixelmap.process</strong></p>
</td>
<td><div class="line-block">
<div class="line">[pixelmap]</div>
<div class="line">process={True, False}</div>
</div>
</td>
<td><p>Specify that pixel maps should undergo the same post-processing steps
(e.g. smoothing, clipping, filtering, etc.) that are used for regular
map-making.  When the option is not set, pixel maps are used in their
raw maximum-likelihood forms.  See <a class="reference internal" href="#pixelmap">pixelmap</a> and <a class="reference internal" href="#pixelmap-writemaps">pixelmap.writemaps</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="pixelmap-writemaps"><strong>pixelmap.writemaps</strong></p>
</td>
<td><div class="line-block">
<div class="line">[pixelmap]</div>
<div class="line">writemaps={True, False, &lt;list&gt;}</div>
</div>
</td>
<td><p>Pixel maps normally only produce the pixel position information as
output.  Use this option if you want SOFSCAN to write individual pixel
maps as well.  See <a class="reference internal" href="#pixelmap">pixelmap</a> and <a class="reference internal" href="#pixelmap-process">pixelmap.process</a>.  You can specify
which pixels to write by setting &lt;list&gt; which may contain comma-separated
values or ranges referring to the integer fixed channel indices.  For
example:</p>
<blockquote>
<div><p>pixelmap.writemaps=10,15:17</p>
</div></blockquote>
<p>would write pixel maps for channels 10, 15, 16, and 17.</p>
</td>
</tr>
<tr class="row-even"><td><p id="pixels"><strong>pixels</strong></p>
</td>
<td><div class="line-block">
<div class="line">[pixels]</div>
<div class="line">&lt;options…&gt;</div>
</div>
</td>
<td><p>Set user defined options relating to how the initial channel data is
read and validated.  See <a class="reference internal" href="#pixeldata">pixeldata</a> and <a class="reference internal" href="#rcp">rcp</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="pixel-criticalflags"><strong>pixel.criticalflags</strong></p>
</td>
<td><div class="line-block">
<div class="line">[pixel]</div>
<div class="line">criticalflags=&lt;flag1&gt;, &lt;flag2&gt;,…</div>
</div>
</td>
<td><p>Determines which flags present in the initial channel data should
continue to mark a channel as being flagged for the remainder of the
reduction (unless removed by another reduction step).  The &lt;flag&gt;
arguments may take the form of an integer, letter, or string (e.g. ‘G’,
‘GAIN’, or 4).  Note that channel flags are usually specific to different
instruments, so please ensure such flags are defined correctly.  For
example, a <a class="reference internal" href="#pixeldata">pixeldata</a> file may define one channel as spiky (‘s’) but
if ‘SPIKY’ is not included in the critical flags, that channel will not
flagged as such at the start of the reduction.  The default critical
flags are ‘GAIN’, ‘DEAD’, and ‘DISCARD’.</p></td>
</tr>
<tr class="row-even"><td><div class="line-block" id="pixels-coupling-range">
<div class="line"><strong>pixels.coupling.range</strong></div>
<div class="line">Instrument: HAWC+</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[pixels]</div>
<div class="line">[[coupling]]</div>
<div class="line">range=&lt;min&gt;:&lt;max&gt;</div>
</div>
</td>
<td><p>Specify a valid range of coupling values for the initial channel data.
Standard range syntax is observed such that <code class="xref py py-obj docutils literal notranslate"><span class="pre">*</span></code> may indicated an
unbounded limit. Any channel that has a coupling value outside of this in
the initial channel data will be flagged as ‘DEAD’.</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="pixels-coupling-exclude">
<div class="line"><strong>pixels.coupling.exclude</strong></div>
<div class="line">Instrument: HAWC+</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[pixels]</div>
<div class="line">[[coupling]]</div>
<div class="line">exclude=&lt;x1&gt;,&lt;x2&gt;,…</div>
</div>
</td>
<td><p>Flag channels with a coupling equal to certain values as ‘DEAD’ in the
initial channel data.  For example:</p>
<blockquote>
<div><p>pixels.coupling.exclude=0,1</p>
</div></blockquote>
<p>would flag channels with initial coupling values exactly equal to 0 or 1
as ‘DEAD’.</p>
</td>
</tr>
<tr class="row-even"><td><div class="line-block" id="pixels-gain-range">
<div class="line"><strong>pixels.gain.range</strong></div>
<div class="line">Instrument: HAWC+</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[pixels]</div>
<div class="line">[[gain]]</div>
<div class="line">range=&lt;min&gt;:&lt;max&gt;</div>
</div>
</td>
<td><p>Specify a valid range of gains for the initial channel data.  Standard
range syntax is observed such that <code class="xref py py-obj docutils literal notranslate"><span class="pre">*</span></code> may indicated an unbounded limit.
Any channel that has a gain value outside of this in the initial channel
data will be flagged as ‘DEAD’.</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="pixels-gain-exclude">
<div class="line"><strong>pixels.gain.exclude</strong></div>
<div class="line">Instrument: HAWC+</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[pixels]</div>
<div class="line">[[gain]]</div>
<div class="line">exclude=&lt;x1&gt;,&lt;x2&gt;,…</div>
</div>
</td>
<td><p>Flag channels with gain equal to certain values as ‘DEAD’ in the initial
channel data.  For example:</p>
<blockquote>
<div><p>pixels.gain.exclude=0,1</p>
</div></blockquote>
<p>would flag channels with initial gain values exactly equal to 0 or 1 as
‘DEAD’.</p>
</td>
</tr>
<tr class="row-even"><td><div class="line-block" id="pixelsize">
<div class="line"><strong>pixelsize</strong></div>
<div class="line">Instrument: HAWC+</div>
</div>
</td>
<td><p>pixelsize={&lt;X&gt; or &lt;x&gt;,&lt;y&gt;}</p></td>
<td><p>Specify the pixel sizes (arcseconds) for the detector array.</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="planetary">
<div class="line"><strong>planetary</strong></div>
<div class="line">Alias: moving</div>
</div>
</td>
<td><p>planetary={True, False}</p></td>
<td><p>An alias for <a class="reference internal" href="#moving">moving</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="point"><strong>point</strong></p>
</td>
<td><p>point={True, False}</p></td>
<td><p>This is a convenience key for triggering settings for reducing pointing
scans.  By default, it invokes:</p>
<div class="line-block">
<div class="line">[iteration]</div>
<div class="line">[[last]]</div>
<div class="line">pointing.suggest=True</div>
</div>
<p>i.e. suggesting the pointing corrections in the last iteration.  See
<a class="reference internal" href="#pointing">pointing</a>, <a class="reference internal" href="#pointing-suggest">pointing.suggest</a> and <a class="reference internal" href="#pointing-method">pointing.method</a>.</p>
</td>
</tr>
<tr class="row-odd"><td><p id="pointing"><strong>pointing</strong></p>
</td>
<td><div class="line-block">
<div class="line">[pointing]</div>
<div class="line">value={&lt;x&gt;,&lt;y&gt; or suggest}</div>
</div>
</td>
<td><p>Specify pointing corrections, or the way these should be derived.  The
following values are accepted:</p>
<ul class="simple">
<li><p><em>&lt;x&gt;,&lt;y&gt;</em>: Specify relative pointing offsets as comma-separated values
(arcseconds) in the system of the telescope mount.  I.e., these should
be horizontal offsets for ground-based telescopes with an Alt/Az mount.
Some instruments may allow more ways to specify pointing corrections.</p></li>
<li><p><em>suggest</em>: Suggest pointing offsets (at the end of the reduction) from
the scan itself.  This is only suitable when reducing compact pointing
sources with sufficient S/N to be clearly visible in single scans.</p></li>
</ul>
<p>See <a class="reference internal" href="#point">point</a>.</p>
</td>
</tr>
<tr class="row-even"><td><p id="pointing-degree"><strong>pointing.degree</strong></p>
</td>
<td><div class="line-block">
<div class="line">[pointing]</div>
<div class="line">degree=&lt;X&gt;</div>
</div>
</td>
<td><p>Sets the degree (integer &lt;X&gt;) of spline used to fit the peak source
amplitude value. This may be important for pixel maps where the map
coverage is not sufficient to provide the required number of points
for a third degree spline fit (default).</p></td>
</tr>
<tr class="row-odd"><td><p id="pointing-exposureclip"><strong>pointing.exposureclip</strong></p>
</td>
<td><div class="line-block">
<div class="line">[pointing]</div>
<div class="line">exposureclip=&lt;X&gt;</div>
</div>
</td>
<td><p>Clip away the underexposed part of the map, below a relative exposure
X times the most exposed part of the map.  This option works similarly to
the <a class="reference internal" href="#exposureclip">exposureclip</a> option, but applies only to the map used for deriving
the pointing internally.</p></td>
</tr>
<tr class="row-even"><td><p id="pointing-lsq"><strong>pointing.lsq</strong></p>
</td>
<td><div class="line-block">
<div class="line">[pointing]</div>
<div class="line">lsq={True, False}</div>
</div>
</td>
<td><p>Attempt to fit the pointing using Least-Squares method rather than the
chosen <a class="reference internal" href="#pointing-method">pointing.method</a>.  This will usually result in a better fit,
but does not always successfully converge when the source is not easily
modelled by a Gaussian.  In case the LSQ method fails, a secondary
attempt will be made using <a class="reference internal" href="#pointing-method">pointing.method</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="pointing-method"><strong>pointing.method</strong></p>
</td>
<td><div class="line-block">
<div class="line">[pointing]</div>
<div class="line">method={centroid, position, peak}</div>
</div>
</td>
<td><p>Specify the method used for obtaining positions of pointing sources.
The available methods are:</p>
<ul class="simple">
<li><p><em>peak</em>: Take the maximum value as the peak location.</p></li>
<li><p><em>centroid</em>: Take the centroid as the peak location.</p></li>
<li><p><em>position</em>: The same as ‘peak’.</p></li>
</ul>
<p>See <a class="reference internal" href="#pointing-suggest">pointing.suggest</a>.</p>
</td>
</tr>
<tr class="row-even"><td><p id="pointing-radius"><strong>pointing.radius</strong></p>
</td>
<td><div class="line-block">
<div class="line">[pointing]</div>
<div class="line">radius=&lt;X&gt;</div>
</div>
</td>
<td><p>Restrict the pointing fit to a circular area, with radius X (arcseconds),
around the nominal map center.  it may be useful for deriving pointing in
a crowded field.  See <a class="reference internal" href="#pointing-suggest">pointing.suggest</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="pointing-reduce-degrees"><strong>pointing.reduce_degrees</strong></p>
</td>
<td><div class="line-block">
<div class="line">[pointing]</div>
<div class="line">reduce_degrees={True, False}</div>
</div>
</td>
<td><p>Allows the degree of spline fit to be lowered if there are insufficient
points to allow for the requested fit (see <a class="reference internal" href="#pointing-degree">pointing.degree</a>).</p></td>
</tr>
<tr class="row-even"><td><p id="pointing-significance"><strong>pointing.significance</strong></p>
</td>
<td><div class="line-block">
<div class="line">[pointing]</div>
<div class="line">significance=&lt;X&gt;</div>
</div>
</td>
<td><p>Set the significance (S/N) level required for pointing sources to provide
a valid pointing result.  If the option is not set, a value of 5.0 is
assumed.</p></td>
</tr>
<tr class="row-odd"><td><p id="pointing-suggest"><strong>pointing.suggest</strong></p>
</td>
<td><div class="line-block">
<div class="line">[pointing]</div>
<div class="line">suggest={True, False}</div>
</div>
</td>
<td><p>Fit pointing for each input scan at the end of the reduction.  It can
also be triggered by the <a class="reference internal" href="#point">point</a> shorthand (alias), and may be enabled by
default for certain types of scans, depending on the instrument.  E.g.,
for HAWC+, pointing fits are automatically enabled for short single-scan
reductions.  See <a class="reference internal" href="#pointing-significance">pointing.significance</a>, <a class="reference internal" href="#pointing-radius">pointing.radius</a>,
<a class="reference internal" href="#pointing-exposureclip">pointing.exposureclip</a>, and <a class="reference internal" href="#pointing-method">pointing.method</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="pointing-tolerance"><strong>pointing.tolerance</strong></p>
</td>
<td><div class="line-block">
<div class="line">[pointing]</div>
<div class="line">tolerance=&lt;X&gt;</div>
</div>
</td>
<td><p>Control how close (relative to the beam FWHM) the telescope pointing must
be to its target position for determining photometry.  A distance of 1/5
beams can result in a 10% degradation on the boundaries, while the signal
would degrade by 25% at 1/3 beams distance.  This setting has no effect
outside of photometry reductions.  See <a class="reference internal" href="#phases">phases</a> and <a class="reference internal" href="#chopped">chopped</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="positions-smooth"><strong>positions.smooth</strong></p>
</td>
<td><div class="line-block">
<div class="line">[positions]</div>
<div class="line">smooth=&lt;X&gt;</div>
</div>
</td>
<td><p>Specify that the telescope encoder data should be smoothed with a time
window X seconds wide in order to minimize the effects on encoder noise
on the calculation of scanning speeds and accelerations.  These
calculations may result in data being discarded, and are used in
determining the optimal downsampling rates.  See <a class="reference internal" href="#aclip">aclip</a>, <a class="reference internal" href="#vclip">vclip</a> and
<a class="reference internal" href="#downsample">downsample</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="projection"><strong>projection</strong></p>
</td>
<td><p>projection=&lt;name&gt;</p></td>
<td><p>Choose a map projection to use.  The following projections are available:</p>
<ul class="simple">
<li><p><em>SFL</em>: Sanson-Flamsteed</p></li>
<li><p><em>SIN</em>: Slant Orthographic</p></li>
<li><p><em>TAN</em>: Gnomonic</p></li>
<li><p><em>ZEA</em>: Zenithal Equal Area</p></li>
<li><p><em>MER</em>: Mercator</p></li>
<li><p><em>CAR</em>: Plate-Carree</p></li>
<li><p><em>AIT</em>: Hammer-Aitoff</p></li>
<li><p><em>GLS</em>: Global Sinusoidal</p></li>
<li><p><em>STG</em>: Stereographic</p></li>
<li><p><em>ARC</em>: Zenithal Equidistant</p></li>
</ul>
<p>See <a class="reference internal" href="#system">system</a>, <a class="reference internal" href="#grid">grid</a> and <a class="reference internal" href="#map-size">map.size</a>.</p>
</td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="pwv41k">
<div class="line"><strong>pwv41k</strong></div>
<div class="line">Telescope: SOFIA</div>
</div>
</td>
<td><p>pwv41k=&lt;X&gt;</p></td>
<td><p>Set a typical PWV value to X microns at 41k feet altitude.  See
<a class="reference internal" href="#tau-pwvmodel">tau.pwvmodel</a> and <a class="reference internal" href="#pwvscale">pwvscale</a>.</p></td>
</tr>
<tr class="row-even"><td><div class="line-block" id="pwvscale">
<div class="line"><strong>pwvscale</strong></div>
<div class="line">Telescope: SOFIA</div>
</div>
</td>
<td><p>pwvscale=&lt;X&gt;</p></td>
<td><p>The typical water vapor scale height (kft) around 41 kilofeet altitude.
See <a class="reference internal" href="#tau-pwvmodel">tau.pwvmodel</a> and <a class="reference internal" href="#pwv41k">pwv41k</a>.</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="radec">
<div class="line"><strong>radec</strong></div>
<div class="line">Sets: system=equatorial</div>
</div>
</td>
<td><p>radec={True, False}</p></td>
<td><p>Reduce using equatorial coordinates for mapping (default).  See <a class="reference internal" href="#altaz">altaz</a>
and <a class="reference internal" href="#system">system</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="range"><strong>range</strong></p>
</td>
<td><div class="line-block">
<div class="line">[range]</div>
<div class="line">value=&lt;min&gt;:&lt;max&gt;</div>
</div>
</td>
<td><p>Set the acceptable range of data (in units it is stored).  Values outside
of this range will be flagged, and pixels that are consistent offenders
will be removed from the reduction (as set by <a class="reference internal" href="#range-flagfraction">range.flagfraction</a>.  See
<a class="reference internal" href="#dataunit">dataunit</a>, and <a class="reference internal" href="#range-flagfraction">range.flagfraction</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="range-flagfraction"><strong>range.flagfraction</strong></p>
</td>
<td><div class="line-block">
<div class="line">[range]</div>
<div class="line">flagfraction=&lt;X&gt;</div>
</div>
</td>
<td><p>Specify the maximum fraction of samples for which a channel can be out of
range (as set by <a class="reference internal" href="#range">range</a>) before that channel is flagged and removed from
the reduction.  See <a class="reference internal" href="#range">range</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="rcp"><strong>rcp</strong></p>
</td>
<td><div class="line-block">
<div class="line">[rcp]</div>
<div class="line">value=&lt;filename&gt;</div>
</div>
</td>
<td><p>Use the RCP file from &lt;filename&gt;.  RCP files can be produces by the
<a class="reference internal" href="#pixelmap">pixelmap</a> option from scans and for certain instruments, when the
observation moves a bright source over all pixels.  For rectangular
arrays, pixel positions can also be calculated on a regular grid using
<a class="reference internal" href="#pixelsize">pixelsize</a> and <a class="reference internal" href="#pcenter">pcenter</a>.  See <a class="reference internal" href="#pixelmap">pixelmap</a>, <a class="reference internal" href="#pixelsize">pixelsize</a>, and <a class="reference internal" href="#pcenter">pcenter</a></p></td>
</tr>
<tr class="row-odd"><td><p id="rcp-center"><strong>rcp.center</strong></p>
</td>
<td><div class="line-block">
<div class="line">[rcp]</div>
<div class="line">center=&lt;x&gt;,&lt;y&gt;</div>
</div>
</td>
<td><p>Define the center RCP position at x, y in arcseconds.  Centering takes
place immediately after the parsing of RCP data.  See <a class="reference internal" href="#rcp">rcp</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="rcp-gains"><strong>rcp.gains</strong></p>
</td>
<td><div class="line-block">
<div class="line">[rcp]</div>
<div class="line">gains={True, False}</div>
</div>
</td>
<td><p>Calculate coupling efficiencies using gains from the RCP files.
Otherwise, uniform coupling is assumed with sky noise gains from the
<a class="reference internal" href="#pixeldata">pixeldata</a> file.  See <a class="reference internal" href="#rcp">rcp</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="rcp-rotate"><strong>rcp.rotate</strong></p>
</td>
<td><div class="line-block">
<div class="line">[rcp]</div>
<div class="line">rotate=&lt;X&gt;</div>
</div>
</td>
<td><p>Rotate the RCP positions by X degrees (anti-clockwise).  Rotations take
place after centering (if specified).  See <a class="reference internal" href="#rcp">rcp</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="rcp-zoom"><strong>rcp.zoom</strong></p>
</td>
<td><div class="line-block">
<div class="line">[rcp]</div>
<div class="line">zoom=&lt;X&gt;</div>
</div>
</td>
<td><p>Zoom (rescale) the RCP position data by the scaling factor X.  Rescaling
takes place after the centering (if defined).  See <a class="reference internal" href="#rcp">rcp</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="recall"><strong>recall</strong></p>
</td>
<td><p>recall=&lt;key1&gt;,&lt;key2&gt;,…</p></td>
<td><p>Undo <a class="reference internal" href="#forget">forget</a>, and reinstates &lt;key&gt; to its old value.  See <a class="reference internal" href="#forget">forget</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="regrid"><strong>regrid</strong></p>
</td>
<td><p>regrid=&lt;X&gt;</p></td>
<td><p>Re-grid the final map to a different grid than that used during the
reduction where X is the final image pixel size in arcseconds.  See
<a class="reference internal" href="#grid">grid</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="resolution"><strong>resolution</strong></p>
</td>
<td><p>resolution=&lt;X&gt;</p></td>
<td><p>Define the resolution of the instrument.  For single color imaging
arrays, this is equivalent to <a class="reference internal" href="#beam">beam</a> with X specifying the instrument’s
main beam FWHM in arcseconds.  Other instruments (e.g. heterodyne
receivers) may interpret ‘resolution’ differently.  See <a class="reference internal" href="#beam">beam</a>.</p></td>
</tr>
<tr class="row-even"><td><div class="line-block" id="roll">
<div class="line"><strong>roll</strong></div>
<div class="line">Instrument: HAWC+</div>
<div class="line">Alias: correlated.roll</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[roll]</div>
<div class="line">value={True, False}</div>
</div>
</td>
<td><p>Remove correlations with the second-derivative of the aircraft roll angle
(roll-type accelerations).  See <a class="reference internal" href="#correlated-modality">correlated.&lt;modality&gt;</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="rotation"><strong>rotation</strong></p>
</td>
<td><div class="line-block">
<div class="line">[rotation]</div>
<div class="line">value=&lt;X&gt;</div>
</div>
</td>
<td><p>Define the instrument rotation X in degrees if applicable.</p></td>
</tr>
<tr class="row-even"><td><div class="line-block" id="rotation-sub">
<div class="line"><strong>rotation.&lt;sub&gt;</strong></div>
<div class="line">Instrument: HAWC+</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[rotation]</div>
<div class="line">&lt;sub&gt;=&lt;X&gt;</div>
</div>
</td>
<td><p>Specify subarray rotations X (degrees) where &lt;sub can be R0, R1, T0,
and/or T1.</p></td>
</tr>
<tr class="row-odd"><td><p id="rounds"><strong>rounds</strong></p>
</td>
<td><p>rounds=&lt;N&gt;</p></td>
<td><p>Iterate N times.  You may want to increase the number of default
iterations either to recover more extended emission (e.g. when <a class="reference internal" href="#extended">extended</a>
is set), or to go deeper (especially when the <a class="reference internal" href="#faint">faint</a> or <a class="reference internal" href="#deep">deep</a> options are
used).  See <a class="reference internal" href="#iteration">iteration</a>, <a class="reference internal" href="#extended">extended</a>, <a class="reference internal" href="#faint">faint</a>, and <a class="reference internal" href="#deep">deep</a>.</p></td>
</tr>
<tr class="row-even"><td><div class="line-block" id="rows">
<div class="line"><strong>rows</strong></div>
<div class="line">Instrument: HAWC+</div>
<div class="line">Alias:  correlated.rows</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[rows]</div>
<div class="line">value={True, False}</div>
</div>
</td>
<td><p>Decorrelate on detector rows, or set options for it.  See
<a class="reference internal" href="#correlated-modality">correlated.&lt;modality&gt;</a>.</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="rtoc">
<div class="line"><strong>rtoc</strong></div>
<div class="line">Instrument: HAWC+</div>
</div>
</td>
<td><p>rtoc={True, False}</p></td>
<td><p>Instruct SOFSCAN to reference maps to Real-Time Object Coordinates (RTOC)
for sidereal and non-sideral sources alike.  Normally, sidereal object
coordinates are determined via the header keywords OBSRA/OBDEC or
OBJRA/OBJDEC.  However, these were not always filled correctly during the
2016 October flights, so this option provides a workaround in those
scans.</p></td>
</tr>
<tr class="row-even"><td><p id="scale"><strong>scale</strong></p>
</td>
<td><div class="line-block">
<div class="line">[scale]</div>
<div class="line">value={&lt;X&gt;, &lt;filename&gt;}</div>
</div>
</td>
<td><p>Set the calibration scaling of the data.  The following values are
available:</p>
<ul class="simple">
<li><p><em>X</em>: An explicit scaling value X, by which the entire scan data is
scaled.</p></li>
<li><p><em>filename</em>: The name of a calibration file which among other things,
contains the ISO timestamp and the corresponding calibration values for</p></li>
</ul>
<p>Note: not all instruments support the &lt;filename&gt; value.  See <a class="reference internal" href="#tau">tau</a>, <a class="reference internal" href="#gain">gain</a>,
<a class="reference internal" href="#invert">invert</a>, and <a class="reference internal" href="#jackknife">jackknife</a>.</p>
</td>
</tr>
<tr class="row-odd"><td><p id="scale-grid"><strong>scale.grid</strong></p>
</td>
<td><div class="line-block">
<div class="line">[scale]</div>
<div class="line">grid=&lt;X&gt;</div>
</div>
</td>
<td><p>The grid resolution in arcseconds for which the <a class="reference internal" href="#scale">scale</a> value was
derived.  If set, this correctly conserves flux values if <a class="reference internal" href="#grid">grid</a> is
set to a different value.</p></td>
</tr>
<tr class="row-even"><td><p id="scanmaps"><strong>scanmaps</strong></p>
</td>
<td><p>scanmaps={True, False}</p></td>
<td><p>When specified, a map will be written for each scan (every time it is
solved), under the name ‘scan-&lt;scanno&gt;.fits’ in the usual output path.
Best to use as:</p>
<div class="line-block">
<div class="line">[iteration]</div>
<div class="line">[[final]]</div>
<div class="line">scanmaps=True</div>
</div>
<p>To avoid unnecessary writing of scan maps for every iteration.  See
<a class="reference internal" href="#final">final</a> and <a class="reference internal" href="#source">source</a>.</p>
</td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="scanpol">
<div class="line"><strong>scanpol</strong></div>
<div class="line">Instrument: HAWC+</div>
<div class="line">Sets: config=scanpol.cfg</div>
</div>
</td>
<td><p>scanpol={True, False}</p></td>
<td><p>Use for scanning polarimetry scans with HAWC+.  Reads and applies the
‘scanpol.cfg’ configuration file.</p></td>
</tr>
<tr class="row-even"><td><p id="scramble"><strong>scramble</strong></p>
</td>
<td><p>scramble={True, False}</p></td>
<td><p>Make a map with inverted scanning offsets.  Under the typical scanning
patterns, this will not produce a coherent source.  Therefore, it is a
good method for checking on the noise properties of deep maps.  The
method essentially smears the source flux all over the map.  While not as
good as <a class="reference internal" href="#jackknife">jackknife</a> for producing pure noise maps, <a class="reference internal" href="#jackknife">jackknife</a> requires a
large number of scans for robust results (because of the random
inversion), whereas ‘scramble’ can be used also for few, or even single
scans to nearly the same effect.</p></td>
</tr>
<tr class="row-odd"><td><p id="segment"><strong>segment</strong></p>
</td>
<td><p>segment=&lt;X&gt;</p></td>
<td><p>Break long integrations into shorter ones, with a maximum duration of X
seconds.  It is the complement option to <a class="reference internal" href="#subscan-merge">subscan.merge</a>, which does the
opposite.  ‘segment’ can also be used together with <a class="reference internal" href="#subscan-split">subscan.split</a> to
break the shorter segments into separate scans altogether.</p></td>
</tr>
<tr class="row-even"><td><p id="serial"><strong>serial</strong></p>
</td>
<td><div class="line-block">
<div class="line">[serial]</div>
<div class="line">[[&lt;scan_range&gt;]]</div>
<div class="line">&lt;key&gt;=&lt;value&gt;</div>
<div class="line">…</div>
</div>
</td>
<td><p>Specify settings to apply when the scan’s serial number falls within a
specified range.  &lt;scan_range&gt; may be specified as:</p>
<ul class="simple">
<li><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">*</span></code>: always</p></li>
<li><p>a:b: Falls between the range (a, b)</p></li>
<li><p>&gt;X: After serial number X</p></li>
<li><p>&gt;=X: From serial number X</p></li>
<li><p>&lt;X: Before serial number X</p></li>
<li><p>&lt;=X: Before and up to serial number X</p></li>
</ul>
</td>
</tr>
<tr class="row-odd"><td><p id="shift"><strong>shift</strong></p>
</td>
<td><p>shift=&lt;X&gt;</p></td>
<td><p>Shift the data by X seconds to the frame headers.  It can be used to
diagnose or correct for timing problems.</p></td>
</tr>
<tr class="row-even"><td><p id="sigmaclip"><strong>sigmaclip</strong></p>
</td>
<td><p>sigmaclip={n, True,False}</p></td>
<td><p>Removes frames that are outside of the permissible scanning speed range
by iteratively remove speeds that are <code class="xref py py-obj docutils literal notranslate"><span class="pre">n</span></code> times the
standard deviation away from the median speed value. If <code class="xref py py-obj docutils literal notranslate"><span class="pre">simgaclip</span></code> is
set to True <code class="xref py py-obj docutils literal notranslate"><span class="pre">n</span></code> defaults to 5.</p></td>
</tr>
<tr class="row-odd"><td><p id="signal-response"><strong>signal-response</strong></p>
</td>
<td><p>signal-response={True, False}</p></td>
<td><p>This is a diagnostic option and affects the log output of decorrelation
steps.  When set, each decorrelation step will produce a sequence of
numbers, corresponding to the normalized covariances of the detector
signals in each correlated mode in the modality.  The user may take this
number as an indication of the importance of each type of correlated
signal, and make decisions as to whether a decorrelation step is truly
necessary.  Values close to 1.0 indicate signals that are (almost)
perfectly correlated, whereas values near zero are indicative of
negligible corrections.  See <a class="reference internal" href="#correlated-modality">correlated.&lt;modality&gt;</a> and <a class="reference internal" href="#ordering">ordering</a>.</p></td>
</tr>
<tr class="row-even"><td><div class="line-block" id="skydip">
<div class="line"><strong>skydip</strong></div>
<div class="line">Sets: source.type=skydip</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[skydip]</div>
<div class="line">value={True, False}</div>
</div>
</td>
<td><p>Reduce skydip data instead of trying to make in impossibly large map out
of it.  This option is equivalent to specifying ‘source.type=skydip’
which is activated conditionally instead of an alias.</p></td>
</tr>
<tr class="row-odd"><td><p id="skydip-elrange"><strong>skydip.elrange</strong></p>
</td>
<td><div class="line-block">
<div class="line">[skydip]</div>
<div class="line">elrange=&lt;min&gt;:&lt;max&gt;</div>
</div>
</td>
<td><p>Set the elevation range (degrees) to use for fitting the skydip model.
In some cases, either the data may be corrupted at low or high
elevations, or both.  This is a useful option to restrict the skydip data
to the desired elevation range.  Use with caution to keep the skydip
results robust.  See <a class="reference internal" href="#skydip">skydip</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="skydip-fit"><strong>skydip.fit</strong></p>
</td>
<td><div class="line-block">
<div class="line">[skydip]</div>
<div class="line">fit=&lt;p1&gt;,&lt;p2&gt;,…</div>
</div>
</td>
<td><p>Specify the list of parameters to fit for the skydip model.  The standard
model is:</p>
<blockquote>
<div><p>y(EL) = kelvin * tsky * (1-exp(-tau/sin(EL))) + offset</p>
</div></blockquote>
<p>where parameters (&lt;pN&gt;) may be:</p>
<ul class="simple">
<li><p><em>kelvin</em>: conversion from Kelvin to dataunits.  See <a class="reference internal" href="#kelvin">kelvin</a>, <a class="reference internal" href="#dataunit">dataunit</a>,
and <a class="reference internal" href="#k2jy">k2jy</a>.</p></li>
<li><p><em>tsky</em>: sky temperature (in Kelvins).  See <a class="reference internal" href="#skydip-tsky">skydip.tsky</a>.</p></li>
<li><p><em>tau</em>: the in band zenith opacity.  See <a class="reference internal" href="#skydip-tau">skydip.tau</a>.</p></li>
<li><p><em>offset</em>: an offset in dataunits.  See <a class="reference internal" href="#skydip-offset">skydip.offset</a>.</p></li>
</ul>
<p>The default is to fit ‘kelvin’, ‘tau’, and ‘offset’, and assume that the
sky temperature is close to ambient.  The assumption os the sky
temperature is not critical so long as the conversion factor ‘kelvin’ is
fitted to absorb an overall scaling.</p>
</td>
</tr>
<tr class="row-odd"><td><p id="skydip-grid"><strong>skydip.grid</strong></p>
</td>
<td><div class="line-block">
<div class="line">[skydip]</div>
<div class="line">grid=&lt;X&gt;</div>
</div>
</td>
<td><p>Set the elevation binning (arcseconds) of the skydip data.  See <a class="reference internal" href="#grid">grid</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="skydip-offset"><strong>skydip.offset</strong></p>
</td>
<td><div class="line-block">
<div class="line">[skydip]</div>
<div class="line">offset=&lt;X&gt;</div>
</div>
</td>
<td><p>Specify the initial offset value in <a class="reference internal" href="#dataunit">dataunit</a>.  See <a class="reference internal" href="#skydip-fit">skydip.fit</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="skydip-tau"><strong>skydip.tau</strong></p>
</td>
<td><div class="line-block">
<div class="line">[skydip]</div>
<div class="line">tau=&lt;X&gt;</div>
</div>
</td>
<td><p>Specify the initial in-band zenith opacity.  See <a class="reference internal" href="#skydip-fit">skydip.fit</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="skydip-tsky"><strong>skydip.tsky</strong></p>
</td>
<td><div class="line-block">
<div class="line">[skydip]</div>
<div class="line">tsky=&lt;X&gt;</div>
</div>
</td>
<td><p>Specify the initial sky temperature in Kelvins.  By default, the ambient
temperature (if available) will be used.  See <a class="reference internal" href="#skydip-fit">skydip.fit</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="smooth"><strong>smooth</strong></p>
</td>
<td><div class="line-block">
<div class="line">[smooth]</div>
<div class="line">value={&lt;X&gt;, minimal, halfbeam, 2/3beam, beam, optimal}</div>
</div>
</td>
<td><p>Smooth the map by X arcsec FWHM beam.  Smoothing helps improve visual
appearance, but is also useful during reduction to create more
redundancy in the data in the intermediate reduction steps.  Also,
smoothing by the beam is optimal for point source extraction from deep
fields.  Therefore, beam smoothing is default with the <a class="reference internal" href="#deep">deep</a> option
(see ‘deep.cfg’).  Typically you want to use some smoothing during
reduction, and you may want to turn it off in the final map.  Such a
typical configuration may look like:</p>
<div class="line-block">
<div class="line">smooth=9.0  # 9” smoothing at first</div>
<div class="line">[iteration]</div>
<div class="line">[[2]]</div>
<div class="line">smooth=12.0  # smooth more later</div>
<div class="line">[[last]]</div>
<div class="line">forget=smooth  # no smoothing at end</div>
</div>
<p>Other than specifying explicit values, you can use the predefined
values: ‘minimal’, ‘halfbeam’, ‘2/3beam’, ‘beam’, or ‘optimal’.  See
<a class="reference internal" href="#smooth-optimal">smooth.optimal</a>, <a class="reference internal" href="#final">final</a>, <a class="reference internal" href="#source-filter">source.filter</a>, and <a class="reference internal" href="#grid">grid</a>.</p>
</td>
</tr>
<tr class="row-even"><td><div class="line-block" id="smooth-external">
<div class="line"><strong>smooth.external</strong></div>
<div class="line"><em>(Not implemented yet)</em></div>
</div>
</td>
<td><div class="line-block">
<div class="line">[smooth]</div>
<div class="line">external={True, False}</div>
</div>
</td>
<td><p>Do not actually perform the smoothing set by the <a class="reference internal" href="#smooth">smooth</a> option.
Instead, use the <a class="reference internal" href="#smooth">smooth</a> value as an assumption in calculating
smoothing-related corrections.  The option is designed for the reduction
of very large datasets, which have to be “split” into smaller,
manageable sized chunks.  The unsmoothed outputs can be coadded and then
smoothed to the desired amount before feeding the result back for further
rounds of reduction via <a class="reference internal" href="#source-model">source.model</a>.  See <a class="reference internal" href="#smooth">smooth</a>, <a class="reference internal" href="#subscan-split">subscan.split</a>,
and <a class="reference internal" href="#source-model">source.model</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="smooth-optimal"><strong>smooth.optimal</strong></p>
</td>
<td><div class="line-block">
<div class="line">[smooth]</div>
<div class="line">optimal=&lt;X&gt;</div>
</div>
</td>
<td><p>Define the optimal smoothing for point-source extraction if it is
different from beam-smoothing.  For arrays whose detectors are completely
independent, beam-smoothing produces the optimal signal-to-noise for
point sources.  However, if the detectors are not independent, the
optimal smoothing may vary.  This is expected to be the case for some
filled arrays, where one expects a certain level of beam-sized photon
correlations.  See <a class="reference internal" href="#smooth">smooth</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="source"><strong>source</strong></p>
</td>
<td><div class="line-block">
<div class="line">[source]</div>
<div class="line">value={True, False}</div>
</div>
</td>
<td><p>Solve for the source model, or set options for it.</p></td>
</tr>
<tr class="row-odd"><td><p id="source-correct"><strong>source.correct</strong></p>
</td>
<td><div class="line-block">
<div class="line">[source]</div>
<div class="line">value={True, False}</div>
</div>
</td>
<td><p>Correct peak fluxes for the point source filtering effect of the various
reduction steps (default).  The filtering of point sources is carefully
calculated through the reduction steps, this with the correction scheme,
point source fluxes ought to stay constant (within a few percent)
independent of the pipeline configuration.  See <a class="reference internal" href="#faint">faint</a>, <a class="reference internal" href="#deep">deep</a>, <a class="reference internal" href="#bright">bright</a>,
<a class="reference internal" href="#ordering">ordering</a>, and <a class="reference internal" href="#whiten">whiten</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="source-coupling"><strong>source.coupling</strong></p>
</td>
<td><div class="line-block">
<div class="line">[source]</div>
<div class="line">[[coupling]]</div>
<div class="line">&lt;options…&gt;</div>
</div>
</td>
<td><p>If present in the configuration, (re-)calculate point source coupling
efficiencies (the ratio of point-source and sky-noise response) as part
of the source modeling step.  This is only really useful for bright
sources.  See <a class="reference internal" href="#source-coupling-range">source.coupling.range</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="source-coupling-range"><strong>source.coupling.range</strong></p>
</td>
<td><div class="line-block">
<div class="line">[source]</div>
<div class="line">[[coupling]]</div>
<div class="line">range=&lt;min&gt;:&lt;max&gt;</div>
</div>
</td>
<td><p>Specify the range of acceptable coupling efficiencies relative to the
“average” of all pixels when <a class="reference internal" href="#source-coupling">source.coupling</a> is used to calculate
these based on bright source responses.  Pixels with efficiencies outside
of the specified range will be flagged and ignored from further source
modeling steps until these flags are cleared again in the reduction.
See <a class="reference internal" href="#correlated-modality-gainrange">correlated.&lt;modality&gt;.gainrange</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="source-coupling-s2n"><strong>source.coupling.s2n</strong></p>
</td>
<td><div class="line-block">
<div class="line">[source]</div>
<div class="line">[[coupling]]</div>
<div class="line">s2n=&lt;min&gt;:&lt;max&gt;</div>
</div>
</td>
<td><p>Set the acceptable range of S/N required in the map for using the
position for estimating detector coupling gains when the
<a class="reference internal" href="#source-coupling">source.coupling</a> option is enabled.</p></td>
</tr>
<tr class="row-odd"><td><p id="source-delete-scan"><strong>source.delete_scan</strong></p>
</td>
<td><div class="line-block">
<div class="line">[source]</div>
<div class="line">delete_scan=&lt;True,False&gt;</div>
</div>
</td>
<td><p>If True, and updating the source in parallel is also True (see
<a class="reference internal" href="#parallel-source">parallel.source</a>, delete the individual scan source model once all
required processing has been performed.  This is recommended when
dealing with large sets of data to reduce memory pressure.</p></td>
</tr>
<tr class="row-even"><td><p id="source-despike"><strong>source.despike</strong></p>
</td>
<td><div class="line-block">
<div class="line">[source]</div>
<div class="line">[[despike]]</div>
<div class="line">&lt;options…&gt;</div>
</div>
</td>
<td><p>If present in the configuration, despike the scan maps using an S/N
threshold of <a class="reference internal" href="#source-despike-level">source.despike.level</a>.  Clearly, this should be higher
than the most significant source in your map.  Therefore, it is only
really useful in <a class="reference internal" href="#deep">deep</a> model, where 5-signa despiking is default.
See ‘deep.cfg’.</p></td>
</tr>
<tr class="row-odd"><td><p id="source-despike-level"><strong>source.despike.level</strong></p>
</td>
<td><div class="line-block">
<div class="line">[source]</div>
<div class="line">[[despike]]</div>
<div class="line">level=&lt;X&gt;</div>
</div>
</td>
<td><p>Set the source despiking level to an S/N of X.  You probably want to set
X to be no more than about 10 times the most significant source in your
map.  See <a class="reference internal" href="#source-despike">source.despike</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="source-filter"><strong>source.filter</strong></p>
</td>
<td><div class="line-block">
<div class="line">[source]</div>
<div class="line">[[filter]]</div>
<div class="line">&lt;options…&gt;</div>
</div>
</td>
<td><p>Filter extended structures.  By default, the filter will skip over map
pixels that are above the <a class="reference internal" href="#source-filter-blank">source.filter.blank</a> S/N level (&gt;6 by
default).  Thus, any structure above this significance level will remain
unfiltered.  Filtering is useful to get deeper in the map when retaining
the very faint extended structures is not an issue.  Filtering above 5
times the source size (see sourcesize_`) is default when the filter is
used.</p></td>
</tr>
<tr class="row-odd"><td><p id="source-filter-blank"><strong>source.filter.blank</strong></p>
</td>
<td><div class="line-block">
<div class="line">[source]</div>
<div class="line">[[filter]]</div>
<div class="line">blank=&lt;X&gt;</div>
</div>
</td>
<td><p>Set the blanking level of the large-scale structure (LSS) filter.  Any
map pixels with an S/N above the specified level will be skipped over,
and therefore remain unaffected by the filter.  See
<a class="reference internal" href="#source-filter-fwhm">source.filter.fwhm</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="source-filter-fwhm"><strong>source.filter.fwhm</strong></p>
</td>
<td><div class="line-block">
<div class="line">[source]</div>
<div class="line">[[filter]]</div>
<div class="line">fwhm=&lt;X&gt;</div>
</div>
</td>
<td><p>Specify the Gaussian FWHM of the large-scale structure (LSS) filter.
Values greater than about 5-times the beam size are recommended in order
to avoid the unnecessary filtering of compact or point sources.  See
<a class="reference internal" href="#source-filter-blank">source.filter.blank</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="source-filter-type"><strong>source.filter.type</strong></p>
</td>
<td><div class="line-block">
<div class="line">[source]</div>
<div class="line">[[filter]]</div>
<div class="line">type={convolution, fft}</div>
</div>
</td>
<td><p>Specify the type of the large-scale structure filter.  Convolution is
more accurate but may be slower than FFT, especially for very large maps.</p></td>
</tr>
<tr class="row-even"><td><p id="source-fixedgains"><strong>source.fixedgains</strong></p>
</td>
<td><div class="line-block">
<div class="line">[source]</div>
<div class="line">fixedgains={True, False}</div>
</div>
</td>
<td><p>Specify the use of fixed source gains (e.g. from an RCP file).  Normally,
SOFSCAN calculates source gains based on the correlated noise response
and the specified point source couplings ( e.g. as derived from the two
gain columns of RCP files).  This option can be used to treat the
supplied source gains as static (i.e. decoupled from the sky-noise
gains).  See <a class="reference internal" href="#source-coupling">source.coupling</a> and <a class="reference internal" href="#pixelmap">pixelmap</a>.</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="source-flatfield">
<div class="line"><strong>source.flatfield</strong></div>
<div class="line">Sets: config=flatfield.cfg</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[source]</div>
<div class="line">flatfield={True, False}</div>
</div>
</td>
<td><p>Use for deriving flatfields based on response to a source.  For it to
work effectively, you need a scan that moves bright source emission over
all fields.  It is a soft option, defined in ‘default.cfg’, and it
results in loading ‘flatfield.cfg’ for configuring optimal settings for
source gain derivation.</p></td>
</tr>
<tr class="row-even"><td><p id="source-intermediates"><strong>source.intermediates</strong></p>
</td>
<td><div class="line-block">
<div class="line">[source]</div>
<div class="line">intermediates={True, False}</div>
</div>
</td>
<td><p>Write the maps made during the reduction into ‘intermediate.fits’ (inside
the SOFSCAN output directory).  This allows the user to keep an eye on
the evolution of maps iteration-by-iteration.  Each iteration will
overwrite this temporary file, and it will be erased at the end of the
reduction.</p></td>
</tr>
<tr class="row-odd"><td><p id="source-mem"><strong>source.mem</strong></p>
</td>
<td><div class="line-block">
<div class="line">[source]</div>
<div class="line">mem={True, False}</div>
</div>
</td>
<td><p>Use the maximum-entropy method (MEM) correction to the source map.  The
MEM requirement suppresses some of the noise on the small spatial scales,
and pushes solutions closer to the zero level for low S/N structures.
This increases contrast between significant source structures and
background.  It is similar to the MEM used in radio interferometry,
although there are key differences.  For one, interferometry measures
components in the uv-plane, and MEM corrections are applied in xy
coordinate space.  For SOFSCAN, both the solutions and corrections are
applied in the same configuration space.  See <a class="reference internal" href="#source-mem-lambda">source.mem.lambda</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="source-mem-lambda"><strong>source.mem.lambda</strong></p>
</td>
<td><div class="line-block">
<div class="line">[source]</div>
<div class="line">[[mem]]</div>
<div class="line">lambda=&lt;X&gt;</div>
</div>
</td>
<td><p>Specify the desirability of MEM solutions relative to the
maximum-likelihood solution.  Typical values of lambda are in the range
0.1 to 1, but higher or lower values may be set to give extra weight
towards one type of solution.</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="source-model">
<div class="line"><strong>source.model</strong></div>
<div class="line"><em>(Not implemented yet)</em></div>
</div>
</td>
<td><div class="line-block">
<div class="line">[source]</div>
<div class="line">model=&lt;filename&gt;</div>
</div>
</td>
<td><p>Specify an initial source model to use in the reduction.  This may be
useful when reducing large datasets where all data cannot be reduced
together.  Instead, the data can be split into manageable sized chunks
which are reduced separately.  The results can be coadded to create a
composite map.  This may be further manipulated (e.g. S/N clipping,
smoothing, filtering, etc.) before feeding back into another round of
reduction.  Clipping and blanking settings are usually altered when an
a-priori source-model is thus defined.  See <a class="reference internal" href="#blank">blank</a>, <a class="reference internal" href="#clip">clip</a>, and
<a class="reference internal" href="#smooth-external">smooth.external</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="source-nosync"><strong>source.nosync</strong></p>
</td>
<td><div class="line-block">
<div class="line">[source]</div>
<div class="line">nosync={True, False}</div>
</div>
</td>
<td><p>Do not bother syncing the source solution back into the raw timestream.
This saves a bit of time in the last round of most reductions when the
<a class="reference internal" href="#source">source</a> is the last step in the pipeline, and the residuals are not used
otherwise (e.g. by <a class="reference internal" href="#write-covar">write.covar</a>, <a class="reference internal" href="#write-ascii">write.ascii</a> or <a class="reference internal" href="#write-spectrum">write.spectrum</a>).</p></td>
</tr>
<tr class="row-odd"><td><p id="source-redundancy"><strong>source.redundancy</strong></p>
</td>
<td><div class="line-block">
<div class="line">[source]</div>
<div class="line">redundancy=&lt;N&gt;</div>
</div>
</td>
<td><p>Specify the minimum redundancy (N samples) that each scan-map pixel
output ought to have in order to be considered valid.  Pixels with
redundancies smaller than this critical value will be flagged and not
used in the composite source making.</p></td>
</tr>
<tr class="row-even"><td><p id="source-sign"><strong>source.sign</strong></p>
</td>
<td><div class="line-block">
<div class="line">[source]</div>
<div class="line">sign=&lt;spec&gt;</div>
</div>
</td>
<td><p>Most astronomical source have a definite signedness.  For continuum, we
expect to see emission, except when looking at SZ clusters at 2-mm, which
have a unique negative signature.  SOFSCAN can do a better job if the
signature of the source is predetermined.  The sign specification &lt;spec&gt;
can be:</p>
<ul class="simple">
<li><p><em>positive</em>: +, positive, plus, pos, &gt;0</p></li>
<li><p><em>negative</em>: -, negative, minus, neg, &lt;0</p></li>
<li><p><em>any</em>: <code class="xref py py-obj docutils literal notranslate"><span class="pre">*</span></code>, any, 0</p></li>
</ul>
<p>When not set, the default is to assume that sources be may of either sign
(same as <code class="xref py py-obj docutils literal notranslate"><span class="pre">*</span></code>, any, or 0).  The signature determines how source clipping
and blanking are implemented.  See <a class="reference internal" href="#clip">clip</a> and <a class="reference internal" href="#blank">blank</a>.</p>
</td>
</tr>
<tr class="row-odd"><td><p id="source-type"><strong>source.type</strong></p>
</td>
<td><div class="line-block">
<div class="line">[source]</div>
<div class="line">type=&lt;type&gt;</div>
</div>
</td>
<td><p>By default, SOFSCAN will try to make a map from the data.  However, some
instruments may take data that is analyzed differently.  For example, you
may want to use SOFSCAN to reduce pixels maps (to determine the position
of pixels on the sky), or skydips (to derive appropriate opacities), or
do point source photometry.  Presently, the following source types
(&lt;type&gt;) are supported for all instruments:</p>
<ul class="simple">
<li><p><em>map</em>: Make a map of the source (default)</p></li>
<li><p><em>cube</em>: Make a spectral cube</p></li>
<li><p><em>skydip</em>: Reduce skydips and determine opacities by fitting a model.</p></li>
<li><p><em>pixelmap</em>: Create individual maps for every pixel, and use it to
determine their location in the field of view.</p></li>
<li><p><em>None</em>: Do not generate a source model.  Useful for lab/diagnostic
reductions.</p></li>
</ul>
<p>Note: you may also just use <a class="reference internal" href="#skydip">skydip</a> and <a class="reference internal" href="#pixelmap">pixelmap</a> shorthands to the same
effect.</p>
</td>
</tr>
<tr class="row-even"><td><p id="sourcesize"><strong>sourcesize</strong></p>
</td>
<td><p>sourcesize=&lt;X&gt;</p></td>
<td><p>This option can be used instead of <a class="reference internal" href="#extended">extended</a> in conjunction with <a class="reference internal" href="#faint">faint</a>
or <a class="reference internal" href="#deep">deep</a> to specify the typical size of sources (FWHM in arcseconds) that
are expected.  The reduction then allows filtering structures that are
much larger than the specified source size.  If <a class="reference internal" href="#sourcesize">sourcesize</a> or <a class="reference internal" href="#extended">extended</a>
are not specified, then point-like compact sources are assumed.  The
source size helps tune the 1/f filter (see <a class="reference internal" href="#drifts">drifts</a>) optimally.  The 1/f
timescale is set to be the larger of the <a class="reference internal" href="#stability">stability</a> or 5 times the
typical source crossing time (calculated via <a class="reference internal" href="#sourcesize">sourcesize</a>).  Note that
noise whitening will mute the effect of this settings almost completely.
See <a class="reference internal" href="#faint">faint</a>, <a class="reference internal" href="#extended">extended</a>, and <a class="reference internal" href="#whiten">whiten</a>.</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="split">
<div class="line"><strong>split</strong></div>
<div class="line">Sets:</div>
<div class="line">smooth.external=True</div>
<div class="line">[last]</div>
<div class="line">forget=exposureclip</div>
</div>
</td>
<td><p>split={True, False}</p></td>
<td><p>A convenience key for adjusting options for very large data sets which
have to be split into manageable sized chunks in the reduction.  See
<a class="reference internal" href="#smooth-external">smooth.external</a> and <a class="reference internal" href="#source-model">source.model</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="stability"><strong>stability</strong></p>
</td>
<td><p>stability=&lt;X&gt;</p></td>
<td><p>Specify the instrument’s 1/f stability time scale in seconds.  This value
is used for optimmizing reduction parameters when these options are not
explicitly specified (e.g. the filtering timescale for the <a class="reference internal" href="#drifts">drifts</a>
option).  See <a class="reference internal" href="#drifts">drifts</a> and <a class="reference internal" href="#sourcesize">sourcesize</a>.</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="subarray">
<div class="line"><strong>subarray</strong></div>
<div class="line">Instrument: HAWC+</div>
</div>
</td>
<td><p>subarray=&lt;sub1&gt;,&lt;sub2&gt;,…</p></td>
<td><p>Restrict the analysis to just the selected subarrays.  For HAWC+, the
&lt;sub?&gt; may contain the subarray IDs: R0, R1, T0, and T1, or R to specify
R0 and R1, or T to specify T0 and T1.</p></td>
</tr>
<tr class="row-even"><td><p id="subscan-merge"><strong>subscan.merge</strong></p>
</td>
<td><div class="line-block">
<div class="line">[subscan]</div>
<div class="line">[[merge]]</div>
<div class="line">value={True, False}</div>
</div>
</td>
<td><p>Specifies that the integrations (subscans) in a scan should be merged
into a single timestream, will invalid frames filling potential gaps at
the boundaries to ensure proper time-spacing of all data (for time window
processing of FFTs).  See <a class="reference internal" href="#subscan-split">subscan.split</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="subscan-merge-maxgap"><strong>subscan.merge.maxgap</strong></p>
</td>
<td><div class="line-block">
<div class="line">[subscan]</div>
<div class="line">[merge]</div>
<div class="line">maxgap=&lt;X&gt;</div>
</div>
</td>
<td><p>Merging integrations (subscans) will pad gaps between them with invalid
frames as needed.  Use this option to limit how much padding X (seconds)
is allowed.  If the gap between two consecutive subscans is larger than
the maximum gap specified by this option, then the merge will continue in
a separate scan.</p></td>
</tr>
<tr class="row-even"><td><p id="subscan-minlength"><strong>subscan.minlength</strong></p>
</td>
<td><div class="line-block">
<div class="line">[subscan]</div>
<div class="line">minlength=&lt;X&gt;</div>
</div>
</td>
<td><p>Set the minimum length of integrations (subscans) to X seconds.
Integrations shorter than the specified value will be skipped during the
scan reading phase.  Most reductions rely on the background variations to
create signals from which detector gains can be estimated with the
required accuracy.  Very short integrations may not have sufficient
background signals for the robust estimation of gains, and it is thus
best to simply ignore such data.</p></td>
</tr>
<tr class="row-odd"><td><p id="subscan-split"><strong>subscan.split</strong></p>
</td>
<td><div class="line-block">
<div class="line">[subscan]</div>
<div class="line">split={True, False}</div>
</div>
</td>
<td><p>Allow subscans (integrations) to be split into separate scans.  This is
practical to speed up the reduction of single scans with may subscans on
machines with multi-core CPUs, since the reduction does not generally
process integrations in parallel, but nearly always does for scans.  See
<a class="reference internal" href="#subscan-merge">subscan.merge</a>.</p></td>
</tr>
<tr class="row-even"><td><div class="line-block" id="supergalactic">
<div class="line"><strong>supergalactic</strong></div>
<div class="line">Sets: system=supergalactic</div>
</div>
</td>
<td><p>supergalactic={True, False}</p></td>
<td><p>Make maps in supergalactic coordinates.  See <a class="reference internal" href="#system">system</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="system"><strong>system</strong></p>
</td>
<td><p>system=&lt;type&gt;</p></td>
<td><p>Select the coordinate system for mapping.  Available &lt;type&gt; values are:</p>
<ul class="simple">
<li><p><em>equatorial</em> (default)</p></li>
<li><p><em>horizontal</em></p></li>
<li><p><em>ecliptic</em></p></li>
<li><p><em>galactic</em></p></li>
<li><p><em>supergalactic</em></p></li>
<li><p><em>focalplane</em></p></li>
<li><p><em>native</em></p></li>
</ul>
<p>Most of these values are aliased to simply keys.  See <a class="reference internal" href="#altaz">altaz</a>,
<a class="reference internal" href="#equatorial">equatorial</a>, <a class="reference internal" href="#ecliptic">ecliptic</a>, <a class="reference internal" href="#galactic">galactic</a>, <a class="reference internal" href="#supergalactic">supergalactic</a>, <a class="reference internal" href="#radec">radec</a>, <a class="reference internal" href="#horizontal">horizontal</a>,
and <a class="reference internal" href="#focalplane">focalplane</a>.</p>
</td>
</tr>
<tr class="row-even"><td><p id="tau"><strong>tau</strong></p>
</td>
<td><div class="line-block">
<div class="line">[tau]</div>
<div class="line">value={&lt;X&gt;, &lt;spec&gt;}</div>
</div>
</td>
<td><p>Specify an in-band zenith opacity value to use (&lt;X&gt;).  For some
instruments, the &lt;spec&gt; may be used to specify a filename with lookup
information, or tau in another band (see <a class="reference internal" href="#id3">tau.&lt;?&gt;</a>) with an appropriate
scaling relation to in-band values (see <a class="reference internal" href="#tau-a">tau.&lt;?&gt;.a</a> and <a class="reference internal" href="#tau-b">tau.&lt;?&gt;.b</a>).</p>
<p>When lookup tables are used, the tau values will be interpolated for each
scan, so long as the scan falls inside the interpolator’s range.
Otherwise, a tau of 0.0 will be used.  For SOFIA instruments, &lt;spec&gt;
may also take the values {atran, pwvmodel}.  Please see
<a class="reference internal" href="#atran-reference">atran.reference</a>, <a class="reference internal" href="#tau-pwvmodel">tau.pwvmodel</a>, and <a class="reference internal" href="#id3">tau.&lt;?&gt;</a> for further details.</p>
</td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="tau-pwvmodel">
<div class="line"><strong>tau.pwvmodel</strong></div>
<div class="line">Telescope: SOFIA</div>
</div>
</td>
<td><div class="line-block">
<div class="line">[tau]</div>
<div class="line">pwvmodel={True, False}</div>
</div>
</td>
<td><p>Estimate a typical PWV value (for opacity correction) based on altitude
alone.  See <a class="reference internal" href="#pwv41k">pwv41k</a> and <a class="reference internal" href="#pwvscale">pwvscale</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="id3"><strong>tau.&lt;?&gt;</strong></p>
</td>
<td><div class="line-block">
<div class="line">[tau]</div>
<div class="line">[[&lt;?&gt;]]</div>
<div class="line">value=&lt;X&gt;</div>
</div>
</td>
<td><p>Specify the tau value for X for &lt;?&gt; where &lt;?&gt; can stand for any
user-specified relation.  Some useful conversion relations are predefined
for certain instruments.  E.g. some typical values may be ‘pwv’
(millimeters of precipitable water vapor).  The values will be scaled to
in-band zenith opacities using the linear scaling relations defined via
the <a class="reference internal" href="#tau-a">tau.&lt;?&gt;.a</a> and <a class="reference internal" href="#tau-b">tau.&lt;?&gt;.b</a> constants.</p></td>
</tr>
<tr class="row-odd"><td><p id="tau-a"><strong>tau.&lt;?&gt;.a</strong></p>
</td>
<td><div class="line-block">
<div class="line">[tau]</div>
<div class="line">[[&lt;?&gt;]]</div>
<div class="line">a=&lt;X&gt;</div>
</div>
</td>
<td><p>Define the scaling term for the opacity measure &lt;?&gt;.  Zenith opacities
are expressed in a linear relationship to some user-defined tau parameter
t as:</p>
<blockquote>
<div><p>tau(&lt;?&gt;) = (a * t) + b</p>
</div></blockquote>
<p>This key sets the linear scaling constant ‘a’ in the above equation,
while <a class="reference internal" href="#tau-b">tau.&lt;?&gt;.b</a> specifies the offset value.</p>
</td>
</tr>
<tr class="row-even"><td><p id="tau-b"><strong>tau.&lt;?&gt;.b</strong></p>
</td>
<td><div class="line-block">
<div class="line">[tau]</div>
<div class="line">[[&lt;?&gt;]]</div>
<div class="line">b=&lt;X&gt;</div>
</div>
</td>
<td><p>Set the offset value in a linear tau scaling relationship.  See
<a class="reference internal" href="#tau-a">tau.&lt;?&gt;.a</a> for details.</p></td>
</tr>
<tr class="row-odd"><td><p id="uniform"><strong>uniform</strong></p>
</td>
<td><p>uniform={True, False}</p></td>
<td><p>Instruct the use of uniform pixel gains initially instead of the values
read from the appropriate pixel data file.  See <a class="reference internal" href="#pixeldata">pixeldata</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="unit"><strong>unit</strong></p>
</td>
<td><p>unit=&lt;name&gt;</p></td>
<td><p>Set the output units to &lt;name&gt;.  You can use either the instrumental
units (e.g. ‘V/beam’ or ‘count/beam’) or the more typical ‘Jy/beam’
(default).  All names must be parseable by the astropy.units.Unit Python
class.  See <a class="reference internal" href="#dataunit">dataunit</a> and <a class="reference internal" href="#jansky">jansky</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="unlock"><strong>unlock</strong></p>
</td>
<td><p>unlock=&lt;key1&gt;,&lt;key2&gt;,…</p></td>
<td><p>Release the lock on a configuration option, allowing it to be changed.
See <a class="reference internal" href="#lock">lock</a> for further details.</p></td>
</tr>
<tr class="row-even"><td><p id="vclip"><strong>vclip</strong></p>
</td>
<td><div class="line-block">
<div class="line">[vclip]</div>
<div class="line">value={auto, &lt;min&gt;:&lt;max&gt;}</div>
</div>
</td>
<td><p>Clip data where the field scan velocity is outside the specified range
(&lt;min&gt;:&lt;max&gt; in arcseconds/second).  The successful disentangling of the
source structures from the various noise terms release on these being
separated in the frequency space.  With typical 1/f type limiting noise,
this is harder when the scan speed is low such that the source signals
occupy the low frequencies.  Therefore, requiring a minimum scanning
speed is a good idea.  Likewise, too high scanning speeds will smear out
sources if the movement between samples is larger than ~1/3 beam.  A
value of ‘auto’ can be specified to set the velocity clipping range
optimally based on the typical scanning speeds.  See <a class="reference internal" href="#vclip-strict">vclip.strict</a>,
<a class="reference internal" href="#aclip">aclip</a>, and <a class="reference internal" href="#resolution">resolution</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="vclip-strict"><strong>vclip.strict</strong></p>
</td>
<td><div class="line-block">
<div class="line">[vclip]</div>
<div class="line">strict={True, False}</div>
</div>
</td>
<td><p>When set, discard any frames outside of the acceptable range of mapping
speeds (as defined by the <a class="reference internal" href="#vclip">vclip</a> option), rather than the default
approach of simply flagging slow motion for source modelling only.</p></td>
</tr>
<tr class="row-even"><td><p id="weighting"><strong>weighting</strong></p>
</td>
<td><div class="line-block">
<div class="line">[weighting]</div>
<div class="line">value={True, False}</div>
</div>
</td>
<td><p>Derive pixel weights based on the RMS of the unmodelled timestream
signals.</p></td>
</tr>
<tr class="row-odd"><td><p id="weighting-frames"><strong>weighting.frames</strong></p>
</td>
<td><div class="line-block">
<div class="line">[weighting]</div>
<div class="line">[[frames]]</div>
<div class="line">&lt;options…&gt;</div>
</div>
</td>
<td><p>If configured, calculate time weights in addition to pixel weighting to
allow for non-stationary noise.  See <a class="reference internal" href="#weighting-frames-resolution">weighting.frames.resolution</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="weighting-frames-noiserange"><strong>weighting.frames.noiserange</strong></p>
</td>
<td><div class="line-block">
<div class="line">[weighting]</div>
<div class="line">[[frames]]</div>
<div class="line">noiserange=&lt;min&gt;:&lt;max&gt;</div>
</div>
</td>
<td><p>Set the acceptable range of temporal noise variation.  Standard range
syntax may be used such as wildcards (<code class="xref py py-obj docutils literal notranslate"><span class="pre">*</span></code>) to indicate an open range or
a hyphen (-) instead of a colon (:).  See <a class="reference internal" href="#weighting-noiserange">weighting.noiserange</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="weighting-frames-resolution"><strong>weighting.frames.resolution</strong></p>
</td>
<td><div class="line-block">
<div class="line">[weighting]</div>
<div class="line">[[frames]]</div>
<div class="line">resolution={&lt;X&gt;, auto}</div>
</div>
</td>
<td><p>By default, all exposures are weighted independently.  With this option
set, weights are derived for blocks of exposures spanning X seconds.  The
value ‘auto’ can also be used to match the time-constant to that of
<a class="reference internal" href="#drifts">drifts</a>.  Time weighting is often desired but can cause instabilities
during the reduction, especially if the time-scale is mismatched to other
reduction steps.  Adjust the time scale only if you really understand
what you are doing.</p></td>
</tr>
<tr class="row-even"><td><p id="weighting-method"><strong>weighting.method</strong></p>
</td>
<td><div class="line-block">
<div class="line">[weighting]</div>
<div class="line">method=&lt;name&gt;</div>
</div>
</td>
<td><p>Set the method used for deriving pixel weights from the residuals.  The
following methods (&lt;name&gt;) are available:</p>
<ul class="simple">
<li><p><em>rms</em>: Standard RMS calculation.</p></li>
<li><p><em>robust</em>: Use robust estimates for the standard deviation.</p></li>
<li><p><em>differential</em>: Estimate noise based on pairs of data separated by some
interval.</p></li>
</ul>
</td>
</tr>
<tr class="row-odd"><td><p id="weighting-noiserange"><strong>weighting.noiserange</strong></p>
</td>
<td><div class="line-block">
<div class="line">[weighting]</div>
<div class="line">noiserange=&lt;min&gt;:&lt;max&gt;</div>
</div>
</td>
<td><p>Specify what range of pixel noises are admissible relative to the median
pixel noise.  Pixels that fall outside of the &lt;min&gt; or &lt;max&gt; will be
flagged.  Standard range syntax may be used such as wildcards (<code class="xref py py-obj docutils literal notranslate"><span class="pre">*</span></code>) to
indicate an open range or a hyphen (-) instead of a colon (:).  See
<a class="reference internal" href="#weighting-frames-noiserange">weighting.frames.noiserange</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="weighting-scans"><strong>weighting.scans</strong></p>
</td>
<td><div class="line-block">
<div class="line">[weighting]</div>
<div class="line">[[scans]]</div>
<div class="line">value={True, False}</div>
</div>
</td>
<td><p>If set, each scan gets an assigned weight with which it contributes to
the composite map.  This weight is measured directly from the noise
properties of the produced map.</p></td>
</tr>
<tr class="row-odd"><td><p id="weighting-scans-method"><strong>weighting.scans.method</strong></p>
</td>
<td><div class="line-block">
<div class="line">[weighting]</div>
<div class="line">[[scans]]</div>
<div class="line">method={robust, maximum-likelihood}</div>
</div>
</td>
<td><p>The method by which to calculate the scan weighting.  ‘robust’ method
weights by median(V) / 0.454937, whereas any other method weights by
mean(V) where V is the significance map variance.</p></td>
</tr>
<tr class="row-even"><td><p id="whitelist"><strong>whitelist</strong></p>
</td>
<td><p>whitelist=&lt;key1&gt;, &lt;key2&gt;,…</p></td>
<td><p>Remove any key from the blacklist, allowing it to be set again if
desired.  Whitelisting an option may not set it to its prior value, so
you should explicitly set it again or <a class="reference internal" href="#recall">recall</a> it to it’s prior state.</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="whiten">
<div class="line"><strong>whiten</strong></div>
<div class="line">Alias: <a class="reference internal" href="#filter-whiten">filter.whiten</a></div>
</div>
</td>
<td><div class="line-block">
<div class="line">[whiten]</div>
<div class="line">&lt;options…&gt;</div>
</div>
</td>
<td><p>An alias for <a class="reference internal" href="#filter-whiten">filter.whiten</a>.</p></td>
</tr>
<tr class="row-even"><td><div class="line-block" id="whiten-level">
<div class="line"><strong>whiten.level</strong></div>
<div class="line">Alias: <a class="reference internal" href="#filter-whiten-level">filter.whiten.level</a></div>
</div>
</td>
<td><p>whiten.level=&lt;X&gt;</p></td>
<td><p>An alias for <a class="reference internal" href="#filter-whiten-level">filter.whiten.level</a>.</p></td>
</tr>
<tr class="row-odd"><td><div class="line-block" id="whiten-minchannels">
<div class="line"><strong>whiten.minchannels</strong></div>
<div class="line">Alias: <a class="reference internal" href="#filter-whiten-minchannels">filter.whiten.minchannels</a></div>
</div>
</td>
<td><p>whiten.minchannels=&lt;N&gt;</p></td>
<td><p>An alias for <a class="reference internal" href="#filter-whiten-minchannels">filter.whiten.minchannels</a>.</p></td>
</tr>
<tr class="row-even"><td><div class="line-block" id="whiten-proberange">
<div class="line"><strong>whiten.proberange</strong></div>
<div class="line">Alias: <a class="reference internal" href="#filter-whiten-proberange">filter.whiten.proberange</a></div>
</div>
</td>
<td><p>whiten.proberange=&lt;spec&gt;</p></td>
<td><p>An alias for <a class="reference internal" href="#filter-whiten-proberange">filter.whiten.proberange</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="wiring"><strong>wiring</strong></p>
</td>
<td><p>wiring=&lt;filename&gt;</p></td>
<td><p>This option is commonly used to specify a file containing the wiring
information of the detectors, which can be used to establish the typical
groupings of the instruments.  There is no standard format for the wiring
file (if may vary by instrument), and not all instruments may use such
information.  See <a class="reference internal" href="#pixeldata">pixeldata</a> and <a class="reference internal" href="#rcp">rcp</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="write-ascii"><strong>write.ascii</strong></p>
</td>
<td><div class="line-block">
<div class="line">[write]</div>
<div class="line">ascii={True, False}</div>
</div>
</td>
<td><p>Write the residual timestreams to an ASCII table.  The file will contain
as many columns as there are pixels in the reduction (see <a class="reference internal" href="#noslim">noslim</a>), each
corresponding to a pixel timestream.  The first row contains the sampling
rate (Hz).  Flagged data is indicated with a NaN character.  See <a class="reference internal" href="#noslim">noslim</a>
and <a class="reference internal" href="#write-spectrum">write.spectrum</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="write-coupling"><strong>write.coupling</strong></p>
</td>
<td><div class="line-block">
<div class="line">[write]</div>
<div class="line">[[coupling]]</div>
<div class="line">value=&lt;sig1&gt;, &lt;sig2&gt;,…</div>
</div>
</td>
<td><p>Measure and write coupling gains to the given signals (&lt;sig&gt;).  Coupling
gains are similar to correlation coefficients but normalized differently
so that they can be used directly to remove the correlated signal from
the timestream.  For example:</p>
<blockquote>
<div><p>write.coupling=telescope-x,accel-mag</p>
</div></blockquote>
<p>will write out the coupling gains of each detector to the telescope
azimuth motion (‘telescope-x’) and scalar acceleration (‘accel-mag’).
See <a class="reference internal" href="#correlated-modality">correlated.&lt;modality&gt;</a>.</p>
</td>
</tr>
<tr class="row-even"><td><p id="write-covar"><strong>write.covar</strong></p>
</td>
<td><div class="line-block">
<div class="line">[write]</div>
<div class="line">[[covar]]</div>
<div class="line">&lt;value&gt;=&lt;spec1&gt;, &lt;spec2&gt;,…</div>
</div>
</td>
<td><p>Write covariance data.  If no value is specified, the full pixel-to-pixel
covariance data will be writen to a FITS image.  The optional &lt;value&gt; can
specify the ordering of the covariance matrix according to pixel
divisions.  Each group in the pixel division will be blocked together for
easy identification of block-diagonal covariance structures.  Other than
the division names, the list can contain ‘full’ and ‘reduced’ to indicate
the full covariance matrix of all instrument pixels, or only those that
were used in the reduction.  See <a class="reference internal" href="#division-name">division.&lt;name&gt;</a> and <a class="reference internal" href="#noslim">noslim</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="write-covar-condensed"><strong>write.covar.condensed</strong></p>
</td>
<td><div class="line-block">
<div class="line">[write]</div>
<div class="line">[[covar]]</div>
<div class="line">condensed={True, False}</div>
</div>
</td>
<td><p>When writing covariance matrices, write only ‘live’ channels.  I.e. those
that are unflagged by the reduction.  This results in a covariance matrix
without gaps.  The downside is that identifying particular
pixels/channels may be difficult in that form.  See <a class="reference internal" href="#write-covar">write.covar</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="write-flatfield"><strong>write.flatfield</strong></p>
</td>
<td><div class="line-block">
<div class="line">[write]</div>
<div class="line">[[flatfield]]</div>
<div class="line">value={True, False}</div>
</div>
</td>
<td><p>Write a DRP flatfield FITS file to be used by the chop-nod pipeline.  The
file format is specified by Marc Berthoud.</p></td>
</tr>
<tr class="row-odd"><td><p id="write-flatfield-name"><strong>write.flatfield.name</strong></p>
</td>
<td><div class="line-block">
<div class="line">[write]</div>
<div class="line">[[flatfield]]</div>
<div class="line">name=&lt;filename&gt;</div>
</div>
</td>
<td><p>An optional setting to specify the FITS file name for <a class="reference internal" href="#write-flatfield">write.flatfield</a>.
If not present, a default name containing the scan ID is written to
<a class="reference internal" href="#outpath">outpath</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="write-pixeldata"><strong>write.pixeldata</strong></p>
</td>
<td><div class="line-block">
<div class="line">[write]</div>
<div class="line">pixeldata={True, False}</div>
</div>
</td>
<td><p>Write the pixel data file (gains, weights, flags).  The output will be
pixel-&lt;scanno&gt;.dat’ in <a class="reference internal" href="#outpath">outpath</a>.  You can use these files to update
instrumental defaults in the instrument subdirectory.  E.g., to replace
‘pixel-A.170mK.F445.dat’ in data/configurations/hawc_plus/.  See <a class="reference internal" href="#rcp">rcp</a> and
<a class="reference internal" href="#wiring">wiring</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="write-png"><strong>write.png</strong></p>
</td>
<td><div class="line-block">
<div class="line">[write]</div>
<div class="line">[[png]]</div>
<div class="line">value={True, False}</div>
</div>
</td>
<td><p>Write a PNG thumbnail with the final result.  The PNG image has the same
name as the output file with a ‘.png’ appended.  See <a class="reference internal" href="#write-png-color">write.png.color</a>,
<a class="reference internal" href="#write-png-crop">write.png.crop</a>, <a class="reference internal" href="#write-png-plane">write.png.plane</a>, <a class="reference internal" href="#write-png-size">write.png.size</a>, and
<a class="reference internal" href="#write-png-smooth">write.png.smooth</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="write-png-color"><strong>write.png.color</strong></p>
</td>
<td><div class="line-block">
<div class="line">[write]</div>
<div class="line">[[png]]</div>
<div class="line">color=&lt;name&gt;</div>
</div>
</td>
<td><p>Set the color scheme for rendering the PNG image.  The available color
scheme names are any that may be passed into the ‘cmap’ parameter of the
Python function matplotlib.pyplot.imshow.  If not supplied, the default
will be ‘viridis’.</p></td>
</tr>
<tr class="row-odd"><td><p id="write-png-crop"><strong>write.png.crop</strong></p>
</td>
<td><div class="line-block">
<div class="line">[write]</div>
<div class="line">[[png]]</div>
<div class="line">crop={auto or &lt;xmin&gt;,&lt;ymin&gt;, &lt;xmax&gt;,&lt;ymax&gt;}</div>
</div>
</td>
<td><p>Set rectangular bounds to the PNG output image in the instrument’s native
size unit (usually arcseconds).  The argument is usually a list of
comma-separated corners relative the the source position.  If a single
value is given then the PNG output will be a square area with +/- that
size in X and Y.  If 2 or 3 values are supplied, the missing offsets will
be assumed to be the negative equivalent to the coordinates given.  Thus:</p>
<ul class="simple">
<li><p>90 = -90, -90, 90, 90</p></li>
<li><p>60, 90 = -60, -90, 60, 90</p></li>
<li><p>-45, -50, 60 = -45, -50, 60, 50</p></li>
</ul>
<p>If ‘auto’ is used, the map will automatically be cropped to the best
dimensions for all valid pixels in the map.  See <a class="reference internal" href="#write-png">write.png</a>.</p>
</td>
</tr>
<tr class="row-even"><td><p id="write-png-plane"><strong>write.png.plane</strong></p>
</td>
<td><div class="line-block">
<div class="line">[write]</div>
<div class="line">[[png]]</div>
<div class="line">plane={flux, noise, weight, time, s2n}</div>
</div>
</td>
<td><p>Selects the FITS image plane to write into the PNG.  Unrecognized planes
will be interpreted as ‘flux’ (default).  See <a class="reference internal" href="#write-png">write.png</a>.</p></td>
</tr>
<tr class="row-odd"><td><p id="write-png-size"><strong>write.png.size</strong></p>
</td>
<td><div class="line-block">
<div class="line">[write]</div>
<div class="line">[[png]]</div>
<div class="line">size={&lt;x&gt;X&lt;y&gt; or &lt;x&gt;,&lt;y&gt; or &lt;X&gt;}</div>
</div>
</td>
<td><p>Set the size of the PNG thumbnails.  You can specify both a single
integer for square images or two integers separated by ‘x’, ‘,’ or ‘X’.
E.g., 640x480.  The default size is 300x300.  See <a class="reference internal" href="#write-png">write.png</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="write-png-smooth"><strong>write.png.smooth</strong></p>
</td>
<td><div class="line-block">
<div class="line">[write]</div>
<div class="line">[[png]]</div>
<div class="line">smooth=&lt;spec&gt;</div>
</div>
</td>
<td><p>Specify how much to smooth the PNG output.  The options works in the same
manner to the regular <a class="reference internal" href="#smooth">smooth</a> option for FITS images, but is not
completely independent from it.  PNG images are always smoothed as much
as required by <a class="reference internal" href="#smooth">smooth</a>, and this option is only effective if the PNG
smoothing is larger.</p></td>
</tr>
<tr class="row-odd"><td><p id="write-signals"><strong>write.signals</strong></p>
</td>
<td><div class="line-block">
<div class="line">[write]</div>
<div class="line">signals={True, False}</div>
</div>
</td>
<td><p>Write out all the correlated signals that were calculated in the
reduction as ASCII timestreams.  Each signal mode is written in its own
file, named after the mode’s name and carrying a ‘.tms’ extension.  The
files are simple ASCII timestreams with the sampling frequency appearing
in the first row.</p></td>
</tr>
<tr class="row-even"><td><p id="write-scandata"><strong>write.scandata</strong></p>
</td>
<td><div class="line-block">
<div class="line">[write]</div>
<div class="line">[[scandata]]</div>
<div class="line">value={True, False}</div>
</div>
</td>
<td><p>Whether or not to add HDUs at the end of the output FITS image
describing each scan (default).  Each scan will contribute an extra HDU
at the end of the image.  Disabling this option (e.g. via <a class="reference internal" href="#forget">forget</a>) can
decrease the size of the output images, especially for large data sets
containing many scans.</p></td>
</tr>
<tr class="row-odd"><td><p id="write-scandata-details"><strong>write.scandata.details</strong></p>
</td>
<td><div class="line-block">
<div class="line">[write]</div>
<div class="line">[[scandata]]</div>
<div class="line">details={True, False}</div>
</div>
</td>
<td><p>when enabled, <a class="reference internal" href="#write-scandata">write.scandata</a> will add extra detail into the FITS
outputs such as channel gains, weights, flags, spectral filtering,
profiles, and residual noise power spectra.  See <a class="reference internal" href="#write-scandata">write.scandata</a>.</p></td>
</tr>
<tr class="row-even"><td><p id="write-spectrum"><strong>write.spectrum</strong></p>
</td>
<td><div class="line-block">
<div class="line">[write]</div>
<div class="line">[[spectrum]]</div>
<div class="line">value=&lt;window&gt;</div>
</div>
</td>
<td><p>Writes channel spectra (of residuals) into an ASCII table.  The optional
argument &lt;window&gt; can specify a window function to use.  This is passed
into the Python function scipy.signal.welch in the ‘window’ parameter.
Please see scipy.signal.get_window for a list of available window types.
The default is ‘hamming’.</p>
<p>The first column in the output file indicated the frequency, after which
come the power-spectral-densities (PSF) of each channel used in the
reduction.  See <a class="reference internal" href="#noslim">noslim</a> and <a class="reference internal" href="#write-ascii">write.ascii</a>.</p>
</td>
</tr>
<tr class="row-odd"><td><p id="write-spectrum-size"><strong>write.spectrum.size</strong></p>
</td>
<td><div class="line-block">
<div class="line">[write]</div>
<div class="line">[[spectrum]]</div>
<div class="line">size=&lt;N&gt;</div>
</div>
</td>
<td><p>Specify the window size (in powers of 2) to use for measuring spectra.
By default, the spectral range is set by the 1/f filtering timescale
(<a class="reference internal" href="#drifts">drifts</a>).</p></td>
</tr>
</tbody>
</table>
</section>
<section id="appendix-sample-configuration-files">
<span id="config-appendix"></span><h2>Appendix: Sample Configuration Files<a class="headerlink" href="#appendix-sample-configuration-files" title="Link to this heading">¶</a></h2>
<section id="full-drp-configuration-file">
<h3>Full DRP Configuration File<a class="headerlink" href="#full-drp-configuration-file" title="Link to this heading">¶</a></h3>
<p>Below is a copy of the full configuration file used by the pipeline in
the DPS environment (<em>pipeconf.cfg</em>). It is in INI format, and is readable
by the configobj Python module.</p>
<pre class="literal-block"># HAWC Pipeline Base Configuration File
#
# This file contains all settings for reducing HAWC science and
# in-flight diagnostic data. It is intended to be used with
# additional delta configuration files.
#
# DO NOT edit this file without consulting with the HAWC data
# reduction team.

#### Basic Settings ####
#=======================

# Data Section: information on data objects and file names
[data]
    # Regexp for part of the filename before the file step identifier
    filenamebegin = '\A((\d.+)|(F[\dX]{3,4}_HA_[A-Za-z]+_[A-Za-z0-9]+_[A-Za-z0-9]+))_'
    filenameend = '_((\d+-)?\d+)(?:_BIN\d+)?\.fits(\.gz)?\Z' # HAWC+
    filenum = '(?:\A.*(?:(?:F\d{3,4})|(?:XXXX))_((?:\d+-)?\d+)_.*\.fits(?:\.gz)?\Z)|(?:\AF[\dX]{3,4}_HA.*_((?:\d+-)?\d+)(?:_BIN\d+)?\.fits(?:\.gz)?\Z)'
    dataobjects = DataFits, DataText #, DataCsv


#### PIPE MODES ####
#===================
# configuration for individual pipeline modes. Each needs:
# - datakeys: List of keyword=values required in file header to select this pipeline mode
#             Format is: Keyword=Value|Keyword=Value|Keyword=Value
# - stepslist: List of pipesteps to run the data through


# Lab polarimetry data -- match this first, since it depends
# on a specific CMTFILE only
[mode_labpol]
    datakeys = 'CMTFILE=Hawc_Take data at HWP positions.txt'
    # list of steps
    stepslist = StepCheckhead, StepPrepare, StepDemodulate, StepDmdPlot, StepDmdCut, StepFlat, StepShift, StepSplit, StepCombine, StepNodPolSub, StepStokes, StepWcs, StepPolVec, StepRegion, StepLabPolPlots
    # change stepprepare to labmode
    [[checkhead]]
        abort = False
    [[prepare]]
        labmode = True
        colrename = 'crioTTLChopOut-&gt;Chop Offset|AZ_Error-&gt;Azimuth Error|EL_Error-&gt;Elevation Error|AZ-&gt;Azimuth|EL-&gt;Elevation|SIBS_VPA-&gt;Array VPA'
        chpoffsofiaRS = False
    [[demodulate]]
        track_tol = -1
    [[dmdcut]]
        mask_bits = 64
    [[flat]]
        labmode = True
    [[wcs]]
        labmode = True
        save = True
    [[region]]
        save = True
    [[header]]
        NODPATT = &quot;'A' / Nod Pattern&quot;
        CHPFREQ = 2.988 / Chop Frequency

# lab noise data
[mode_noisedata]
    datakeys = 'CALMODE=NOISE'
    # list of steps
    stepslist = StepCheckhead, StepPrepare, StepNoiseFFT, StepNoisePlots
    # change stepprepare to labmode
    [[checkhead]]
        abort = False
    [[prepare]]
        labmode = True
        colrename = 'crioTTLChopOut-&gt;Chop Offset|AZ_Error-&gt;Azimuth Error|EL_Error-&gt;Elevation Error|AZ-&gt;Azimuth|EL-&gt;Elevation|SIBS_VPA-&gt;Array VPA'
        chpoffsofiaRS = False
    [[header]]
        NODPATT = &quot;'A' / Nod Pattern&quot;
        CHPFREQ = 2.988 / Chop Frequency
        NHWP     = &quot;1 / Number of HWP angles&quot;

# Other lab data
[mode_labdata]
    datakeys = 'INSTMODE=C2N (NMC)|CHPSRC=internal|CALMODE=UNKNOWN'
    # list of steps
    stepslist = StepCheckhead, StepPrepare, StepDemodulate, StepDmdPlot, StepDmdCut, StepLabChop, StepFlat, StepShift, StepSplit, StepCombine, StepNodPolSub, StepStokes, StepWcs, StepMerge
    # change stepprepare to labmode
    [[checkhead]]
        abort = False
    [[prepare]]
        labmode = True
        colrename = 'crioTTLChopOut-&gt;Chop Offset|AZ_Error-&gt;Azimuth Error|EL_Error-&gt;Elevation Error|AZ-&gt;Azimuth|EL-&gt;Elevation|SIBS_VPA-&gt;Array VPA'
        chpoffsofiaRS = False
    [[demodulate]]
        track_tol = -1
    [[dmdcut]]
        mask_bits = 64
    [[flat]]
        labmode = True
    [[labchop]]
        save = True
    [[wcs]]
        labmode = True
        save = True
    [[header]]
        NODPATT = &quot;'A' / Nod Pattern&quot;
        CHPFREQ = 2.988 / Chop Frequency
        NHWP     = &quot;1 / Number of HWP angles&quot;

# PolMap step, for generating png file only
[mode_polmap]
    datakeys = 'PRODTYPE = polmap'
    stepslist = StepPolMap,
    [[polmap]]
        save = False

# Mode for Internal Calibrator File to generate flats
[mode_intcal]
    datakeys ='CALMODE=INT_CAL'
    # list of steps
    stepslist = StepCheckhead, StepFluxjump, StepPrepare, StepDemodulate, StepDmdPlot, StepDmdCut, StepMkflat
    # Always attempt to continue reduction
    [[checkhead]]
        abort = False
    # Stepprepare change to labmode and get Chop Offset from crioAnalogChopOut
    [[prepare]]
        labmode=True
        colrename = 'crioAnalogChopOut -&gt; Chop Offset|AZ_Error-&gt;Azimuth Error|EL_Error-&gt;Elevation Error|AZ-&gt;Azimuth|EL-&gt;Elevation|SIBS_VPA-&gt;Array VPA'
        chpoffsofiars = False
    # Change demodulation options
    [[demodulate]]
        l0method = 'RE'
        phasefile = 0.0
        checkhwp = False
        track_tol = -1
    [[dmdcut]]
        mask_bits = 64
    # Change header value NODPATT = A
    [[header]]
        NODPATT  = &quot;'A' / Nod Pattern&quot;

# SKYDIP data
[mode_skydip]
    datakeys = 'INSTCFG=TOTAL_INTENSITY|CALMODE=SKY_DIP'
    # list of steps
    stepslist = StepCheckhead, StepScanMap, StepFluxjump, StepPrepare, StepDemodulate, StepDmdPlot, StepDmdCut, StepSkydip
    # Always attempt to continue reduction
    [[checkhead]]
        abort = False
    # ScanMap - no output
    [[scanmap]]
        noout = True
        save = False
    # Stepprepare change to labmode and get Chop Offset from crioAnalogChopOut
    [[prepare]]
        labmode=True
        colrename = 'crioAnalogChopOut -&gt; Chop Offset|AZ_Error-&gt;Azimuth Error|EL_Error-&gt;Elevation Error|AZ-&gt;Azimuth|EL-&gt;Elevation|SIBS_VPA-&gt;Array VPA'
            chpoffsofiaRS = False
    # Change demodulation options
    [[demodulate]]
        l0method = 'ABS'
        track_tol = -1
        track_extra = 0,0
    [[dmdcut]]
        mask_bits = 64
    [[header]]
        NODPATT  = &quot;'A' / Nod Pattern&quot;

# POLDIP data
[mode_poldip]
    datakeys = 'INSTCFG=POLARIZATION|CALMODE=SKY_DIP'
    stepslist = StepCheckhead, StepFluxjump, StepPrepare, StepPolDip
    # Always attempt to continue reduction
    [[checkhead]]
        abort = False
    [[prepare]]
        traceshift = 4

# AUTOFOCUS: Mode for Automatic Focusing for Scan data
[mode_autofocus]
    datakeys = 'INSTMODE=OTFMAP|INSTCFG=TOTAL_INTENSITY|CALMODE=FOCUS'
    # list of steps
    stepslist = StepCheckhead, StepScanMapFocus, StepStdPhotCal, StepFocus, StepImgMap
    [[scanmap]]
        use_frames = ''

# ChopNod Mode Configuration
[mode_nod_std_dmd]
    datakeys = 'INSTMODE=C2N (NMC)|INSTCFG=TOTAL_INTENSITY|OBSTYPE=STANDARD_FLUX|PRODTYPE=demodulate'
    stepslist = StepDmdPlot, StepDmdCut, StepFlat, StepShift, StepSplit, StepCombine, StepNodPolSub, StepStokes, StepWcs, StepOpacity, StepBgSubtract, StepMerge, StepStdPhotCal, StepImgMap
[mode_nod_std]
    datakeys = 'INSTMODE = C2N (NMC)|INSTCFG = TOTAL_INTENSITY|OBSTYPE=STANDARD_FLUX'
    # list of steps
    stepslist = StepCheckhead, StepFluxjump, StepPrepare, StepDemodulate, StepDmdPlot, StepDmdCut, StepFlat, StepShift, StepSplit, StepCombine, StepNodPolSub, StepStokes, StepWcs, StepOpacity, StepBgSubtract, StepMerge, StepStdPhotCal, StepImgMap
    [[demodulate]]
        checkhwp = False
[mode_nod_dmd]
    datakeys = 'INSTMODE = C2N (NMC)|INSTCFG = TOTAL_INTENSITY|PRODTYPE = demodulate'
    stepslist = StepDmdPlot, StepDmdCut, StepFlat, StepShift, StepSplit, StepCombine, StepNodPolSub, StepStokes, StepWcs, StepOpacity, StepBgSubtract, StepMerge, StepCalibrate, StepImgMap
[mode_nod]
    datakeys = 'INSTMODE = C2N (NMC)|INSTCFG = TOTAL_INTENSITY'
    # list of steps
    stepslist = StepCheckhead, StepFluxjump, StepPrepare, StepDemodulate, StepDmdPlot, StepDmdCut, StepFlat, StepShift, StepSplit, StepCombine, StepNodPolSub, StepStokes, StepWcs, StepOpacity, StepBgSubtract, StepMerge, StepCalibrate, StepImgMap
    [[demodulate]]
        checkhwp = False

# Nod-Pol Mode Configuration
[mode_nodpol_dmd_std]
    datakeys = 'INSTMODE=C2N (NMC)|INSTCFG=POLARIZATION|OBSTYPE=STANDARD_FLUX|PRODTYPE=demodulate'
    stepslist = StepDmdPlot, StepDmdCut, StepFlat, StepShift, StepSplit, StepCombine, StepNodPolSub, StepStokes, StepWcs, StepIP, StepRotate, StepOpacity, StepBgSubtract, StepMerge, StepStdPhotCal, StepPolVec, StepRegion, StepPolMap
[mode_nodpol_std]
    datakeys = 'INSTMODE=C2N (NMC)|INSTCFG=POLARIZATION|OBSTYPE=STANDARD_FLUX'
    # list of steps
    stepslist = StepCheckhead, StepFluxjump, StepPrepare, StepDemodulate, StepDmdPlot, StepDmdCut, StepFlat, StepShift, StepSplit, StepCombine, StepNodPolSub, StepStokes, StepWcs, StepIP, StepRotate, StepOpacity, StepBgSubtract, StepMerge, StepStdPhotCal, StepPolVec, StepRegion, StepPolMap
[mode_nodpol_dmd]
    datakeys = 'INSTMODE = C2N (NMC)|INSTCFG = POLARIZATION|PRODTYPE = demodulate'
    stepslist = StepDmdPlot, StepDmdCut, StepFlat, StepShift, StepSplit, StepCombine, StepNodPolSub, StepStokes, StepWcs, StepIP, StepRotate, StepOpacity, StepCalibrate, StepBgSubtract, StepMerge, StepPolVec, StepRegion, StepPolMap
[mode_nodpol]
    datakeys = 'INSTMODE = C2N (NMC)|INSTCFG = POLARIZATION'
    # list of steps
    stepslist = StepCheckhead, StepFluxjump, StepPrepare, StepDemodulate, StepDmdPlot, StepDmdCut, StepFlat, StepShift, StepSplit, StepCombine, StepNodPolSub, StepStokes, StepWcs, StepIP, StepRotate, StepOpacity, StepCalibrate, StepBgSubtract, StepMerge, StepPolVec, StepRegion, StepPolMap

# Flux standards configuration
[mode_scan_std]
    datakeys = 'INSTMODE=OTFMAP|INSTCFG=TOTAL_INTENSITY|OBSTYPE=STANDARD_FLUX'
    stepslist = StepCheckhead, StepScanMap, StepStdPhotCal, StepImgMap

[mode_scanpol_std]
    datakeys = 'INSTMODE=OTFMAP|INSTCFG=POLARIZATION|OBSTYPE=STANDARD_FLUX'
    stepslist = StepCheckhead, StepScanMapPol, StepScanStokes, StepIP, StepRotate, StepStdPhotCal, StepMerge, StepPolVec, StepRegion, StepPolMap, StepImgMap
    [[ip]]
        fileip = uniform
    # beam size pixels for scanpol
    #[[merge]]
    #    cdelt = 4.84, 7.80, 7.80, 13.6, 18.2  # Pixel size in arcseconds of output map. cdelt = beamsize
    #    fwhm = 4.84, 7.80, 7.80, 13.6, 18.2 # smoothing FWHM: beam size
    #    radius = 14.52, 23.4, 23.4, 40.8, 54.6 # fit window: beam size * 3

# Imaging Scan Mode Configuration
[mode_scan]
    datakeys = 'INSTMODE=OTFMAP|INSTCFG=TOTAL_INTENSITY'
    stepslist = StepCheckhead, StepScanMap, StepZeroLevel, StepCalibrate, StepImgMap

# Scanning Polarimetry Mode Configuration
[mode_scanpol]
    datakeys = 'INSTMODE=OTFMAP|INSTCFG=POLARIZATION'
    stepslist = StepCheckhead, StepScanMapPol, StepScanStokes, StepIP, StepRotate, StepCalibrate, StepMerge, StepPolVec, StepRegion, StepPolMap
    [[ip]]
        fileip = uniform
    # beam size pixels for scanpol
    #[[merge]]
    #    cdelt = 4.84, 7.80, 7.80, 13.6, 18.2  # Pixel size in arcseconds of output map. cdelt = beamsize
    #    fwhm = 4.84, 7.80, 7.80, 13.6, 18.2 # smoothing FWHM: beam size
    #    radius = 14.52, 23.4, 23.4, 40.8, 54.6 # fit window: beam size * 3

# Skyflat mode configuration: this mode does not uniquely match any
# input data.  It needs to be selected manually.
[mode_skycal]
    datakeys = 'INSTMODE=OTFMAP|INSTCFG=TOTAL_INTENSITY'
    # list of steps
    stepslist = StepCheckhead, StepScanMapFlat, StepSkycal


#### PIPE STEPS ####
#====================
#   All HAWC steps in alphabetical order.

# BINPIXELS
[binpixels]
    block_size = 1  # binning size: 2, 4, or 8.  Set &lt;= 1 to turn off.

# BGSUBTRACT - background subtraction step
[bgsubtract]
    cdelt = 2.57, 4.02, 4.02, 6.93, 9.43 # output pixel size: detector pixscale
    proj = TAN # Projection of output map
    sizelimit = 3000 # Upper limit on map size (either axis, in pixels)
    fwhm = 4.84, 7.80, 7.80, 13.6, 18.2 # smoothing FWHM: beam size
    radius = 9.68, 15.6, 15.6, 27.2, 36.4 # fit window: beam size * 2
    errflag = True   # Use uncertainties when computing averages?
    widowstokesi = True   # Use widow pixels (flagged 1 or 2) when smoothing
    edge_threshold = 0.5   # Set edge pixels to NaN
    fit_order = 0 # Fit order for local regression
    bgoffset = 10 # Number of iterations of background subtract with offset (intercept) term
    chauvenet = True   # Use Chauvenet's criterion in background subtraction?
    fitflag = False   # Use errors in intensity when fitting?
    qubgsubtract = True # Apply background offsets to individual Stokes QU files?

# CALIBRATE - fluxes from data units to Jy/pixel
[calibrate]

# COMBINE - R-T and R+T data
[combine]
    sigma = 3.0   # Reject outliers more than this many sigma from the mean
    sum_sigma = 4.0  # Reject additional R+T outliers more than sum_sigma from the mean
    use_error = False # Set to True to use Chauvenet output errors rather than propagating input variances

# Check the primary FITS header for required keywords
[checkhead]
    abort = True
    headerdef = $DPS_HAWCPIPE/data/config/header_req_config.cfg

# DEMODULATE -  Demodulate the chopped data while keeping all samples
[demodulate]
    chop_tol = 0.2   # chopper tolerance in arcseconds
    nod_tol = 5.0   # nod tolerance in arcseconds
    hwp_tol = 2.   # hwp angle tolerance in degrees
    az_tol = 5000000.0   # Azimuth error tolerance in arcseconds
    el_tol = 5000000.0  # Elevation error tolerance in arcseconds
    track_tol = 'centroidexp'    # Track error tolerance in arcseconds (AOIs 3 and 4) - set negative to deactivate
    track_extra = 0, 0  # Extra samples removed (in seconds) before and after samples flagged by track_tol
    chopphase = True   # Flag requiring chop phase correction
    checkhwp = True  # Set FALSE to avoid check expected number of HWP angles
    phasefile = $DPS_HAWCPIPE/data/phasefiles/masterphase_170307.fits
    phaseoffset = 0.0 # Offset to apply to phasefile, in degrees
    l0method = 'RE' # Method to normalize data: REal, IMag and ABSolute
    boxfilter = -1 # Box Highpass Filter. -1 = frequency from the header
    chopavg = True # Flag to save chop averaged raw data (default = False)
    tracksampcut = 0.5 # If fraction of all samples removed due to tracking is larger than this number, than tracking status is BAD
    data_sigma = 5.0 # value for sigma-clipping of detector data in variance calculation

# DMDCUT - Discard chops based from the Demodulate output
[dmdcut]
    mask_bits = 1023   # bits of 'Chop Mask' on which to discard chops
    min_samples = 1  # minimum number of samples for retaining a chop

# DMDPLOT - Plot output of Demodulate
[dmdplot]
    door_threshold = 2.0          # ratio of imaginary to real median stds for door vignetting
    detector_i = 14               # i-location of detector pixel to plot
    detector_j = 24               # j-location of detector pixel to plot
    data_sigma = 5.0              # value for sigma-clipping of detector data
    data_iters = 3                # number of iterations for data clipping
    user_freq = 10.2              # INT_CAL: user frequency in Hz
    ref_phase_file = $DPS_HAWCPIPE/data/phasefiles/refphases_180419.fits
    phase_thresh = 50.0           # threshold in phase uncertainty (deg) for blanking pixels
    save_phase = False            # Save phase images to PHS suffix
    savefolder = ''               # Folder to save plots to. '' means same as input file

# FLAT - step configuration
[flat]
    # filename glob to find the flat files
    flatfile = flats/*OFT*.fits
    # list of keys that need to match flat and data file (only if flatfile=search)
    flatfitkeys = 'SPECTEL1', 'MISSN-ID', 'FILEGPID', 'SCRIPTID'
    # Back up filename for auxiliary file(s). Can contain * and ? wildcards to match
    # multiple files to be selected using fitkeys (default = bkupflatfile/*.fits)
    bkupflat = $DPS_HAWCPIPE/data/flats/*OFT.fits  # Backup flat files

# FLUXJUMP - Flux Jump step configuration
[fluxjump]
    # Filepathname specifying the jump gap map, alternatively a number for the
    #   gap to be used for all pixels (default = '4600')
    # Default is a no-op map
    jumpmap = $DPS_HAWCPIPE/data/fluxjumps/flux_jump_dummy.fits

# FOCUS - step configuration
[focus]
    widowisgood = True       # Include widow pixels in the analysis (T) or only good pixels (F, will assume widow pixels are bad)
    medianaverage = True     # Run a median average box through the array to fill bad pixels (T) or not (F)
    boxaverage = 5           # Size of the median average box (if medianaverage is True) in pixels
    autocrop = True          # Crop image automatically around the target (w/ boxsize = 1/3 of image size)
    cropimage = True         # Crop portion (box) of the image for analysis? True or False
    xyboxcent = 87,87       # If cropimage = True, central X/Y pixel position of the box to be cropped
    boxsizecrop = 30         # If cropimage = True, size of the box to be cropped (in pixels)
    primaryimg = ''          # Specifies which image will be used for the Gaussian fit. If left blank, the first image will be used.

# IMGMAP - Image map step
[imgmap]
   maphdu = 'STOKES I'         # HDU name to be used in the mapfile. The HDU used for the background image.
   lowhighscale = 0.25, 99.75  # Low/High percentile for image scaling
   colormap = 'plasma'
   ncontours = 0               # Number of contours
   fillcontours = True
   colorcontour = 'gray'
   grid = False
   title = 'info'              # Title in the polarization map
   centercrop = False          # Crop a region of the image. Default = False. Inputs: RA, DEC, width, height in degrees.
   watermark = ''       # Text to add to the plot as a watermark

# IP Correction for instrumental polarization step configuration
[ip]
    # IP from planets estimated using FS13.
    #qinst =  -0.0154, 0.0, -0.0151, 0.0028, -0.0129   # Fractional instrumental polarization in q
    #uinst =  -0.0030, 0.0,  0.0090,  0.0191, -0.0111  # Fractional instrumental polarization in u
    # Median q/u from below file
    qinst =  -0.0157, 0.0, -0.0164, 0.0009, -0.0104
    uinst =  -0.0038, 0.0,  0.0081, 0.0192, -0.0142
    # IP file from FS15 poldip
    fileip = $DPS_HAWCPIPE/data/ip/hawc_ip_FS15_poldip_v1.fits

# MERGE - step configuration
[merge]
    beamsize = 4.84, 7.80, 7.80, 13.6, 18.2 # Beam FWHM size (arcsec) to write into BMAJ/BMIN header keywords
    cdelt  =  1.21, 1.95, 1.95, 3.40, 4.55  # Pixel size in arcseconds of output map. cdelt = beamsize/4
    proj = TAN   # Projection of output map
    sizelimit = 3000 # Upper limit on map size (either axis, in pixels)
    widowstokesi = True   # Use widow pixels to compute Stokes I map
    conserveflux = True    # Apply flux conservation factor due to change in pixel size to all output images
    fit_order = 2  # Fit order for local regression
    fwhm = 4.84, 7.80, 7.80, 13.6, 18.2 # smoothing FWHM: beam size / 2
    radius = 9.68, 15.6, 15.6, 27.2, 36.4 # fit window: beam size * 2
    errflag = True   # Use uncertainties when computing averages
    edge_threshold = 0.5   # Set edge pixels to NaN
    adaptive_algorithm = scaled  # Adaptive smoothing kernel type (scaled, shaped, None)
    fit_threshold = 0.0  # Deviation from weighted mean to allow for higher order fit
    bin_cdelt = True # if input pixels have been binned, multiply the cdelt and radius by the binning factor

# MKFLAT - Make flat file from INT_CAL files
[mkflat]
    # Path for the folder to write flat files to (default: .)
    flatoutfolder = flats
    # Header Keyword to match input files to the same observation (default: FILEGPID)
    groupkey = &quot;SCRIPTID&quot;
    # Chops to exclude from the beginning of the file (default: 1)
    skip_start = 1
    # Chops to exclude from the end of the file (default: 1)
    skip_end = 1
    # Raw data threshold for dead pixels (default: 10.0)
        bad_dead = 10.0
        # Raw data threshold for ramping pixels (default: 2000000.0)
    bad_ramping = 2000000
    # Threshold for HIGH STD of DMD SIGNAL to exclude pixels (default: 10.0)
    normstd = 10.0
    # Threshold to eliminate pixels with LOW SIGNAL (default: [0.5, 0.5, 0.5])
    ynormlowlim = 0.5, 0.5, 0.5
    # Threshold to eliminate pixels with HIGH NORMALIZED SIGNAL
    # (default: [10.0, 10.0, 10.0])
    ynormhighlim = 10.0, 10.0, 10.0
    # Scale factor for T/R flatfield (default: 2.0)
    TtoR = 2.0
    # Filename for auxiliary file(s). Can contain * and ? wildcards to match
    # multiple files to be selected using fitkeys (default = skycal/*.fits)
    # (default: skycal/*SCAL.fits)
    scalfile = $DPS_HAWCPIPE/data/skycals/fs15/*.fits
    # Back up filename for auxiliary file(s). Can contain * and ? wildcards
    # to match multiple files to be selected using fitkeys
    bkupscal = $DPS_HAWCPIPE/data/skycals/fs15/*.fits
    # List of header keys that need to match auxiliary data file
    # - only used if multiple files match skycal (default = [])
    scalfitkeys = SPECTEL1

# NODPOLSUB - Subtract L and R nods with HWP
[nodpolsub]

# NOISE FFT and plots
[noisefft]
   truncate = True

[noiseplots]

# OPACITY - Correction for model atmospheric opacity
[opacity]

# POLDIP - Polarization skydip step
[poldip]
   hwp0 = 5.0 # Reference HWP angle
   temp0 = 0.532 # Reference temperature (ADR setpoint)
   maxrms = 0.1 # Maximum allowed reduced RMS

# POLMAP - Polarization map step
[polmap]
   maphdu = 'STOKES I'        # HDU name to be used in the mapfile. The HDU used for the background image.
   scalevec = 0.0003          # Scale factor for vector sizes
   scale = True               # Set to False to make all vectors the same length
   rotate = True              # True gives (B-Field) vectors
   debias = True              # Use debiased polarizations
   lowhighscale = 0.25,99.75  # Low/High percentile for image scaling
   colorvec = 'black'         # Vector colors
   colormap = 'plasma'
   ncontours = 20             # Number of contours
   fillcontours = True
   colorcontour = 'gray'
   grid = True
   title = 'info'             # Title in the polarization map
   centercrop = False         # Crop a region of the image. Default = False. Inputs: RA, DEC, width, height in degrees.
   watermark = 'Preview'      # Text to add to the plot as a watermark
   save = True

# POLVEC - Polarization vector step configuration
[polvec]
    # telescope polarization efficiency
    eff = 0.842, 0.9, 0.939, 0.975, 0.978

# PREPARE - Prepare file for demodulation
[prepare]
    detcounts = 'SQ1Feedback'# Name of the column containing the detector flux values R/T arrays
    hwpcounts = 'hwpCounts'  # Name of the input fits column containing the HWP counts (only used if column &quot;HWP Angle&quot; is not present)
    hwpconv = 0.25           # Value to convert hwpcounts to HWP Angles (only used if column &quot;HWP Angle&quot; is not present)
    labmode = False          # If TRUE (processing lab data), will fill in with zeros a few columns and keywords that are important for the DRP
    replacenod = True # If TRUE will replace Nod Offset by calculation based on RA/DEC. If False use original column (has problems)
    chpoffsofiars = True     # If TRUE will calculate Chop Offset based on SofiaChopR/S. If False the user should use colrename to specify which column to use
    colrename = 'AZ_Error-&gt;Azimuth Error|EL_Error-&gt;Elevation Error|AZ-&gt;Azimuth|EL-&gt;Elevation|SIBS_VPA-&gt;Array VPA|NOD_OFF-&gt;Nod Offset Orig'
    # List of data columns to delete: The format [&quot;column1&quot;,&quot;column2&quot;,...]
    coldelete = hwpA,hwpB,FluxJumps
        # Number of samples to shift the data (default is 0 i.e. no shift)
    traceshift = 0
    # List for PIXSCAL values for each band - to update PIXSCAL in the header
    pixscalist  = 2.57, 4.02, 4.02, 6.93, 9.43
    # Remove data Dropouts (i.e. data with RA==Dec==0)
    removedropouts = True

# REGION - Extract ds9 region file of polarization vectors
[region]
    skip = 2       # Only plot every ith pixel. If skip =1 it will show every pixel. If cdelt = beamsize/4, skip=2 gives Nyquist sampling.
    scale = True   # Set to False to make all vectors the same length
    rotate = True   # Use rotated (B-Field) vectors
    debias = True   # Use debiased polarizations
    length = 10.0   # Scale factor for length of polarization vectors in pixels.
    mini = 0.0   # Do not plot vectors with flux &lt; this fraction of peak flux
    minp = 0.0   # Require percentage polarizations to be &gt;= this value
    offset = 0, 0   # Offset in pixels in x,y (controls which pixels are extracted)
    sigma = 3.0   # p/sigmap must be &gt;= this value
    minisigi = 200  # StokesI/ErrorI must be above this value
    maxp = 50  # Pol. Degree must be below this value

# ROTATE - Rotate Q and U from detector to sky frame step configuration
[rotate]
    gridangle = -89.69, 0.0, -104.28, 37.42, 119.62  #Angle of the grid in degrees (for each waveband)
    hwpzero_tol = 3.0   # Tolerance in the difference between commanded and actual initial HWP angles
    hwpzero_option = 'commanded'   # Option to use between &quot;commanded&quot; or &quot;actual&quot; in case the difference between the initial HWP angles is &gt; hwpzero_tol

# Run the scanmap image data reduction
[scanmap]
    save = True
    options = ''
    subarray = 'R0,T0,R1'
    use_frames = '800:-800'

# Use scanmap to generate a flat
[scanmapflat]
    save = True
    options = ''
    use_frames = '800:-800'

# ScanMapFOCUS - Run scanmap on focus groups
[scanmapfocus]
    save = True
    groupkeys = 'FOCUS_ST'  # header keywords to decide data group membership (| separated)
    groupkfmt = '%.1f'   # group key formats to force string comparison (| separated)

# Run the scanmap pol data reduction
[scanmappol]
    save = True
    options = ''
    vpa_tol = 5.0
    use_frames = '800:-800'

# SCANSTOKES - Calculate Stokes parameters for scanpol data
[scanstokes]
    hwp_tol = 5.0   # HWP angles for Stokes parameters must differ by no more than 45+-hwp_tol degrees
    zero_level_method = none # Statistic for zero-level calculation (mean, median, none)
    zero_level_radius = 9.68, 15.6, 15.6, 27.2, 36.4 # 2 * Beam FWHM size radius for averaging
    zero_level_sigma = 5.0   # Sigma value for statistics clipping in non-auto mode
    zero_level_region = header # Zero level region method (header, auto, or [RA, Dec, radius] in degrees)

# SHIFT - Account for R/T misalignment and apply integer displacements (shifts)
[shift]
    angle1   = 0.0       # rotation angle of R1 relative to T1, in degrees counterclockwise
    angle2   = 0.0       # rotation angle of R2 relative to T2, in degrees counterclockwise
    mag      = 1.0, 1.0  # Magnification of R relative to T, in the x,y pixel direction
    disp1    = 0.0, 0.0  # Pixel displacement of R1 relative to T1, in the x,y directions
    disp2    = 0.0, 0.0  # Pixel displacement of R2 relative to T2, in the x,y directions
    gapx     = 4.0       # displacement in x pixels between T1 and T2
    gapy     = 0.0       # displacement in y pixels between T1 and T2
    gapangle = 0.0       # Rotation angle in degrees CCW between T1 and T2

[skycal]
    normalize = False
    sigma_lower = 3.0
    sigma_upper = 3.0
    ttor = 1.275
    bins = 'fd'
    scalfitkeys = SPECTEL1
    dclfile = intcals/*DCL*.fits
    dclfitkeys = 'SPECTEL1', 'MISSN-ID', 'DATE-OBS'
    pixfile = pixel*.dat
    ref_pixpath = $DPS_HAWCPIPE/data/pixdata/
    ref_pixfile = pixel-A.170mK.F445.dat,'',pixel-C.170mK.F446.dat,pixel-D.170mK.F445.dat,pixel-E.170mK.F446.dat

# SPLIT - Split data by HWP angle and nod position step configuration
[split]
    # Nod tolerance, as the percent difference allowed in number of chop cycles
    # between 1st and 2nd left, and between left and right
    nod_tol = 50.0

# STDPHOTCAL - Run photometry on standards and calibrate to Jy
[stdphotcal]

# STOKES - Compute Stokes I, Q, U step configuration
[stokes]
    hwp_tol = 5.0   # HWP angles for Stokes parameters must differ by no more than 45+-hwp_tol degrees
    erri = median   # How to inflate errors in I.  Can be median, mean, or none.
    erripolmethod   = meansigma         # Options are &quot;hwpstddev&quot; or &quot;meansigma&quot;
    removeR1stokesi = True      # Remove R1 subarray for Stokes I
    override_hwp_order = False  # If True, the first two HWP angles will be used for Q, last two for U

# WCS - Update Parallactic angle and crval1 and crval2 for a single file
[wcs]
    add180vpa = True   # Add 180 degrees to the SIBS_VPA
    # Small Offset (in pixels along x/y) between SIBS_X/Y and actual target position
    offsibs_x = 0.0, 0.0, 0.0, 0.0, 0.0
    offsibs_y = 0.0, 0.0, 0.0, 0.0, 0.0
    labmode = False # If labmode = True, will ignore keywords and input parameters and create fake astrometry

# ZEROLEVEL - Correct zero level for scanning imaging mode
[zerolevel]
    zero_level_method = none # Statistic for zero-level calculation (mean, median, none)
    zero_level_radius = 9.68, 15.6, 15.6, 27.2, 36.4 # 2 * Beam FWHM size radius for averaging
    zero_level_sigma = 5.0   # Sigma value for statistics clipping in non-auto mode
    zero_level_region = header # Zero level region method (header, auto, or [RA, Dec, radius] in degrees)


#### Data Section ####
#=====================

# Treatment of the FITS header: can include keyword replacement
# The keyword value and comment must be printed as they would in a FITS header
# If the value is another keyword, the value of that keyword will be used
# instead (This only works if the other keywords starts with an alphabetic
# character).
[header]
    #INSTMODE = &quot;'test' / instrument mode&quot;
    #CHPFREQ  = &quot;10.0 / Chop Frequency&quot;
    #SKYANGL  = 0.0 / Sky Angle
    #CHOPPING = T / Chopping flag
    #CHPMODE  = &quot;'2-POINT' / Chopping mode&quot;
    #CHPAMP1  = 30000 / Chop Amplitude
    #CHPANGLE = 0.0 / Chop Angle
    #DETSIZE  = &quot;'(32,41)'&quot;
    #NHWP     = &quot;1 / Number of HWP angles&quot;
    #NODDING  = T / Nodding flag
    #NODANGLE = 92.8 / Nod Angle
    #NODPATT  = &quot;'ABBA' / Nod Pattern&quot;
    #NODTIME  = 5.0 / Nod Integration Time
    #NODSETL  = 0.05 / Nod Settle Time
    #OBSRA    = 5000 / Observation RA (now DOG units)
    #OBSDEC   = 5000 / Observation DEC (now DOG units)
    #SCANNING = T / Scanning flag
    #TAUOBS = 0.0 / Estimated optical depth

# Merge Header Section: How to merge header keywords when headers from
# several files are merged. Options are:
# - FIRST (default), LAST: For all values
# - DEFAULT: For all values (-9999 for ints, UNKNOWN for strings, etc)
# - MIN, MAX, SUM: For numbers
# - AND, OR: For boolean flags
# - CONCATENATE: For strings
[headmerge]
    ALTI_END = LAST
    ASSC_AOR = CONCATENATE
    ASSC_MSN = CONCATENATE
    DTHINDEX = DEFAULT
    LAT_END  = LAST
    LON_END  = LAST
    FBC-STAT = LAST
    FOCUS_EN = LAST
    SIBS_X   = DEFAULT
    SIBS_Y   = DEFAULT
    UTCEND   = LAST
    WVZ_END  = LAST
    ZA_END   = LAST
    TRACERR  = OR
    TSC-STAT = LAST

# Treatment for table values when combining images
# Options are MIN, MED, AVG, FIRST, LAST, SUM
[table]
    samples           = SUM
    chop offset       = WTAVG
    nod offset        = WTAVG
    hwp angle         = WTAVG
    azimuth           = WTAVG
    azimuth error     = WTAVG
    elevation         = WTAVG
    elevation error   = WTAVG
    array vpa         = WTAVG
    nod index         = WTAVG
    hwp index         = WTAVG
    nod offset orig   = FIRST
    framecounter      = FIRST
    crioframenum      = WTAVG
    hwpcounts         = WTAVG
    fasthwpa          = WTAVG
    fasthwpb          = WTAVG
    fasthwpcounts     = WTAVG
    a2a               = WTAVG
    a2b               = WTAVG
    b2a               = WTAVG
    b2b               = WTAVG
    chop1             = WTAVG
    chop2             = WTAVG
    criottlchopout    = FIRST
    sofiachops        = WTAVG
    sofiachopr        = WTAVG
    sofiachopsync     = WTAVG
    ai22              = MED
    ai23              = MED
    crioanalogchopout = FIRST
    irigupdatediff    = FIRST
    timestamp         = WTAVG
    ra                = FIRST
    dec               = FIRST
    chop_vpa          = FIRST
    lon               = FIRST
    lat               = FIRST
    lst               = WTAVG
    los               = WTAVG
    xel               = WTAVG
    tabs_vpa          = FIRST
    pitch             = WTAVG
    roll              = WTAVG
    nonsiderealra     = WTAVG
    nonsiderealdec    = WTAVG
    flag              = WTAVG
    pwv               = FIRST
    nodpositionreached = FIRST
    trackerraoi3      = FIRST
    trackerraoi4      = FIRST
    trackerraoi5      = FIRST
    r array imag      = FIRST
    t array imag      = FIRST
    r array imag var  = FIRST
    t array imag var  = FIRST
    chop offset imag  = FIRST
    r array avg       = FIRST
    t array avg       = FIRST
    phase corr        = WTAVG
    nod_off           = WTAVG
    centroidexpmsec   = WTAVG
    # Centroid Values for FS15
    centroidworkphase = WTAVG
    centroidaoi       = FIRST
    # SofiaHK values (temporary)
    sofhkchopamp      = WTAVG
    sofhkbinning      = WTAVG
    sofhkaoi4col      = WTAVG
    sofhkaoi4row      = WTAVG
    sofhkaoi3col      = WTAVG
    sofhkaoi3row      = WTAVG
    sofhktrkaoi       = WTAVG
    sofhkseqphase     = WTAVG
    sofhkexptime      = WTAVG
    sofhkaoi4err      = WTAVG
    sofhkaoi3err      = WTAVG
    chop mask         = FIRST
</pre>
</section>
<section id="drp-override-configuration-file">
<h3>DRP Override Configuration File<a class="headerlink" href="#drp-override-configuration-file" title="Link to this heading">¶</a></h3>
<p>Below is a sample override configuration file that demonstrates how to set
override parameters to provide to the HAWC pipeline. The parameters
listed here are those most likely to change from one flight series to
another.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># HAWC Pipeline Configuration File - Overrides for OC8E,
# flights F683 to F693
#
# 2020-09-14 S. Shenoy

# Demodulate chops
[demodulate]
    phasefile = $DPS_HAWCPIPE/data/phasefiles/masterphase_170307.fits

# Flux Jump step configuration
[fluxjump]
    jumpmap = $DPS_HAWCPIPE/data/fluxjumps/flux_jump_dummy.fits

# Correction for instrumental polarization
[ip]
    fileip = $DPS_HAWCPIPE/data/ip/hawc_ip_FS15_poldip_v1.fits

# Make flat from int_cal
[mkflat]
    scalfile = $DPS_HAWCPIPE/data/skycals/fs15/*.fits

# WCS - Update Parallactic angle and crval1 and crval2 for a single file
[wcs]
    offsibs_x = -0.578, -0.205, -0.395, -0.347, -0.306
    offsibs_y = -3.028, -2.615, -2.005, -1.637, -1.260
</pre></div>
</div>
</section>
<section id="full-scan-map-configuration-file">
<h3>Full Scan Map Configuration File<a class="headerlink" href="#full-scan-map-configuration-file" title="Link to this heading">¶</a></h3>
<p>Below is a copy of the default global configuration file for the scan
map algorithm. Other configuration files specifying values for specific
instruments or modes may override values in this file.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>forget = name, source.despike, noiseclip, source.filter

projection = SFL
system = equatorial

# The ordering of models in the default reduction pipeline.
ordering = offsets, drifts, correlated.obs-channels, weighting.frames, whiten, weighting, despike, correlated.gradients, correlated.accel, source

# The default 1/f stabilty time scale. Instruments should define their own.
stability = 15.0

# Determine the velocity clipping based on stability and beam size...
vclip = auto

# Determine accelaration clipping
# aclip = 20

# Downsample data as needed...
downsample = auto

# Signal estimators to use (&#39;median&#39; or &#39;maximum-likelihood&#39;).
estimator = maximum-likelihood

perimeter = auto

mappingfraction = 0.5

pixeldata = auto

rounds = 6

smooth = minimal

clip = 30.0

blank = 30.0

# Check for timestream gaps and fill with null frames as necessary
[fillgaps]
    value = True

# Remove the DC offsets before entering pipeline.
[level]
    value = True

[pointing]
    # The telescope pointing tolerance (in beams), e.g. for positions switched
    # photometry
    tolerance = 0.2

    # Specify the method for determining pointing offsets (also for pixelmap)
    # Choose between &#39;peak&#39; and &#39;centroid&#39;.
    method = centroid

    # Use the least-squares method for fitting rather than default CRUSH method
    lsq = True

    # Restrict pointing fits to a circular area around the nominal position.
    # The radius is specified in arcsec.
    # radius = 60.0
    radius = None

    # Derive pointing only if the peak S/N exceeds a critical level
    significance = 6.0

    # Discard the underexposed parts of the map when deriving pointing results
    # This does not affect the output image in any way
    exposureclip = 0.25

    suggest = None

[range]
    # The maximum fraction of samples which can be out-of-range before the
    # channel is flagged for being unusable.
    flagfraction = 0.05

[gains]
    value = True
    estimator = maximum-likelihood

[drifts]
    value = 30
    method = blocks

[filter]
    value = True
    ordering = motion, kill, whiten

    [[motion]]
        range = 0.01:1.0
        s2n = 6.0
        above = 0.3

    [[whiten]]
        level = 2.0
        proberange = auto

[weighting]
    value = True
    method = rms
    noiserange = 0.1:10.0

    [[frames]]
        resolution = auto
        noiserange = 0.3:3.0

    [[scans]]
        method = robust

[source]
    value = True
    type = map
    sign = +
    redundancy = 2

    [[coupling]]
        s2n = 5.0:*
        range = 0.3:3.0

    [[mem]]
        lambda = 0.1

    [[filter]]
        type = convolution

[rcp]
    [[gains]]
        value = True

[array]
    value = True
    gainrange = 0.01:10

[despike]
    value = True
    level = 100.0
    method = neighbours
    flagfraction = 3e-3
    flagcount = 10
    framespikes = 3
    width = auto

[dejump]
    level = 2.0
    minlength = 5.0

[indexing]
    indexing = auto
    saturation = 0.8

[pixelmap]
    [[process]]
        value = True

[skydip]
    grid = 900.0
    fit = tau, offset, kelvin
    attempts = 10
    [[uniform]]
        value = True

[write]
    source = True

    [[scandata]]
        value = True

    [[png]]
        value = False
        plane = s2n
        size = 500x500
        color = colorful
        bg = transparent
        smooth = halfbeam

   [[gnuplot]]
        value = True

[parallel]
    mode = hybrid
    cores = 0.5
    jobs = -1
    # idle = 0.5

[iteration]
    [[1]]
        forget = filter.kill

    [[2]]
        estimator = maximum-likelihood
        despike.level = 30.0
        clip = 10.0
        blank = 10.0
        [[[conditionals]]]
            [[[[extended]]]]
                blank = 100

    [[3]]
        # drifts.method = auto
        despike.level = 10.0
        clip = 4.0
        [[[conditionals]]]
            [[[[extended]]]]
                clip = 2.0

    [[4]]
        despike.method = absolute
        clip = 2.0
        [[[conditionals]]]
            [[[[extended]]]]
                blacklist = blank, despike

    [[-2]]
        add = filter.whiten

    [[0.9]]
        add = filter.whiten
        [[[conditionals]]]
            [[[[extended]]]]
                add = whiten

    [[-1]]
        forget = source.mem, smooth
        blacklist = clip, blank
        add = source.correct, source.nosync
        exposureclip = 0.04

[aliases]
    whiten = filter.whiten
    motion = filter.motion
    kill = filter.kill
    array = correlated.obs-channels
    gradients = correlated.gradients
    sky = correlated.sky
    nonlinearity = correlated.nonlinearity
    accel = correlated.accel-mag
    final = iteration.-1
    i = iteration
    i1 = iteration.1

[conditionals]
    [[system=focalplan]]
        blacklist = point

    [[source.type=skydip]]
        blacklist = point, aclip, vclip, drifts, offsets, whiten, point
        range.flagfraction = 0.75
        add = sourcegains
        beam = skydip.grid
        lock = beam

    [[source.type=pixelmap]]
        system = focalplane
        blacklist = pixeldata, exposureclip
        forget = source.redundancy, rcp

    [[extended]]
        stability = 30.0
        forget = filter.motion, weighting.frames, source.mem, correlated.gradients, weighting.scans
        weighting.method = differential
        correlated.*.gainrange = 0.01:100
        drifts.value = 300
        rounds = 15
        smooth = halfbeam
        blank = 100

    [[chopped]]
        forget = vclip, aclip, downsample, filter.motion

    [[map]]
        source.type = map

    [[pixelmap]]
        source.type = pixelmap

    [[skydip]]
        source.type = skydip

    [[beammap]]
        [[[pixelmap]]]

    [[sources]]
        add = source.fixedgains

    [[split]]
        add = smooth.external
        forget = final.exposureclip

    [[drifts]]
        forget = offsets

    [[offsets]]
        forget = drifts

    [[source.model]]
        forget = clip

    [[lab]]
        blacklist = source, filter.motion, tau, filter, whiten, shift, point
        forget = downsample
        add = write.spectrum

    [[derive]]
        forget = pixeldata, vclip, aclip
        blacklist = whiten
        add = write.pixeldata
        rounds = 30

    [[source.flatfield]]
        config = flatfield.cfg

    [[write.ascii]]
        blacklist = source.nosync

    [[write.spectrum]]
        blacklist = source.nosync

    [[write.covar]]
        blacklist = source.nosync

    [[bright]]
        config = bright.cfg

    [[faint]]
        config = faint.cfg

    [[deep]]
        config = deep.cfg


    [[scanpol]]
        config = scanpol.cfg

    # Use &#39;point&#39; as a shorthand for determining the pointing offsets at the end
    [[point]]
        [[[iterations]]]
            [[[[-1]]]]
                add = pointing.suggest
</pre></div>
</div>
</section>
<section id="hawc-scan-map-configuration-file">
<h3>HAWC+ Scan Map Configuration File<a class="headerlink" href="#hawc-scan-map-configuration-file" title="Link to this heading">¶</a></h3>
<p>Below is the HAWC+ configuration file for the scan map algorithm. Values in
this file override those in the global configuration file for HAWC reductions.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># Load SOFIA defaults
config = sofia/default.cfg

projection = TAN

# The ordering of models in the default reduction pipeline.
# ordering = dejump, offsets, drifts, correlated.obs-channels, correlated.sky, correlated.nonlinearity, correlated.polarrays, correlated.telescope-x, correlated.chopper-x, correlated.chopper-y, correlated.los, correlated.pitch, correlated.roll, correlated.accel-|y|, weighting.frames, filter, weighting, despike, correlated.subarrays, correlated.gradients, correlated.bias, correlated.series, correlated.mux, correlated.rows, source
ordering = dejump, offsets, drifts, correlated.obs-channels, correlated.sky, correlated.nonlinearity, correlated.polarrays, correlated.telescope-x, correlated.chopper-x, correlated.chopper-y, correlated.los, correlated.pitch, correlated.roll, correlated.accel-|y|, weighting.frames, filter, weighting, despike, correlated.subarrays, correlated.gradients, correlated.bias, correlated.series, correlated.mux, correlated.rows, source

# Specify the unit of the raw data
dataunits = count

unit = count

# The gain conversion to readout units
gain = -1.0

# The appropriate Jy/K conversion value (assuming 2.5m, 95% forward eff.)
K2Jy = 582

# Shift data relative to coordinates by the specified amount (seconds).
shift = -0.014

# Map even if many channels are flagged
mappingfraction = 0.2

# Use the faster maximum-likelihood estimation from the start...
estimator = maximum-likelihood

# 1/f stability timescale in seconds
stability = 5.0

# For scanpol mode, all output maps should have the same WCS
commonwcs = True

forget = write.png, write.eps, gnuplot, skydip
blacklist = calibrated, source.nosync

# Use neighbor-based de-spiking all the way...

despike.method = neighbours
lock = despike.method

intcalfreq = {?fits.DIAG_HZ}

#outpath = /Users/dperera/test_data/hawc/crush/testing/my_reductions

# My changes
rounds = 6
crushbugs = True
# subarray = R0
# End my changes

# Worm analysis
#downsample = 1
#
[fixjumps]
    value = True
    r0 = True
    r1 = True
    t0 = True
    t1 = True
    blank = 0, 0.015  # The number of seconds to blank (before, after) a jump

# Options to apply to pixels when loading channel data
# Channels will be excluded if values are outside of the specified ranges
# (gain.range, coupling.range) or are at a specific level (gain.exclude,
# couling.exclude).   The critical flags are those that will exclude a channel
# from being included.  Available flags are:
# Flag &#39;?&#39; - Unknown
# Flag &#39;X&#39; - Dead
# Flag &#39;B&#39; - Blind
# Flag &#39;d&#39; - Discarded
# Flag &#39;g&#39; - Gain
# Flag &#39;n&#39; - Noisy
# Flag &#39;f&#39; - Degrees-of-freedom.
# Flag &#39;s&#39; - Spiky
# Flag &#39;r&#39; - Railing/Saturated
# Flag &#39;F&#39; - Insufficient phase degrees-of-freedom
# Flag &#39;@&#39; - Bad subarray gain
# Flag &#39;b&#39; - Bad TES bias gain
# Flag &#39;m&#39; - Bad MUX gain
# Flag &#39;R&#39; - Bad detector row gain
# Flag &#39;M&#39; - Bad series array gain
# Flag &#39;T&#39; - Flicker noise
# Flag &#39;L&#39; - LOS response
# Flag &#39;\&#39; - Roll response
[pixels]
    criticalflags = X,B,g
    [[gain]]
        range = 0.3:3.0
    [[coupling]]
        range = 0.3:2.5
        exclude = 1.0

# Assumes sign of source signals +, -, or 0
[source]
    sign = +
    [[coupling]]
        s2n = 5.0:500.0

# starting Oct 2016 run, assume real-time object coordinates (rtoc) are
# recorded in the FITS for all sources, regardless of whether they are
# sidereal or not.
[rtoc]
    value = True

[subscan]
    # The minimum length of a valid scan in seconds.
    minlength = 5.0

[fits]

    # Additional header keys to migrate into product headers from earliest
    # scan...
    addkeys = SCRIPTID, OBSMODE, CALMODE, MCEMAP, HWPSTART, HWPINIT, NHWP, CHPONFPA, DTHSCALE

[chopper]
    # Shift chopper data to align with detectors
    shift = 2

    # Set a tolerance (arcsec) for the chopper signal. It has to be within the
    # nominal amplitude value for the frame to be used. This is useful to avoid
    # smearing when reducing chopped data...
    tolerance = 10

[vclip]
    # Discard slow scanning frames with entirely (instead of just
    # flagging them).
    [[strict]]
        value = True

[gyrocorrect]
    # Set a limit to what&#39;s the largest gyro drift that can be corrected...
    # (in arcsec)
    max = 30

[drifts]
    # Set the initial 1/f timescale..
    value = 30

[flag]
    # Flag some MUX lines that seem to be always bad...
    mux = 6, 20, 24, 27, 32, 46-49, 56, 70, 86
    # Flag rows that seem always bad
    row = 14, 15, 19, 52, 82, 83, 87

[rotation]
    # The overall rotation of the array from crush x,y coordinates to SI x,y.
    value = 0.1
    # The relative rotations of the subarrays.
    R0 = 0.0
    R1 = 180.0
    T0 = 0.5

[offset]
    # Subarray offsets (in channels)
    R0 = 0.0, 0.0
    R1 = 67.03, 39.0
    T0 = 0.5, -0.5

[zoom]
    # zoom constants (T vs R)
    T = 1.0

[weighting]
    # Flag channels outside an acceptable range of relative noise levels
    noiserange = 0.3:3.0

[array]
    # The range of acceptable relative sky-noise gains.
    gainrange = 0.3:3.0
    [[signed]]
        value = True

[biaslines]
    # Decorrelated on TES bias lines
    value = True
    gainrange = 0.3:3.0

[series]
    [[nogains]]
        value = True

[mux]
    # Decorrelate on SQUID multiplexed channels
    gainrange = 0.3:3.0
    [[nogains]]
        value = True

[rows]
    # Decorrelate on detector rows (i.e. MUX address lines)
    gainrange = 0.3:3.0

[tau]
    # Use&#39;s Bill Vacca&#39;s ATRAN-based polynomial model for calculating opacity...
    value = atran

    # Use the measured PWV to calculate tau...
    # value = pwv

    # Calculate typical PWV values, instead of using the monitor data
    # value = pwvmodel

    # Set tau to 0; turn off calibration
    # value = 0.0

    # Refer opacity relations to the PWV value (which is recorded)
    [[pwv]]
        a = 1.0
        b = 0.0

[skydip]
    # Fit skydips on restricted elevation range only...
    elrange = 0:55

[notch]
    width = 0.03
    harmonics = 35

[obslog]
    # logging...
    format = date\t flight\t scanno\t band\t object\t ?skydip\t obsmins(f1)\t chop.flag\t gyro.max(f1)\t ac.altkft(f1)\t tel.el(f1)\t env.pwv(f1)\t env.tamb(f1)\t dfoc(f1)

# Date is like conditionals
[date]
    [[*--2016-07-01]]
        add = apr2016

    [[2016-09-01--2016-11-01]]
        add = oct2016

    [[2016-11-30--2016-12-20]]
        add = dec2016

    [[*--2016-12-01]]
        [[[conditionals]]]
            [[[[tau.pwv]]]]
                # Use this model, whenever the pwv values aren&#39;t available or
                # cannot be trusted...
                add = tau.pwvmodel

    [[2016-12-03--2016-12-04]]
        [[[conditionals]]]
            [[[[tau.pwv]]]]
                add = tau.pwvmodel

    [[*--2017-05-01]]
        jumpdata = {?configpath}/hawc_plus/flux_jump_FS13_v1.fits.gz

    [[2017-05-01--2017-06-01]]
        add = may2017

    [[*--2017-10-01]]
        rotation.value = 0.9
        rotation.T0 = -0.5
        offset.T0 = 0.18,-0.17

    [[2017-10-01--2017-12-01]]
        add = oct2017

    [[2018-01-01--2018-07-16]]
        add = oc6i

    [[2018-07-17--2018-11-01]]
        add = oc6k

    [[*--2018-10-20]]
        flag.row = 2, 19, 52, 82, 83, 87, 114, 122, 65, 69, 77
        flag.mux = 6, 20, 24, 27-34, 40, 46-48, 50, 63, 70, 86

    [[2019-01-01--2019-03-01]]
        add = oc6t

    [[2019-03-02--2019-08-01]]
        add = oc7e

    [[2019-08-02--2019-10-15]]
        add = oc7f

    [[2020-01-17--2020-02-01]]
        add = oc7j

    [[2020-09-09--2020-09-23]]
        add = oc8e

    [[2021-05-05--2021-05-22]]
        add = oc8i

    [[2021-08-28--2021-09-11]]
        add = oc9d

    [[2021-11-03--2021-11-05]]
        add = oc9e

[conditionals]

    # If dealing with demodulated data, then load the appropriate
    # settings for reducing it
    [[fits.PRODTYPE=demod]]
        config = hawc_plus/demod.cfg

    [[peakflux]]
        scale = 1.18

    [[fits.SIBS_X=15.5]]
        # Select specific subarrays only. E.g. if pointing to the center of R0,
        # then reduce R0/T0 only...
        subarray = T0, R0
        # subarray = T0

    # Reduce skydips if OBSMODE, CALMODE or DIAGMODE is set to SKYDIP
    [[fits.DIAGMODE=SKYDIP]]
        add = skydip

    [[fits.OBSMODE=SkyDip]]
        add = skydip

    # Set the observing band based on the SPECTEL1 header value
    [[fits.SPECTEL1=HAW_A]]
        band = A

    [[fits.SPECTEL1=HAW_B]]
        band = B

    [[fits.SPECTEL1=HAW_C]]
        band = C

    [[fits.SPECTEL1=HAW_D]]
        band = D

    [[fits.SPECTEL1=HAW_E]]
        band = E

    [[source.type=skydip]]
        # Reduce skydips with R0 only (least non-linear)
        subarray = R0
        # For skydips, notch out the intcal signal (203.25 Hz / 68 --
        # and harmonics)
        add = notch
        lock = subarray
        blacklist = fixjumps

    [[chopped]]
        # Allow velocity clip for chopped data (mapping mode)
        recall = vclip
        # For chopped data, remove the chopper-induced correlated signals...
        add = correlated.chopper-x, correlated.chopper-y

    # When using non-linear response corrections, make sure the drift window
    # covers the entire scan...
    [[correlated.nonlinearity]]
        drifts = max

    [[extended]]
        stability = 10.0

    # Use shorter &#39;stability&#39; timescale for short scans, such as focus scans,
    # to get the crispest possible images...
    [[obstime&lt;45]]
        stability = 2.5

    [[may2017]]
        jumpdata = {?configpath}/hawc_plus/flux_jump_FS14_v1.fits.gz

    [[oct2017]]
        jumpdata = {?configpath}/hawc_plus/flux_jump_FS15_v3.fits.gz
        # Apply correction for gyro drifts
        add = gyrocorrect

    [[sourcegains]]
        # If the couplings are merged into the correlated gains, then do not
        # decorrelate on sky separately...
        blacklist = sky

    # Previously weird intcalfreq = fits.DIAG_HZ, then transfered to this
    [[fits.DIAG_HZ!=-9999.0]]
        notch.frequencies = fits.DIAG_HZ

    # Load date-based configuration overrides...
    [[apr2016]]
        config = hawc_plus/2016-04.cfg

    [[oct2016]]
        config = hawc_plus/2016-10.cfg

    # Load the appropriate configuration for each band
    [[band=A]]
        config = hawc_plus/band-A.cfg

    [[band=B]]
        config = hawc_plus/band-B.cfg

    [[band=C]]
        config = hawc_plus/band-C.cfg

    [[band=D]]
        config = hawc_plus/band-D.cfg

    [[band=E]]
        config = hawc_plus/band-E.cfg

    # If pixel data was loaded from a previous band
    [[pixeldata]]
        # Decorrelate sky signal (separated from temperature signal)
        add = sky

    # Never segment scans if using them for determining flatfields.
    [[write.flatfield]]
        blacklist = segment

[aliases]
    # Define various shorthands for decorrelations
    pols = correlated.polarrays
    subs = correlated.subarrays
    biaslines = correlated.bias
    mux = correlated.mux
    rows = correlated.rows
    series = correlated.series
    accel = correlated.accel-|y|
    los = correlated.los
    roll = correlated.roll
    gradients = correlated.gradients

[iteration]
    [[-2]]
        # Decorrelate on the series arrays (heat-sinking)
        series = True

    [[-1]]
        [[[conditionals]]]
            # Never smooth focus scans...
            [[[[fits.CALMODE=Focus]]]]
                blacklist = smooth


</pre></div>
</div>
</section>
</section>
<section id="appendix-required-header-keywords">
<span id="kwd-appendix"></span><h2>Appendix: Required Header Keywords<a class="headerlink" href="#appendix-required-header-keywords" title="Link to this heading">¶</a></h2>
<p>The file below defines all keywords that the HAWC pipeline checks for
validity before proceeding. It is normally located in the hawc
distribution at <em>hawc/pipeline/config/header_req_config.cfg</em>. The path
to this file should be specified in the pipeline configuration file
under the ‘[checkhead]’ section in order to perform the header check.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># HAWC pipeline header requirements configuration file
#
# Keywords in this list are only those required for successful
# data reduction (grouping and processing).  There may be more
# keywords required by the SOFIA DCS. This file is used
# by StepCheckhead.
#
# Requirement value should be *, chopping, nodding, dithering,
# or scanning (as denoted by the corresponding FITS keywords).
# * indicates a keyword that is required for all data.  All
# others will only be checked if they are appropriate to the
# mode of the input data.
#
# DRange is not required to be present in the configuration --
# if missing, the keyword will be checked for presence only.  If
# drange is present, it will be checked for an enum requirement
# first; other requirements are ignored if present.  Min/max
# requirements are only used for numerical types, and are inclusive
# (i.e. the value may be &gt;= min and &lt;= max).
#
# 2016-08-22 Melanie Clarke: First version

[CHOPPING]
    requirement = *
    dtype = bool

[CHPAMP1]
    requirement = chopping
    dtype = float
    [[drange]]
        min = -1125
        max = 1125

[CHPANGLE]
    requirement = chopping
    dtype = float
    [[drange]]
        min = -360
        max = 360

[CHPCRSYS]
    requirement = chopping
    dtype = str
    [[drange]]
        enum = TARF, ERF, SIRF

[CHPFREQ]
    requirement = chopping
    dtype = float
    [[drange]]
        min = 0.0
        max = 20.0

[CHPONFPA]
    requirement = chopping
    dtype = bool

[DATE-OBS]
    requirement = *
    dtype = str

[DITHER]
    requirement = *
    dtype = bool

[DTHINDEX]
    requirement = dithering
    dtype = int
    [[drange]]
        min = 0

[DTHSCALE]
    requirement = dithering
    dtype = float

[DTHXOFF]
    requirement = dithering
    dtype = float

[DTHYOFF]
    requirement = dithering
    dtype = float

[EQUINOX]
    requirement = *
    dtype = float

[EXPTIME]
    requirement = *
    dtype = float
    [[drange]]
        min = 0.0

[FOCUS_EN]
    requirement = *
    dtype = float
    [[drange]]
        min = -5000.0
        max = 5000.0

[FOCUS_ST]
    requirement = *
    dtype = float
    [[drange]]
        min = -5000.0
        max = 5000.0

[HWPSTART]
    requirement = nodding
    dtype = float
    [[drange]]
        min = -360.0
        max = 360.0

[INSTCFG]
    requirement = *
    dtype = str
    [[drange]]
        enum = TOTAL_INTENSITY, POLARIZATION

[INSTMODE]
    requirement = *
    dtype = str
    [[drange]]
        enum = C2N (NMC), OTFMAP

[INSTRUME]
    requirement = *
    dtype = str
    [[drange]]
        enum = HAWC_PLUS

[MCEMAP]
    requirement = scanning
    dtype = str

[NHWP]
    requirement = nodding
    dtype = int
    [[drange]]
        min = 1

[NODDING]
    requirement = *
    dtype = bool

[NODPATT]
    requirement = nodding
    dtype = str
    [[drange]]
        enum = ABBA, A

[OBJECT]
    requirement = *
    dtype = str

[OBS_ID]
    requirement = *
    dtype = str

[SIBS_X]
    requirement = *
    dtype = float

[SIBS_Y]
    requirement = *
    dtype = float

[SMPLFREQ]
    requirement = *
    dtype = float
    [[drange]]
        min = 1.0

[SPECTEL1]
    requirement = *
    dtype = str
    [[drange]]
        enum = HAW_A, HAW_B, HAW_C, HAW_D, HAW_E

[SPECTEL2]
    requirement = *
    dtype = str
    [[drange]]
        enum = NONE, HAW_HWP_A, HAW_HWP_B, HAW_HWP_C, HAW_HWP_D, HAW_HWP_E, HAW_HWP_Open, HAW_HWP_Offset1, HAW_HWP_Offset2, HAW_HWP_Offset3

[SRCTYPE]
    requirement = *
    dtype = str
    [[drange]]
        enum = POINT_SOURCE, COMPACT_SOURCE, EXTENDED_SOURCE, OTHER, UNKNOWN

[TELDEC]
    requirement = *
    dtype = float
    [[drange]]
        min = -90.0
        max = 90.0

[TELRA]
    requirement = *
    dtype = float
    [[drange]]
        min = 0.0
        max = 24.0

[TELVPA]
    requirement = *
    dtype = float
    [[drange]]
        min = -360.0
        max = 360.0

[UTCSTART]
    requirement = *
    dtype = str
</pre></div>
</div>
</section>
<section id="appendix-change-notes-for-the-hawc-pipeline">
<h2>Appendix: Change notes for the HAWC+ pipeline<a class="headerlink" href="#appendix-change-notes-for-the-hawc-pipeline" title="Link to this heading">¶</a></h2>
<section id="significant-changes">
<h3>Significant changes<a class="headerlink" href="#significant-changes" title="Link to this heading">¶</a></h3>
<p>Below are listed the most significant changes for the HAWC+ pipeline
over its history, highlighting impacts to science data products.
See the data handbooks or user manuals associated with each release
for more information.</p>
<p>For previously processed data, check the PIPEVERS keyword in the FITS
header to determine the pipeline version used.</p>
<section id="hawc-drp-v3-2-0-2022-12-20">
<h4>HAWC DRP v3.2.0 (2022-12-20)<a class="headerlink" href="#hawc-drp-v3-2-0-2022-12-20" title="Link to this heading">¶</a></h4>
<p><em>User manual: Rev. L</em></p>
<ul class="simple">
<li><p>Improved the ‘fixjumps’ algorithm for correcting discrepant artifacts
in scan maps caused by detector flux jumps.</p></li>
</ul>
</section>
<section id="hawc-drp-v3-1-0-2022-09-12">
<h4>HAWC DRP v3.1.0 (2022-09-12)<a class="headerlink" href="#hawc-drp-v3-1-0-2022-09-12" title="Link to this heading">¶</a></h4>
<p><em>User manual: Rev. K</em></p>
<ul class="simple">
<li><p>Added a ‘grid’ parameter for the scan map steps to allow easy spatial
regridding without impacting flux conservation.</p></li>
</ul>
</section>
<section id="hawc-drp-v3-0-0-2022-02-15">
<h4>HAWC DRP v3.0.0 (2022-02-15)<a class="headerlink" href="#hawc-drp-v3-0-0-2022-02-15" title="Link to this heading">¶</a></h4>
<p><em>User manual: Rev. J</em></p>
<ul class="simple">
<li><p>Replaced the Java sub-pipeline for reconstructing scanned maps with
a Python implementation (sofia_redux.scan).</p></li>
<li><p>Added optional step to correct the zero level in total intensity
scan maps.</p></li>
</ul>
</section>
<section id="hawc-drp-v2-7-0-2021-08-23">
<h4>HAWC DRP v2.7.0 (2021-08-23)<a class="headerlink" href="#hawc-drp-v2-7-0-2021-08-23" title="Link to this heading">¶</a></h4>
<p><em>User manual: Rev. H</em></p>
<ul class="simple">
<li><p>Added support for generating noise plots from lab data.</p></li>
<li><p>Fixed a time accounting bug in the EXPTIME keyword for scan-pol data.
Prior to this version, EXPTIME in the reduced data products counted
only the exposure time from a single HWP angle.</p></li>
<li><p>Added new visualization tools to the pipeline interface and QAD tool.</p></li>
</ul>
</section>
<section id="hawc-drp-v2-6-0-2021-04-26">
<h4>HAWC DRP v2.6.0 (2021-04-26)<a class="headerlink" href="#hawc-drp-v2-6-0-2021-04-26" title="Link to this heading">¶</a></h4>
<p><em>User manual: Rev. G</em></p>
<ul class="simple">
<li><p>Improvements to error estimates, edge pixel handling, and adaptive
smoothing in the resampling algorithm.</p></li>
<li><p>Introduce a pipeline mode to be used to generate new skycal files,
scan-mode flats, and bad pixel lists from scans of bright sources.</p></li>
<li><p>Add preview images (*.png files) for all final data products.</p></li>
<li><p>Improvement for parallel processing across disparate architectures.</p></li>
<li><p>Add an optional pixel-binning step for the chop-nod pipeline,
to allow improved S/N at the cost of decreases resolution.</p></li>
<li><p>Introduce a zero-level correction algorithm for scanning polarimetry
maps of large, diffuse sources.</p></li>
</ul>
</section>
<section id="hawc-drp-v2-5-0-2020-06-09">
<h4>HAWC DRP v2.5.0 (2020-06-09)<a class="headerlink" href="#hawc-drp-v2-5-0-2020-06-09" title="Link to this heading">¶</a></h4>
<p><em>User manual: Rev. F</em></p>
<ul class="simple">
<li><p>Python code refactored into common namespace, for compatibility
with other SOFIA pipelines.</p></li>
<li><p>Improve error estimates for photometry profile fits for flux
standards.</p></li>
</ul>
</section>
<section id="hawc-drp-v2-4-0-2020-01-15">
<h4>HAWC DRP v2.4.0 (2020-01-15)<a class="headerlink" href="#hawc-drp-v2-4-0-2020-01-15" title="Link to this heading">¶</a></h4>
<p><em>User manual: Rev. E</em></p>
<ul class="simple">
<li><p>Add SIBS offset value calculation in FITS headers (SIBS_DXE, SIBS_DE),
for computing pointing corrections for the scan-mode pipeline.</p></li>
<li><p>Internal C library replaced with Python algorithms.</p></li>
</ul>
</section>
<section id="hawc-drp-v2-3-2-2019-09-17">
<h4>HAWC DRP v2.3.2 (2019-09-17)<a class="headerlink" href="#hawc-drp-v2-3-2-2019-09-17" title="Link to this heading">¶</a></h4>
<p><em>User manual: Rev. D</em></p>
<ul class="simple">
<li><p>Scan mode data frames at the beginning and end of observations
are now trimmed, by default, to account for the pause between
data readouts begin/end and telescope movement begin/end.</p></li>
<li><p>Add option to allow manual override for Stokes combination,
when HWP angle is inaccurately recorded.</p></li>
</ul>
</section>
<section id="hawc-drp-v2-3-1-2019-08-06">
<h4>HAWC DRP v2.3.1 (2019-08-06)<a class="headerlink" href="#hawc-drp-v2-3-1-2019-08-06" title="Link to this heading">¶</a></h4>
<p><em>User manual: Rev. D</em></p>
<ul class="simple">
<li><p>Fix for occasional WCS offset error in scan-pol mode.</p></li>
</ul>
</section>
<section id="hawc-drp-v2-3-0-2019-07-02">
<h4>HAWC DRP v2.3.0 (2019-07-02)<a class="headerlink" href="#hawc-drp-v2-3-0-2019-07-02" title="Link to this heading">¶</a></h4>
<p><em>User manual: Rev. D</em></p>
<ul class="simple">
<li><p>Scanning polarimetry now groups data in sets of 4 HWP angles and
combines the data after computing Stokes parameters, rather than
running common HWP angles through the CRUSH sub-pipeline together.
This allows better correction for sky rotation angle (VPA).</p></li>
</ul>
</section>
<section id="hawc-drp-v2-2-0-2019-05-24">
<h4>HAWC DRP v2.2.0 (2019-05-24)<a class="headerlink" href="#hawc-drp-v2-2-0-2019-05-24" title="Link to this heading">¶</a></h4>
<p><em>User manual: Rev. D</em></p>
<ul class="simple">
<li><p>Fix for parameter resets between files in a single reduction run.</p></li>
<li><p>Revise Python packaging structure to avoid manual C library compilation.</p></li>
</ul>
</section>
<section id="hawc-drp-v2-1-0-2019-02-21">
<h4>HAWC DRP v2.1.0 (2019-02-21)<a class="headerlink" href="#hawc-drp-v2-1-0-2019-02-21" title="Link to this heading">¶</a></h4>
<p><em>User manual: Rev. D</em></p>
<ul class="simple">
<li><p>Introduce support for scanning polarimetry.</p></li>
<li><p>Flux calibration improvements: add automated photometry routines
for flux standards, move scan-mode calibration out of CRUSH sub-pipeline
and into the same Python step used for chop-nod mode. Default saved
products are changed.</p></li>
<li><p>Introduced option for sigma-clipping on telescope velocity in the
scan modes.</p></li>
</ul>
</section>
<section id="hawc-drp-v2-0-0-2018-09-24">
<h4>HAWC DRP v2.0.0 (2018-09-24)<a class="headerlink" href="#hawc-drp-v2-0-0-2018-09-24" title="Link to this heading">¶</a></h4>
<p><em>User manual: Rev. C</em></p>
<ul class="simple">
<li><p>Refactored all Python 2 code into Python 3.</p></li>
<li><p>Integrated pipeline algorithms into Redux interface for consistency
with other SOFIA pipelines.</p></li>
<li><p>Fixes for BUNIT keywords in extension headers.</p></li>
</ul>
</section>
<section id="hawc-drp-v1-3-0-2018-05-17">
<h4>HAWC DRP v1.3.0 (2018-05-17)<a class="headerlink" href="#hawc-drp-v1-3-0-2018-05-17" title="Link to this heading">¶</a></h4>
<p><em>User manual: Rev. B</em></p>
<ul class="simple">
<li><p>Introduce instrumental polarization maps to correct IP for each
detector pixel.</p></li>
<li><p>Modify background subtraction to apply to Stokes Q and U as well
as Stokes I images.</p></li>
<li><p>Remove unused, empty pixel covariance planes from output data products.</p></li>
<li><p>Demodulation step separated into two parts in order to separate pixel
flagging from filtering, to allow inspection of the flagged data.</p></li>
<li><p>Outlier rejection improvements for the time-series combination step.</p></li>
<li><p>Add diagnostic plots (*DPL*.png) of demodulated data.</p></li>
<li><p>Error propagation improvements: calculating initial errors from raw
samples (before demodulation and R-T subtraction), and propagating
covariance between Stokes parameters.</p></li>
</ul>
</section>
<section id="hawc-drp-v1-2-0-2017-11-09">
<h4>HAWC DRP v1.2.0 (2017-11-09)<a class="headerlink" href="#hawc-drp-v1-2-0-2017-11-09" title="Link to this heading">¶</a></h4>
<p><em>User manual: Rev. A</em></p>
<ul class="simple">
<li><p>Track all input MISSN-IDs in the ASSC_MSN FITS keyword.</p></li>
</ul>
</section>
<section id="hawc-drp-v1-1-1-2017-05-17">
<h4>HAWC DRP v1.1.1 (2017-05-17)<a class="headerlink" href="#hawc-drp-v1-1-1-2017-05-17" title="Link to this heading">¶</a></h4>
<p><em>User manual: Rev. A</em></p>
<ul class="simple">
<li><p>Fix sign error for WCS in SI reference frame.</p></li>
</ul>
</section>
<section id="hawc-drp-v1-1-0-2017-05-02">
<h4>HAWC DRP v1.1.0 (2017-05-02)<a class="headerlink" href="#hawc-drp-v1-1-0-2017-05-02" title="Link to this heading">¶</a></h4>
<p><em>User manual: Rev. A</em></p>
<ul class="simple">
<li><p>Introduce flats for chop-nod mode derived from internal calibrator files
bracketing science observations.</p></li>
<li><p>Update scan mode opacity corrections to match chop-nod mode method
(from ATRAN model).</p></li>
</ul>
</section>
<section id="hawc-drp-v1-0-1-2017-01-30">
<h4>HAWC DRP v1.0.1 (2017-01-30)<a class="headerlink" href="#hawc-drp-v1-0-1-2017-01-30" title="Link to this heading">¶</a></h4>
<p><em>User manual: Rev. -</em></p>
<ul class="simple">
<li><p>Fix for bad pixel mask handling for T array.</p></li>
</ul>
</section>
<section id="hawc-drp-v1-0-0-2017-01-25">
<h4>HAWC DRP v1.0.0 (2017-01-25)<a class="headerlink" href="#hawc-drp-v1-0-0-2017-01-25" title="Link to this heading">¶</a></h4>
<p><em>User manual: Rev. -</em></p>
<ul class="simple">
<li><p>Initial release.</p></li>
</ul>
</section>
</section>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><h3>Page Contents</h3>
<ul>
<li><a class="reference internal" href="#">HAWC+ DRP User’s Manual</a><ul>
<li><a class="reference internal" href="#introduction">Introduction</a></li>
<li><a class="reference internal" href="#si-observing-modes-supported">SI Observing Modes Supported</a><ul>
<li><a class="reference internal" href="#hawc-instrument-information">HAWC+ Instrument Information</a></li>
<li><a class="reference internal" href="#hawc-observing-modes">HAWC+ Observing Modes</a></li>
</ul>
</li>
<li><a class="reference internal" href="#algorithm-description">Algorithm Description</a><ul>
<li><a class="reference internal" href="#chop-nod-and-nod-pol-reduction-algorithms">Chop-Nod and Nod-Pol Reduction Algorithms</a><ul>
<li><a class="reference internal" href="#prepare">Prepare</a></li>
<li><a class="reference internal" href="#demodulate">Demodulate</a></li>
<li><a class="reference internal" href="#flat-correct">Flat Correct</a></li>
<li><a class="reference internal" href="#align-arrays">Align Arrays</a></li>
<li><a class="reference internal" href="#split-images">Split Images</a></li>
<li><a class="reference internal" href="#combine-images">Combine Images</a></li>
<li><a class="reference internal" href="#subtract-beams">Subtract Beams</a></li>
<li><a class="reference internal" href="#compute-stokes">Compute Stokes</a></li>
<li><a class="reference internal" href="#update-wcs">Update WCS</a></li>
<li><a class="reference internal" href="#subtract-instrumental-polarization">Subtract Instrumental Polarization</a></li>
<li><a class="reference internal" href="#rotate-polarization-coordinates">Rotate Polarization Coordinates</a></li>
<li><a class="reference internal" href="#correct-for-atmospheric-opacity">Correct for Atmospheric Opacity</a></li>
<li><a class="reference internal" href="#calibrate-flux">Calibrate Flux</a></li>
<li><a class="reference internal" href="#subtract-background">Subtract Background</a></li>
<li><a class="reference internal" href="#rebin-images">Rebin Images</a></li>
<li><a class="reference internal" href="#merge-images">Merge Images</a></li>
<li><a class="reference internal" href="#compute-vectors">Compute Vectors</a></li>
</ul>
</li>
<li><a class="reference internal" href="#scan-reduction-algorithms">Scan Reduction Algorithms</a><ul>
<li><a class="reference internal" href="#signal-structure">Signal Structure</a></li>
<li><a class="reference internal" href="#sequential-incremental-modeling-and-iterations">Sequential Incremental Modeling and Iterations</a></li>
<li><a class="reference internal" href="#initialization-and-scan-validation">Initialization and Scan Validation</a></li>
<li><a class="reference internal" href="#dc-offset-and-1-f-drift-removal">DC Offset and 1/f Drift Removal</a></li>
<li><a class="reference internal" href="#correlated-noise-removal-and-gain-estimation">Correlated Noise Removal and Gain Estimation</a></li>
<li><a class="reference internal" href="#noise-weighting">Noise Weighting</a></li>
<li><a class="reference internal" href="#despiking">Despiking</a></li>
<li><a class="reference internal" href="#spectral-conditioning">Spectral Conditioning</a></li>
<li><a class="reference internal" href="#map-making">Map Making</a></li>
<li><a class="reference internal" href="#point-source-flux-corrections">Point-Source Flux Corrections</a></li>
<li><a class="reference internal" href="#scan-map-output">Scan Map Output</a></li>
</ul>
</li>
<li><a class="reference internal" href="#scan-pol-reduction-algorithms">Scan-Pol Reduction Algorithms</a></li>
<li><a class="reference internal" href="#other-resources">Other Resources</a></li>
</ul>
</li>
<li><a class="reference internal" href="#data-products">Data Products</a><ul>
<li><a class="reference internal" href="#file-names">File names</a></li>
<li><a class="reference internal" href="#data-format">Data format</a></li>
<li><a class="reference internal" href="#pipeline-products">Pipeline products</a></li>
</ul>
</li>
<li><a class="reference internal" href="#grouping-level-0-data-for-processing">Grouping Level 0 Data for Processing</a></li>
<li><a class="reference internal" href="#configuration-and-execution">Configuration and Execution</a><ul>
<li><a class="reference internal" href="#installation">Installation</a><ul>
<li><a class="reference internal" href="#external-requirements">External Requirements</a></li>
<li><a class="reference internal" href="#source-code-installation">Source Code Installation</a></li>
</ul>
</li>
<li><a class="reference internal" href="#configuration">Configuration</a></li>
<li><a class="reference internal" href="#input-data">Input Data</a><ul>
<li><a class="reference internal" href="#auxiliary-files">Auxiliary Files</a></li>
</ul>
</li>
<li><a class="reference internal" href="#automatic-mode-execution">Automatic Mode Execution</a></li>
<li><a class="reference internal" href="#manual-mode-execution">Manual Mode Execution</a><ul>
<li><a class="reference internal" href="#basic-workflow">Basic Workflow</a></li>
<li><a class="reference internal" href="#display-features">Display Features</a></li>
</ul>
</li>
<li><a class="reference internal" href="#important-parameters">Important Parameters</a></li>
</ul>
</li>
<li><a class="reference internal" href="#data-quality-assessment">Data Quality Assessment</a></li>
<li><a class="reference internal" href="#appendix-scan-map-option-glossary">Appendix: Scan Map Option Glossary</a></li>
<li><a class="reference internal" href="#appendix-sample-configuration-files">Appendix: Sample Configuration Files</a><ul>
<li><a class="reference internal" href="#full-drp-configuration-file">Full DRP Configuration File</a></li>
<li><a class="reference internal" href="#drp-override-configuration-file">DRP Override Configuration File</a></li>
<li><a class="reference internal" href="#full-scan-map-configuration-file">Full Scan Map Configuration File</a></li>
<li><a class="reference internal" href="#hawc-scan-map-configuration-file">HAWC+ Scan Map Configuration File</a></li>
</ul>
</li>
<li><a class="reference internal" href="#appendix-required-header-keywords">Appendix: Required Header Keywords</a></li>
<li><a class="reference internal" href="#appendix-change-notes-for-the-hawc-pipeline">Appendix: Change notes for the HAWC+ pipeline</a><ul>
<li><a class="reference internal" href="#significant-changes">Significant changes</a><ul>
<li><a class="reference internal" href="#hawc-drp-v3-2-0-2022-12-20">HAWC DRP v3.2.0 (2022-12-20)</a></li>
<li><a class="reference internal" href="#hawc-drp-v3-1-0-2022-09-12">HAWC DRP v3.1.0 (2022-09-12)</a></li>
<li><a class="reference internal" href="#hawc-drp-v3-0-0-2022-02-15">HAWC DRP v3.0.0 (2022-02-15)</a></li>
<li><a class="reference internal" href="#hawc-drp-v2-7-0-2021-08-23">HAWC DRP v2.7.0 (2021-08-23)</a></li>
<li><a class="reference internal" href="#hawc-drp-v2-6-0-2021-04-26">HAWC DRP v2.6.0 (2021-04-26)</a></li>
<li><a class="reference internal" href="#hawc-drp-v2-5-0-2020-06-09">HAWC DRP v2.5.0 (2020-06-09)</a></li>
<li><a class="reference internal" href="#hawc-drp-v2-4-0-2020-01-15">HAWC DRP v2.4.0 (2020-01-15)</a></li>
<li><a class="reference internal" href="#hawc-drp-v2-3-2-2019-09-17">HAWC DRP v2.3.2 (2019-09-17)</a></li>
<li><a class="reference internal" href="#hawc-drp-v2-3-1-2019-08-06">HAWC DRP v2.3.1 (2019-08-06)</a></li>
<li><a class="reference internal" href="#hawc-drp-v2-3-0-2019-07-02">HAWC DRP v2.3.0 (2019-07-02)</a></li>
<li><a class="reference internal" href="#hawc-drp-v2-2-0-2019-05-24">HAWC DRP v2.2.0 (2019-05-24)</a></li>
<li><a class="reference internal" href="#hawc-drp-v2-1-0-2019-02-21">HAWC DRP v2.1.0 (2019-02-21)</a></li>
<li><a class="reference internal" href="#hawc-drp-v2-0-0-2018-09-24">HAWC DRP v2.0.0 (2018-09-24)</a></li>
<li><a class="reference internal" href="#hawc-drp-v1-3-0-2018-05-17">HAWC DRP v1.3.0 (2018-05-17)</a></li>
<li><a class="reference internal" href="#hawc-drp-v1-2-0-2017-11-09">HAWC DRP v1.2.0 (2017-11-09)</a></li>
<li><a class="reference internal" href="#hawc-drp-v1-1-1-2017-05-17">HAWC DRP v1.1.1 (2017-05-17)</a></li>
<li><a class="reference internal" href="#hawc-drp-v1-1-0-2017-05-02">HAWC DRP v1.1.0 (2017-05-02)</a></li>
<li><a class="reference internal" href="#hawc-drp-v1-0-1-2017-01-30">HAWC DRP v1.0.1 (2017-01-30)</a></li>
<li><a class="reference internal" href="#hawc-drp-v1-0-0-2017-01-25">HAWC DRP v1.0.0 (2017-01-25)</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>


        </div>
      </div>
      <div class="clearer"></div>
    </div>
<footer class="footer">
  <p class="pull-right">
    <a href="../../../_sources/manuals/hawc/users/users.rst.txt"
       rel="nofollow">Page Source</a> &nbsp;
    <a href="#">Back to Top</a></p>
  <p>
    &copy; Copyright 2024, SOFIA-USRA.<br/>
    Created using <a href="http://www.sphinx-doc.org/en/stable/">Sphinx</a> 7.2.6. &nbsp;
    Last built 05 Feb 2024. <br/>
  </p>
</footer>
  </body>
</html>